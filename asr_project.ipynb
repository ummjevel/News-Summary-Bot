{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25815,"status":"ok","timestamp":1672227382522,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"NBud-xIUJfLZ","outputId":"9fb31765-7318-4877-824e-262ff9e391e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"KqYwUg-GI5T_"},"source":["# extract zip file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4836,"status":"ok","timestamp":1672049707410,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"JKNrUvRvK24a","outputId":"8dc0d88c-80a1-4b46-ea43-279d08857c92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n","Collecting gdown\n","  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.4.0\n","    Uninstalling gdown-4.4.0:\n","      Successfully uninstalled gdown-4.4.0\n","Successfully installed gdown-4.6.0\n"]}],"source":["!pip install -U --no-cache-dir gdown --pre"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1672049710002,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"8uzBSMwSK7Zr","outputId":"68a615cd-4f14-4010-fb34-34d495719669"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Alpaco_NLP\n"]}],"source":["%cd /content/drive/MyDrive/Alpaco_NLP"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1672049712994,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"e-j4SdyyK-rP","outputId":"5b8a1bf5-6126-4b30-8f99-de1422da0bc8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Alpaco_NLP\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11877,"status":"ok","timestamp":1672037173581,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"B-jiL6cxK5Lj","outputId":"f48c667f-f256-4764-ec93-e3415fcf9eda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1kvkYZvejEjIrrcn3MclW1bwTyaflYzSv\n","To: /content/drive/MyDrive/Alpaco_NLP/TL1.zip\n","100% 227M/227M [00:10<00:00, 21.6MB/s]\n"]}],"source":["!gdown '1kvkYZvejEjIrrcn3MclW1bwTyaflYzSv'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_ZUWSwSI4pR"},"outputs":[],"source":["import zipfile\n","\n","path_to_zip_file1 = '/content/drive/MyDrive/Alpaco_NLP/TL1.zip'\n","directory_to_extract_to = '/content/drive/MyDrive/Alpaco_NLP/training/tl1'\n","\n","with zipfile.ZipFile(path_to_zip_file1, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2524,"status":"ok","timestamp":1672049721112,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"N_OLgPfQOd4n","outputId":"a71088b8-f704-428e-f4e6-e7a1d19a3290"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1vgbM7FAyZU5y5CBgv8Gv9UAVa9KUWraq\n","To: /content/drive/MyDrive/Alpaco_NLP/VL1.zip\n","100% 28.3M/28.3M [00:00<00:00, 40.0MB/s]\n"]}],"source":["!gdown 1vgbM7FAyZU5y5CBgv8Gv9UAVa9KUWraq # VL1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxabwE5KOcjQ"},"outputs":[],"source":["import zipfile\n","\n","path_to_zip_file1 = '/content/drive/MyDrive/Alpaco_NLP/VL1.zip'\n","directory_to_extract_to = '/content/drive/MyDrive/Alpaco_NLP/validation/vl1'\n","\n","with zipfile.ZipFile(path_to_zip_file1, 'r') as zip_ref:\n","    zip_ref.extractall(directory_to_extract_to)"]},{"cell_type":"markdown","metadata":{"id":"BeEsUq3yHevJ"},"source":["# json to dataframe to pickle\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1822559,"status":"ok","timestamp":1672044480387,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"MUM_6vGdHbx7","outputId":"10a7f545-939b-4ab7-87ae-4738f4749656"},"outputs":[{"data":{"text/plain":["146771"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import os\n","import glob\n","import pandas as pd\n","from tqdm import tqdm\n","\n","train_json_path = '/content/drive/MyDrive/Alpaco_NLP/training/tl1/'\n","dict_train_json_folder = []\n","\n","df_train = pd.DataFrame()\n","\n","for dir in os.listdir(train_json_path):\n","    dict_train_json_folder.append(dir)\n","    break\n","\n","for dict_key in dict_train_json_folder:\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/20per/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_train = df_train.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/2~3sent/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_train = df_train.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","len(df_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370187,"status":"ok","timestamp":1672140359458,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"hHglsORyR2pQ","outputId":"4ab88635-04a6-4d9b-965a-696075fb3ef3"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10800/10800 [05:14<00:00, 34.34it/s] \n","100%|██████████| 10800/10800 [00:54<00:00, 196.66it/s]\n"]},{"data":{"text/plain":["21600"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import os\n","import glob\n","import pandas as pd\n","from tqdm import tqdm\n","\n","train_json_path = '/content/drive/MyDrive/Alpaco_NLP/training/tl1/'\n","dict_train_json_folder = []\n","\n","df_train = pd.DataFrame()\n","\n","for dir in os.listdir(train_json_path):\n","    dict_train_json_folder.append(dir)\n","    break\n","\n","for dict_key in dict_train_json_folder:\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/20per/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_train = df_train.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/2~3sent/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_train = df_train.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","len(df_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":344,"status":"ok","timestamp":1672140378881,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"yarpJ_xNTZyT","outputId":"283bcef8-1dd4-43f4-b993-c3b5fd8bb0a9"},"outputs":[{"data":{"text/plain":["21600"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(df_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EM3WEjYHZtFC"},"outputs":[],"source":["df_train.to_pickle('/content/drive/MyDrive/Alpaco_NLP/training/tl_news.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59950,"status":"ok","timestamp":1672140452966,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"xYrrKJfHn7vF","outputId":"7e5f1221-7e0f-4836-9b3c-638995c34dd1"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1350/1350 [00:18<00:00, 73.99it/s] \n","100%|██████████| 1350/1350 [00:19<00:00, 69.30it/s] \n"]},{"data":{"text/plain":["2700"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import os\n","import glob\n","import pandas as pd\n","from tqdm import tqdm\n","\n","train_json_path = '/content/drive/MyDrive/Alpaco_NLP/validation/vl1/'\n","dict_train_json_folder = []\n","\n","df_test = pd.DataFrame()\n","\n","for dir in os.listdir(train_json_path):\n","    dict_train_json_folder.append(dir)\n","    break\n","\n","for dict_key in dict_train_json_folder:\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/20per/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_test = df_test.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","    for file in tqdm(glob.glob(train_json_path + dict_key + '/2~3sent/*.json')):\n","        with open(file, \"r\") as json_file:\n","            json_data = json.load(json_file)\n","            original = json_data[\"Meta(Refine)\"][\"passage\"]\n","            summary1 = json_data[\"Annotation\"][\"summary1\"]\n","            df_test = df_test.append({\"original\": original, \"summary\": summary1}, ignore_index=True)\n","len(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcES3EX58-cQ"},"outputs":[],"source":["df_test.to_pickle('/content/drive/MyDrive/Alpaco_NLP/validation/vl_news.pkl')"]},{"cell_type":"markdown","metadata":{"id":"UZVfsqwE_S3i"},"source":["# load pickle\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1672055328821,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"},"user_tz":-540},"id":"ub0dU4ixQ4n9","outputId":"e56ca583-d838-4ab8-eaec-1cb254ad706c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/jeonminjeong\r\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5gSWE9yAzqP"},"outputs":[],"source":["import pickle\n","\n","with open('/content/drive/MyDrive/mjjeon/tl_news.pkl', 'rb') as f:\n","    df_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/mjjeon/vl_news.pkl', 'rb') as f:\n","    df_test = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXkqzivYQtqn"},"outputs":[],"source":["import pickle\n","\n","with open('/content/drive/MyDrive/Alpaco_NLP/training/tl_news.pkl', 'rb') as f:\n","    df_train = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/Alpaco_NLP/validation/vl_news.pkl', 'rb') as f:\n","    df_test = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1672198496573,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"LdkhEXUgCL79","outputId":"0f94bff2-664b-4b82-f701-649f64124c37"},"outputs":[{"data":{"text/plain":["(21600, 2700)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["len(df_train), len(df_test)"]},{"cell_type":"markdown","metadata":{"id":"P-V7NqDyDkvt"},"source":["# load transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10759,"status":"ok","timestamp":1672227474270,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"q8kgClKbF3TN","outputId":"8aea2376-e89d-4156-dc55-11a5fa624d4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 26.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 82.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 105.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"Wb9SoZt9gTpu"},"source":["# 이건 안된다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18333,"status":"ok","timestamp":1672142837655,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"9_WyHaKvhXB0","outputId":"dc650acc-84dc-4c34-eac1-da60d27c7a70"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n","The class this function is called from is 'BartTokenizer'.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n","- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"]}],"source":["from transformers import BartTokenizer, TFBartForConditionalGeneration\n","import tensorflow as tf\n","\n","tokenizer = BartTokenizer.from_pretrained(\"gogamza/kobart-base-v2\", model_max_length = 256)\n","model = TFBartForConditionalGeneration.from_pretrained(\"gogamza/kobart-base-v2\", from_pt = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1094,"status":"ok","timestamp":1672142838747,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"CLArU0e7JKxK","outputId":"222655e0-0222-4b51-9025-7d8d5cdcd876"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"data":{"text/plain":["BartConfig {\n","  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n","  \"bos_token_id\": 1,\n","  \"classif_dropout\": 0.1,\n","  \"classifier_dropout\": 0.1,\n","  \"d_model\": 768,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 3072,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 1,\n","  \"do_blenderbot_90_layernorm\": false,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 3072,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"NEGATIVE\",\n","    \"1\": \"POSITIVE\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"kobart_version\": 2.0,\n","  \"label2id\": {\n","    \"NEGATIVE\": 0,\n","    \"POSITIVE\": 1\n","  },\n","  \"max_position_embeddings\": 1026,\n","  \"model_type\": \"bart\",\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 3,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 30000\n","}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AutoConfig\n","config = AutoConfig.from_pretrained(\"gogamza/kobart-base-v2\")\n","config"]},{"cell_type":"markdown","metadata":{"id":"9WGWl_K0gPo4"},"source":["# 이건된다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5032,"status":"ok","timestamp":1672198596978,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"3u7bLafAgSLv","outputId":"c35d86b1-220d-476c-bed6-774cc8b1e86e"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartForConditionalGeneration: ['model.decoder.embed_tokens.weight', 'model.encoder.embed_tokens.weight']\n","- This IS expected if you are initializing TFBartForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBartForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"]}],"source":["from transformers import PreTrainedTokenizerFast, TFBartForConditionalGeneration\n","import tensorflow as tf\n","\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"digit82/kobart-summarization\", model_max_length=256)\n","model = TFBartForConditionalGeneration.from_pretrained(\"digit82/kobart-summarization\", from_pt = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":169098,"status":"ok","timestamp":1672223693191,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"UdsH4CMzgqQN","outputId":"15e7d443-a261-4947-f12c-8e6a8e11d02e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'에도도 신이치라는 고등학생 탐정이었지만, 란과 유원지에 놀러갔다가 검은 조직의 거래 현장을 목격 후 뒤에서 오는 다른 조직원을 보지 못한 채 습격을 당했고, 그 조직원은 이상한 약을 나에게 먹였고, 경찰에 발견된 나는 초등학생으로 몸이 작아져 현재는 소년 탐정단에서 겐타, 미츠히코, 아유미와 활동하고 있고, 최근에는 하이바라 아이라는 이전 조직원 약 개발자를 만나게 되었다.'"]},"execution_count":143,"metadata":{},"output_type":"execute_result"}],"source":["\n","text = \"\"\"\n","1일 오후 9시까지 최소 20만3220명이 코로나19에 신규 확진됐다. 또다시 동시간대 최다 기록으로, 사상 처음 20만명대에 진입했다.\n","방역 당국과 서울시 등 각 지방자치단체에 따르면 이날 0시부터 오후 9시까지 전국 신규 확진자는 총 20만3220명으로 집계됐다.\n","국내 신규 확진자 수가 20만명대를 넘어선 것은 이번이 처음이다.\n","동시간대 최다 기록은 지난 23일 오후 9시 기준 16만1389명이었는데, 이를 무려 4만1831명이나 웃돌았다. 전날 같은 시간 기록한 13만3481명보다도 6만9739명 많다.\n","확진자 폭증은 3시간 전인 오후 6시 집계에서도 예견됐다.\n","오후 6시까지 최소 17만8603명이 신규 확진돼 동시간대 최다 기록(24일 13만8419명)을 갈아치운 데 이어 이미 직전 0시 기준 역대 최다 기록도 넘어섰다. 역대 최다 기록은 지난 23일 0시 기준 17만1451명이었다.\n","17개 지자체별로 보면 서울 4만6938명, 경기 6만7322명, 인천 1만985명 등 수도권이 12만5245명으로 전체의 61.6%를 차지했다. 서울과 경기는 모두 동시간대 기준 최다로, 처음으로 각각 4만명과 6만명을 넘어섰다.\n","비수도권에서는 7만7975명(38.3%)이 발생했다. 제주를 제외한 나머지 지역에서 모두 동시간대 최다를 새로 썼다.\n","부산 1만890명, 경남 9909명, 대구 6900명, 경북 6977명, 충남 5900명, 대전 5292명, 전북 5150명, 울산 5141명, 광주 5130명, 전남 4996명, 강원 4932명, 충북 3845명, 제주 1513명, 세종 1400명이다.\n","집계를 마감하는 자정까지 시간이 남아있는 만큼 2일 0시 기준으로 발표될 신규 확진자 수는 이보다 더 늘어날 수 있다. 이에 따라 최종 집계되는 확진자 수는 21만명 안팎을 기록할 수 있을 전망이다.\n","한편 전날 하루 선별진료소에서 이뤄진 검사는 70만8763건으로 검사 양성률은 40.5%다. 양성률이 40%를 넘은 것은 이번이 처음이다. 확산세가 계속 거세질 수 있다는 얘기다.\n","이날 0시 기준 신규 확진자는 13만8993명이었다. 이틀 연속 13만명대를 이어갔다.\n","\"\"\"\n","text2 = \"\"\"\n","안녕 명탐정 코난의 이야기를 시작하도록 하지. 내 이름은 에도가와 코난, 탐정이지. 나는 원래 쿠도 신이치라는 고등학생 탐정이었지만,\n","란과 유원지에 놀러갔다가 검은 조직의 거래 현장을 목격 후 뒤에서 오는 다른 조직원을 보지 못한 채 습격을 당했다.\n","그 조직원은 이상한 약을 나에게 먹였고, 경찰에 발견된 나는 초등학생으로 몸이 작아져 있었다.\n","현재는 소년 탐정단에서 겐타, 미츠히코, 아유미와 활동하고 있고, 최근에는 하이바라 아이라는 이전 조직원 약 개발자를 만나게 되었다.\n","\"\"\"\n","text = text2.replace('\\n', ' ')\n","\n","raw_input_ids = tokenizer.encode(text)\n","input_ids1 = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n","\n","summary_ids = model.generate([input_ids1],  num_beams=4,  max_length=512,  eos_token_id=1)\n","tokenizer.decode(np.array(summary_ids).squeeze().tolist(), skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672205223330,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"l1Q3spQ0KLFJ","outputId":"d455e203-051b-4ccc-92ab-a9756dbf85b3"},"outputs":[{"data":{"text/plain":["torch.Size([1, 117])"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor([input_ids1]).shape"]},{"cell_type":"markdown","metadata":{"id":"ZOdZnhxaI0ec"},"source":["# load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B1NkoCyOgRx3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ynrd9vixIW8y"},"outputs":[],"source":["X_train_list = df_train['original'].tolist()\n","X_test_list = df_test['original'].tolist()\n","y_train = df_train['summary'].tolist()\n","y_test = df_test['summary'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672120054003,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"5bJqjy7rNOHc","outputId":"e4aaf90a-10ec-47ec-dc11-f2b62971caa7"},"outputs":[{"name":"stdout","output_type":"stream","text":["256\n"]}],"source":["print(tokenizer.model_max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLvLIFYcIlxh"},"outputs":[],"source":["X_train = tokenizer(X_train_list, truncation=True, padding=True)\n","X_test = tokenizer(X_test_list, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4olUZ1VGCJ5E"},"outputs":[],"source":["Y_train = tokenizer(y_train, truncation=True, padding=True)\n","Y_test = tokenizer(y_test, truncation=True, padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSnSnfIBIoo-"},"outputs":[],"source":["X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672198638389,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"vupBqMLlIre1","outputId":"cb0deb94-15d1-4aa2-e1c6-6ba276e5481b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['▁8일', '▁인천', '▁영', '종', '도', '▁스카', '이', '72', '▁골프', '앤', '리조', '트', '▁오', '션', '▁코스', '.\\n', '▁', '▁한국', '▁여자', '프로', '골프', '(K', 'L', 'PG', 'A)', '▁투어', '▁하나금융', '그룹', '▁챔피언십', '▁최종', '▁라', '운드', '에', '▁나선', '▁선수', '▁62', '명은', '▁초', '속', '▁7', 'm', '▁찬', '바람', '을', '▁맞', '으며', '▁추', '위와', '▁싸', '웠다.\\n', '▁', '▁핀', '에', '▁꽂', '힌', '▁깃', '대는', '▁심하게', '▁흔들', '렸다.\\n', '▁', '▁선수들은', '▁두', '꺼', '운', '▁점', '퍼', '를', '▁입고', '▁벗', '기를', '▁반복', '했다.\\n', '▁', '▁세계', '▁1위', '▁고', '진', '영', '(25', ')과', '▁장', '타자', '▁김', '아', '림', '(25', ')은', '▁방한', '용', '▁귀', '마', '개', '까지', '▁착용', '했다.\\n', '▁', '▁강', '풍', '▁탓에', '▁이날', '▁언', '더', '파를', '▁기록한', '▁선수는', '▁3명', '뿐', '이었다.\\n', '▁', '▁안', '나', '린', '(25', ')은', '▁그중', '에서도', '▁가장', '▁돋보', '였다.\\n', '▁', '▁공동', '▁선두', '로', '▁출발', '한', '▁그는', '▁최종', '▁라', '운드', '에서', '▁버디', '▁2개', ',', '▁보기', '▁1', '개로', '▁1', '타를', '▁줄', '였다.\\n', '▁', '▁합', '계', '▁8', '언더파', '.\\n', '▁', '▁장', '하나', '(28', '·', '5', '언더파', ')를', '▁3', '타', '▁차로', '▁따돌', '리고', '▁우승', '했다.\\n', '▁', '▁지난달', '▁오', '텍', '캐', '리어', '▁챔피언십', '에서', '▁데뷔', '▁네', '▁시즌', ',', '▁개인', '▁통산', '▁9', '3', '번째', '▁대회', '▁만에', '▁처음', '▁우승', '했던', '▁그는', '▁4', '주', '▁만에', '▁시즌', '▁2', '승을', '▁달성', '했다.\\n', '▁', '▁이번', '▁대회는', '▁올', '▁시즌', '▁K', 'L', 'PGA', '▁투어', '▁대회', '▁중', '▁가장', '▁많은', '▁상', '금이', '▁걸렸다.\\n', '▁', '▁안', '나', '린이', '▁우승', '▁상금', '▁3', '억원을', '▁가져', '갔다.\\n', '▁', '▁상금', '▁잭', '폿', '을', '▁터뜨', '린', '▁그는', '▁시즌', '▁상금', '▁순위', '▁11', '위에서', '▁2위', '(5', '억', '95', '00만원', ')로', '▁훌쩍', '▁올라', '섰다.\\n', '▁', '▁그는', '▁“', '첫', '▁우승', '▁때', '▁받은', '▁상', '금으로', '▁아직', '▁자동차', '를', '▁못', '▁샀', '다.\\n']\n","[16635, 15058, 14126, 12191, 9866, 21737, 12034, 26814, 17041, 11725, 21215, 13328, 14075, 11300, 16125, 14023, 1700, 14188, 15439, 15786, 20080, 18497, 275, 20243, 19835, 21306, 29965, 15106, 27333, 15657, 14560, 15960, 11786, 16297, 14637, 24632, 16237, 14272, 11320, 14235, 308, 15710, 20071, 12007, 14292, 14297, 14170, 19936, 15136, 16235, 1700, 20899, 11786, 24196, 13845, 22828, 15597, 27256, 16934, 14627, 1700, 25641, 14196, 9351, 11914, 14244, 13417, 10443, 17823, 15466, 14241, 17317, 14037, 1700, 14370, 17179, 14068, 12335, 11821, 24924, 15882, 14137, 23080, 14116, 11696, 10486, 24924, 15137, 25313, 11908, 14796, 10496, 9006, 14129, 22216, 14037, 1700, 14119, 13517, 20011, 14358, 14375, 9806, 23486, 19115, 24479, 24860, 11159, 14530, 1700, 14105, 9495, 10479, 24924, 15137, 24122, 14590, 14377, 21119, 14234, 1700, 14856, 18031, 10338, 16444, 13590, 14329, 15657, 14560, 15960, 14030, 24993, 18808, 243, 17238, 14035, 19984, 14035, 18201, 14390, 14234, 1700, 14350, 9092, 14260, 27016, 14023, 1700, 14137, 17019, 27055, 373, 252, 27016, 15087, 14086, 13123, 26271, 28893, 14268, 15589, 14037, 1700, 15260, 14075, 13193, 12894, 18762, 27333, 14030, 17302, 14323, 15169, 243, 15006, 24778, 14308, 250, 16244, 15602, 15322, 14656, 15589, 14622, 14329, 14136, 12258, 15322, 15169, 14043, 17234, 16890, 14037, 1700, 14322, 28784, 14171, 15169, 14572, 275, 29408, 21306, 15602, 14059, 14377, 14467, 14066, 16273, 29271, 1700, 14105, 9495, 21520, 15589, 28549, 14086, 16084, 15950, 15290, 1700, 28549, 24380, 13476, 12007, 19285, 10479, 14329, 15169, 28549, 23659, 14460, 19161, 21231, 15701, 11764, 25678, 16266, 16272, 27615, 15189, 15704, 1700, 14329, 14128, 12679, 15589, 14089, 15141, 14066, 21195, 14974, 15527, 10443, 14200, 24811, 14024]\n"]}],"source":["print(X_train[0].tokens)\n","print(X_train[0].ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIX3s2ewI7fS"},"outputs":[],"source":["import tensorflow as tf\n","\n","# 주어진 데이터소스를 여러 Tensor로 자른 후 iterator(반복가능 객체)로 만들기\n","train_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(X_train),\n","    Y_train\n","))\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices((\n","    dict(X_test),\n","    Y_test\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGYgyM4I_VVr"},"outputs":[],"source":["train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1672202378613,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"i7c77CxyBFiB","outputId":"31da845a-b6c1-42be-a255-2463bcb6fac4"},"outputs":[{"data":{"text/plain":["<TakeDataset element_spec={'input_ids': TensorSpec(shape=(256,), dtype=tf.int64, name=None), 'decoder_input_ids': TensorSpec(shape=(256,), dtype=tf.int64, name=None), 'labels': TensorSpec(shape=(256,), dtype=tf.int64, name=None)}>"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset.take(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCe3w2kLW4f_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42227,"status":"ok","timestamp":1672222504379,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"2V9VUkcd33wb","outputId":"994b6acc-ae08-4d1e-8ca2-c57bcd14e142"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 21600/21600 [00:41<00:00, 515.51it/s]"]},{"name":"stdout","output_type":"stream","text":["21600 21600 21600\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import numpy as np\n","import torch\n","\n","\n","max_len = 256\n","pad_index = tokenizer.pad_token_id\n","ignore_index = -100\n","\n","def add_padding_data(inputs):\n","    if len(inputs) < max_len:\n","        pad = np.array([pad_index] *(max_len - len(inputs)))\n","        inputs = np.concatenate([inputs, pad])\n","    else:\n","        inputs = inputs[:max_len]\n","\n","    return inputs\n","\n","def add_ignored_data(inputs):\n","    if len(inputs) < max_len:\n","        pad = np.array([pad_index] *(max_len - len(inputs)))\n","        inputs = np.concatenate([inputs, pad])\n","    else:\n","        inputs = inputs[:max_len]\n","\n","    return inputs\n","\n","def translateData(df_train):\n","    \n","    input_ids_list, dec_input_ids_list, label_ids_list = [], [], []\n","    for idx in tqdm(range(len(df_train))):\n","        instance = df_train.iloc[idx]\n","        input_ids = tokenizer.encode(instance['original'])\n","        input_ids = add_padding_data(input_ids)\n","\n","        label_ids = tokenizer.encode(instance['summary'])\n","        label_ids.append(tokenizer.eos_token_id)\n","        dec_input_ids = [tokenizer.eos_token_id]\n","        dec_input_ids += label_ids[:-1]\n","        dec_input_ids = add_padding_data(dec_input_ids)\n","        label_ids = add_ignored_data(label_ids)\n","\n","        input_ids_list.append(input_ids)\n","        dec_input_ids_list.append(dec_input_ids)\n","        label_ids_list.append(label_ids)\n","    print(len(input_ids_list), len(dec_input_ids_list), len(label_ids_list))\n","\n","    return input_ids_list, dec_input_ids_list, label_ids_list\n","'''\n","    input_ids_tensor = torch.tensor(np.array(input_ids_list)).reshape(1, -1)\n","    decoder_input_ids_tensor = torch.tensor(np.array(dec_input_ids_list)).reshape(1, -1)\n","    labels_tensor = torch.tensor(np.array(label_ids_list)).reshape(1, -1)\n","\n","    return_dict = {'input_ids': input_ids_tensor,\n","            'decoder_input_ids': decoder_input_ids_tensor,\n","            'labels': labels_tensor}\n","\n","    return return_dict\n","'''\n","input_ids_list, dec_input_ids_list, label_ids_list = translateData(df_train)\n","\n","# train_dataset_dict['input_ids'][0], train_dataset_dict['decoder_input_ids'][0], train_dataset_dict['labels'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":533,"status":"ok","timestamp":1672222507908,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"qeMONcnEOfbd","outputId":"be606999-d893-4ad8-c7fe-18fcb6188f38"},"outputs":[{"data":{"text/plain":["(21600, 21600, 21600)"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["len(input_ids_list), len(dec_input_ids_list), len(label_ids_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":612,"status":"ok","timestamp":1672222613908,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"mtgxB7_AOqwC","outputId":"ec2bbb20-8123-405d-8daa-32d11699b1c1"},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'decoder_input_ids', 'labels'])"]},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset_dict['input_ids'] = torch.tensor(np.array(input_ids_list))\n","train_dataset_dict['decoder_input_ids'] = torch.tensor(np.array(dec_input_ids_list))\n","train_dataset_dict['labels'] = torch.tensor(np.array(label_ids_list))\n","train_dataset_dict.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1672222638835,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"2DEpbwJkPEhk","outputId":"74320e9f-938f-496b-d116-f2b30a0e2fdf"},"outputs":[{"data":{"text/plain":["torch.Size([21600, 256])"]},"execution_count":140,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset_dict['input_ids'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RR3SNtP_nzGs"},"outputs":[],"source":["with open('/content/drive/MyDrive/mjjeon/train_dataset.pickle', 'wb') as handle:\n","    pickle.dump(train_dataset_dict, handle)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1672222341323,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"4fjN724f-Z8l","outputId":"b82b1c8d-87ba-480d-d70d-2c25f63d7001"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = {}\n","train_dataset['input_ids'] = np.array(input_ids_list)\n","train_dataset['decoder_input_ids'] = np.array(dec_input_ids_list)\n","train_dataset['labels'] = np.array(label_ids_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1672143012566,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"B4GHTNyfpTZM","outputId":"dbd5e208-0e07-474d-9b86-9c87fbdbcc25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"tf_bart_for_conditional_generation\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," model (TFBartMainLayer)     multiple                  123859968 \n","                                                                 \n"," final_logits_bias (BiasLaye  multiple                 30000     \n"," r)                                                              \n","                                                                 \n","=================================================================\n","Total params: 123,889,968\n","Trainable params: 123,859,968\n","Non-trainable params: 30,000\n","_________________________________________________________________\n"]}],"source":["model.summary() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3ilqZJgpZrR"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz0Un3xxqi0D"},"outputs":[],"source":["model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_a-jd5ajyShy"},"outputs":[],"source":["list(train_dataset.take(1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1672203027447,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"JATAHPXuEASu","outputId":"0ece2e11-a1a2-47ae-f250-ec8fe2638267"},"outputs":[{"name":"stdout","output_type":"stream","text":["676\n"]}],"source":["batch_size = 32\n","steps = len(df_train) // batch_size + 1\n","print(steps)\n","adam = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1672204032846,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"y8mXHdArIJMJ","outputId":"137ac6c0-ceaa-4a12-bfa0-0aecb2c74493"},"outputs":[{"data":{"text/plain":["<TakeDataset element_spec={'input_ids': TensorSpec(shape=(256,), dtype=tf.int32, name=None), 'decoder_input_ids': TensorSpec(shape=(256,), dtype=tf.int32, name=None), 'labels': TensorSpec(shape=(256,), dtype=tf.int32, name=None)}>"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset.take(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494,"status":"ok","timestamp":1672204986261,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"V1ukGl2KGiZY","outputId":"8d9b79e1-2323-4938-cac3-d0039d25a3cc"},"outputs":[{"data":{"text/plain":["256"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["for input_ids in train_dataset.take(1):  # only take first element of dataset\n","    input_ids_one = input_ids\n","\n","t_tensor = torch.tensor(list(input_ids_one['input_ids'].numpy()))\n","len(t_tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6D14oUxQMZfm"},"outputs":[],"source":["t_tensor = t_tensor.reshape(1,-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":159572,"status":"ok","timestamp":1672205650857,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"LPfmZT4XGuZD","outputId":"3db97f4b-4ed1-45a4-81ac-c45c5f77ddd7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'8일 한국 영종도 스카이72 골프앤리조트 오션 코스에서 열린 한국 여자프로골프 투어 하나금융그룹 챔피언십 최종 라운드에 나선 선수 62명은 초속 7m 찬바람을 맞으며 초속 7m 찬바람을 맞으며 추위와 싸우고 있다.'"]},"execution_count":116,"metadata":{},"output_type":"execute_result"}],"source":["summary_ids = model.generate(t_tensor,  num_beams=4,  max_length=512,  eos_token_id=1)\n","tokenizer.decode(np.array(summary_ids).squeeze().tolist(), skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"elapsed":502,"status":"error","timestamp":1672224470792,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"kB6gzl-OD2Ut","outputId":"5363d97a-0446-47de-d63d-a192050bdfbb"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-145-fb7fbe9f20f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'TensorSliceDataset' object is not subscriptable"]}],"source":["from tqdm import tqdm\n","\n","EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  epoch_loss = 0\n","\n","  for input_ids, dec_input_ids, labels in zip(tqdm(train_dataset['input_ids']), train_dataset['decoder_input_ids'], train_dataset['labels']):\n","      with tf.GradientTape() as tape:\n","\n","        attention_mask = input_ids.ne(tokenizer.pad_token_id).float()\n","        decoder_attention_mask = dec_input_ids.ne(tokenizer.pad_token_id).float()\n","\n","        result = model(input_ids=input_ids,\n","                        attention_mask=attention_mask,\n","                        decoder_input_ids=dec_input_ids,\n","                        decoder_attention_mask=decoder_attention_mask,\n","                        labels=labels, return_dict=True)\n","        loss = result[0]\n","        batch_loss = tf.reduce_mean(loss)\n","          \n","      grads = tape.gradient(batch_loss, model.trainable_variables)\n","      adam.apply_gradients(zip(grads, model.trainable_variables))\n","      epoch_loss += batch_loss / steps\n","\n","  print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, epoch_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":527,"status":"error","timestamp":1672224612328,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"s52bhUVCW63e","outputId":"0649eddc-8041-4cac-d550-724dda3deb07"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-146-24172e46ec33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     save_best_only=True)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"]}],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","callback_earlystop = EarlyStopping(\n","    monitor=\"val_accuracy\", \n","    min_delta=0.001,\n","    patience=2)\n","checkpoint_filepath = '/content/drive/MyDrive/mjjeon/weights2/'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    save_best_only=True)\n","\n","model.fit(\n","    train_dataset.shuffle(10000).batch(32), epochs=1, batch_size=32,\n","    validation_data = val_dataset.shuffle(10000).batch(32),\n","    callbacks = [callback_earlystop, model_checkpoint_callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"elapsed":4,"status":"error","timestamp":1672201702999,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"C01Ryx_eqlTO","outputId":"5461a8a0-6c79-4de2-a26d-bfdc887702a0"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-e0a89a15b0a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     save_best_only=True)\n\u001b[0;32m---> 13\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/polymorphism/function_cache.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/core/function/trace_type/default_types.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot generate a hashable key for IteratorSpec(({'input_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 256), dtype=tf.int32, name=None)}, {'input_ids': TensorSpec(shape=(None, 60), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 60), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 60), dtype=tf.int32, name=None)}),) because the _serialize() method returned an unsupproted value of type <class 'transformers.tokenization_utils_base.BatchEncoding'>"]}],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","callback_earlystop = EarlyStopping(\n","    monitor=\"val_accuracy\", \n","    min_delta=0.001,\n","    patience=2)\n","checkpoint_filepath = '/content/drive/MyDrive/mjjeon'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    save_best_only=True)\n","model.fit(\n","    train_dataset.shuffle(10000).batch(32), epochs=1, batch_size=32,\n","    validation_data = val_dataset.shuffle(10000).batch(32),\n","    callbacks = [callback_earlystop, model_checkpoint_callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HHhj2SiBi3_r"},"outputs":[],"source":["model.save_weights('/content/drive/MyDrive/mjjeon/weights/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"executionInfo":{"elapsed":999,"status":"error","timestamp":1672177400320,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"qcGEM9k7iL02","outputId":"9eeba23f-1574-4b5c-97ff-ce17b32ccbf1"},"outputs":[{"ename":"NotImplementedError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-568a588d7b7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/mjjeon/v2_saveformat.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    140\u001b[0m     if (not model._is_graph_network and  # pylint:disable=protected-access\n\u001b[1;32m    141\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[0;32m--> 142\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    143\u001b[0m           \u001b[0;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m           \u001b[0;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."]}],"source":["model.save('/content/drive/MyDrive/mjjeon/v2_saveformat.h5',save_format='tf')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5427,"status":"ok","timestamp":1672114661353,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"f7v3snObq9Tb","outputId":"97ce55e4-0997-4562-c359-28149d2d3278"},"outputs":[{"name":"stderr","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n","The class this function is called from is 'BartTokenizer'.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBartModel: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n","- This IS expected if you are initializing TFBartModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBartModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBartModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartModel for predictions without further training.\n"]}],"source":["from transformers import BartTokenizer, TFBartModel\n","import tensorflow as tf\n","\n","tokenizer = BartTokenizer.from_pretrained(\"gogamza/kobart-base-v2\")\n","model = TFBartModel.from_pretrained(\"gogamza/kobart-base-v2\", from_pt = True)\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n","outputs = model(inputs)\n","\n","last_hidden_states = outputs.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1672114692082,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"9QrGi8lFzJSu","outputId":"423293e5-9602-4c1a-ce1b-840236469204"},"outputs":[{"data":{"text/plain":["{'input_ids': <tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n","array([[    0,   271, 16997, 20858,   243,   461,   308,   320,   461,\n","          299, 25873,   461, 15868,   461,   298, 23124,   300,     1]],\n","      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n","      dtype=int32)>}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6033,"status":"ok","timestamp":1672188494260,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"YL5DvJAEzP_M","outputId":"21a148f2-7d2b-408c-c119-616359d46d13"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 20), dtype=int32, numpy=\n","array([[  1,   0, 416,   5,   5, 415,   5,   5, 461,   5,   5, 461, 416,\n","          5,   5, 416,   5,   5, 461,   1]], dtype=int32)>"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["ARTICLE_TO_SUMMARIZE = (\n","    \"안녕하세요 오늘 아침을 책임질 7시 기상 알람입니다. 저는 매일 7시에 알람이 맞춰져 있으며 사용자마다 커스텀이 가능합니다.\"\n","    \"명탐정 코난은 뛰어난 애니메이션입니다. 28년동안 코난은 어린아이의 몸에 갖혀져 있으면서 기술은 진보하는 것을 보고 있었기 때문입니다.\"\n",")\n","inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\", truncation=True)\n","\n","# Generate Summary\n","summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)\n","# tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","summary_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1672188849027,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"q0qTPWFDOD-c","outputId":"c656c3b9-9748-42b7-df3e-b5e0a4d678c8"},"outputs":[{"data":{"text/plain":["{'vocab_file': 'vocab.json', 'merges_file': 'merges.txt'}"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.vocab_files_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MViAEpsROyZx"},"outputs":[],"source":["dic_vocab = tokenizer.get_vocab()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBEC79ZKO_og"},"outputs":[],"source":["dic_index = {v:k for k, v in dic_vocab.items()}\n","dic_index"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1672189151985,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"v4h4-588PXac","outputId":"c6867a49-9683-4184-979f-1d3262486fc7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'ë'"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["dic_index[415]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1672191750588,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"0SfHEiqJY-1H","outputId":"f6d250c5-43d4-4ad0-f2ef-d6aff17f72df"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'</s><s>ì<unk><unk>ë<unk><unk>Ġ<unk><unk>Ġì<unk><unk>ì<unk><unk>Ġ</s>'"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","''.join([dic_index[i] for i in np.array(summary_ids[0])])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":723,"status":"ok","timestamp":1672188988253,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"6kO68raFNiPi","outputId":"6e4bf286-0b2f-45ed-cde2-2038851087de"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'�'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["text = tokenizer.decode(415)\n","text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1105,"status":"ok","timestamp":1672188653844,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"QIau9AoRNcD0","outputId":"f9c11fd5-bb53-4c18-cc55-5176a8e375b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['��  �� ']\n"]}],"source":["# summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n","print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dNUXU2nky7m"},"outputs":[],"source":["inputs = tokenizer(\"안녕하세요 오늘 아침을 책임질 7시 기상 알람입니다. 저는 매일 7시에 알람이 맞춰져 있으며 사용자마다 커스텀이 가능합니다.\", return_tensors=\"tf\")\n","outputs = model(inputs)\n","outputs.decoder_hidden_states"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1631,"status":"ok","timestamp":1672178299114,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"3gbVmG8BlPOW","outputId":"25960993-68bf-48b5-e88f-7239a4c7b639"},"outputs":[{"name":"stdout","output_type":"stream","text":["['�']\n"]}],"source":["ARTICLE_TO_SUMMARIZE = \"안녕하세요 오늘 아침을 책임질 7시 기상 알람입니다. 저는 매일 7시에 알람이 맞춰져 있으며 사용자마다 커스텀이 가능합니다.\"\n","inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"tf\")\n","\n","# Generate Summary\n","summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=5)\n","print(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":771,"status":"error","timestamp":1672184388554,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"PbPER7tal-gi","outputId":"ab9b7a8d-a805-4ed1-fe9a-ee20b7e41f31"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-d34107004362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"안녕하세요 저는 000입니다. 반갑습니다. 저는 이것을 좋아하고 저것을 싫어합니다. 저희 취미는 이것이며 앞으로의 계획은 이렇습니다.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36minput_processing\u001b[0;34m(func, config, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data of type {type(v)} is not allowed only {allowed_types} is accepted for {k}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmain_input\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"tf_bart_for_conditional_generation\" (type TFBartForConditionalGeneration).\n\nData of type <class 'torch.Tensor'> is not allowed only (<class 'tensorflow.python.framework.ops.Tensor'>, <class 'bool'>, <class 'int'>, <class 'transformers.utils.generic.ModelOutput'>, <class 'tuple'>, <class 'list'>, <class 'dict'>, <class 'numpy.ndarray'>, <class 'tensorflow.python.keras.engine.keras_tensor.KerasTensor'>) is accepted for input_ids.\n\nCall arguments received by layer \"tf_bart_for_conditional_generation\" (type TFBartForConditionalGeneration):\n  • input_ids={'input_ids': 'tensor([[    0,   416,   473,     5,   415,   465,   473,   417,   473,   476,\\n           416,   464,     5,   416,     5,     5,   461,   416,   480,     5,\\n           415,     5,     5,   461, 14474,   416,     5,   465,   415,   468,\\n             5,   415,   468,   361,   245,   461,   415,   370,   476,   414,\\n           370,     5,   416,     5,     5,   415,   468,     5,   415,   468,\\n           361,   245,   461,   416,   480,     5,   415,     5,     5,   461,\\n           416,     5,     5,   414,     5,   463,   416,     5,   464,   461,\\n           416,   359,   468,   416,   473,   464,   417,   473,   476,   414,\\n             5,   480,   461,   416,   480,     5,   414,     5,   463,   416,\\n             5,   464,   461,   416,   468,   366,   416,   474,     5,   417,\\n           473,   365,   415,   468,     5,   415,   468,   361,   245,   461,\\n           416,   480,     5,   417,     5,   367,   461,   416,   373,     5,\\n           415,     5,     5,   415,     5,     5,   461,   416,     5,     5,\\n           414,     5,   463,   416,     5,     5,   415,   365,   370,   461,\\n           416,   473,     5,   416,   478,     5,   415,   358,   478,   416,\\n             5,   476,   461,   414,     5,   464,   417,     5,     5,   416,\\n             5,     5,   461,   416,     5,     5,   415,   480,   466,   416,\\n             5,     5,   415,   468,     5,   415,   468,   361,   245,     1]])', 'attention_mask': 'tensor...\n  • attention_mask=None\n  • decoder_input_ids=None\n  • decoder_attention_mask=None\n  • decoder_position_ids=None\n  • head_mask=None\n  • decoder_head_mask=None\n  • cross_attn_head_mask=None\n  • encoder_outputs=None\n  • past_key_values=None\n  • inputs_embeds=None\n  • decoder_inputs_embeds=None\n  • use_cache=None\n  • output_attentions=None\n  • output_hidden_states=None\n  • return_dict=None\n  • labels=None\n  • training=False"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L4fLCdPNmGV9"},"outputs":[],"source":["last_hidden_states"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":611,"status":"ok","timestamp":1672192151079,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"bMPBT7Jnaua-","outputId":"ab1e6a2b-1364-4dd0-a38b-a20e6b2248cc"},"outputs":[{"data":{"text/plain":["array([  1,   0, 416,   5,   5, 415,   5,   5, 461,   5,   5, 461, 416,\n","         5,   5, 416,   5,   5, 461,   1], dtype=int32)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["np.array(summary_ids[0]).squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bk4Ikz-WabkA"},"outputs":[],"source":["import torch\n","\n","text = \"\"\"\n","1일 오후 9시까지 최소 20만3220명이 코로나19에 신규 확진됐다. 또다시 동시간대 최다 기록으로, 사상 처음 20만명대에 진입했다.\n","방역 당국과 서울시 등 각 지방자치단체에 따르면 이날 0시부터 오후 9시까지 전국 신규 확진자는 총 20만3220명으로 집계됐다.\n","국내 신규 확진자 수가 20만명대를 넘어선 것은 이번이 처음이다.\n","동시간대 최다 기록은 지난 23일 오후 9시 기준 16만1389명이었는데, 이를 무려 4만1831명이나 웃돌았다. 전날 같은 시간 기록한 13만3481명보다도 6만9739명 많다.\n","확진자 폭증은 3시간 전인 오후 6시 집계에서도 예견됐다.\n","오후 6시까지 최소 17만8603명이 신규 확진돼 동시간대 최다 기록(24일 13만8419명)을 갈아치운 데 이어 이미 직전 0시 기준 역대 최다 기록도 넘어섰다. 역대 최다 기록은 지난 23일 0시 기준 17만1451명이었다.\n","17개 지자체별로 보면 서울 4만6938명, 경기 6만7322명, 인천 1만985명 등 수도권이 12만5245명으로 전체의 61.6%를 차지했다. 서울과 경기는 모두 동시간대 기준 최다로, 처음으로 각각 4만명과 6만명을 넘어섰다.\n","비수도권에서는 7만7975명(38.3%)이 발생했다. 제주를 제외한 나머지 지역에서 모두 동시간대 최다를 새로 썼다.\n","부산 1만890명, 경남 9909명, 대구 6900명, 경북 6977명, 충남 5900명, 대전 5292명, 전북 5150명, 울산 5141명, 광주 5130명, 전남 4996명, 강원 4932명, 충북 3845명, 제주 1513명, 세종 1400명이다.\n","집계를 마감하는 자정까지 시간이 남아있는 만큼 2일 0시 기준으로 발표될 신규 확진자 수는 이보다 더 늘어날 수 있다. 이에 따라 최종 집계되는 확진자 수는 21만명 안팎을 기록할 수 있을 전망이다.\n","한편 전날 하루 선별진료소에서 이뤄진 검사는 70만8763건으로 검사 양성률은 40.5%다. 양성률이 40%를 넘은 것은 이번이 처음이다. 확산세가 계속 거세질 수 있다는 얘기다.\n","이날 0시 기준 신규 확진자는 13만8993명이었다. 이틀 연속 13만명대를 이어갔다.\n","\"\"\"\n","\n","text = text.replace('\\n', ' ')\n","\n","raw_input_ids = tokenizer.encode(text)\n","input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n","\n","# summary_ids = model.generate(torch.tensor([input_ids]),  num_beams=4,  max_length=512,  eos_token_id=1)\n","d = tokenizer.decode(np.array(summary_ids[0]).squeeze().tolist(), skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1672192537304,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"gdUWG3D1cSaP","outputId":"063b1515-45aa-49f1-ec05-28a4bc2af6d4"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'��  �� '"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(np.array(summary_ids[0]).squeeze().tolist(), skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":832,"status":"ok","timestamp":1672192448575,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"_fdgWF3VbsDS","outputId":"a4ba161f-939a-4e61-97c1-790241946f9f"},"outputs":[{"data":{"text/plain":["[1, 0, 416, 5, 5, 415, 5, 5, 461, 5, 5, 461, 416, 5, 5, 416, 5, 5, 461, 1]"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["np.array(summary_ids[0]).squeeze().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1341,"status":"ok","timestamp":1672192501386,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"s0ha0Sfbb-R7","outputId":"80b2db89-5c92-49e9-fadc-265c027b8d9c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'</s><s>ì<unk><unk>ë<unk><unk>Ġ<unk><unk>Ġì<unk><unk>ì<unk><unk>Ġ</s>'"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["ans = ''\n","for idx in np.array(summary_ids[0]).squeeze().tolist(): \n","  ans += dic_index[idx]\n","ans"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":824,"status":"ok","timestamp":1672192402368,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"Yn17Lfcgae6A","outputId":"fdeff552-6f54-4206-aee0-371b0f0cf779"},"outputs":[{"data":{"text/plain":["b'\\xef\\xbf\\xbd\\xef\\xbf\\xbd  \\xef\\xbf\\xbd\\xef\\xbf\\xbd '"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["decoded_value = d.encode()\n","decoded_value"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1672192404949,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"xCWKlyUkbLES","outputId":"66764668-e263-4801-da63-06c21ea8d6eb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'占쏙옙  占쏙옙 '"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["decoded_value.decode('cp949')"]},{"cell_type":"markdown","metadata":{"id":"9PEjAmRtbQTY"},"source":["# 세 번째야"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5235,"status":"ok","timestamp":1672225216510,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"LJy0h-WVYlLm","outputId":"a42fc894-8e55-41b0-b101-44ee92000f71"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/mjjeon\n","/content/drive/MyDrive/mjjeon\n","Cloning into 'KoBART-summarization'...\n","remote: Enumerating objects: 142, done.\u001b[K\n","remote: Counting objects: 100% (59/59), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 142 (delta 46), reused 37 (delta 37), pack-reused 83\u001b[K\n","Receiving objects: 100% (142/142), 37.23 MiB | 20.55 MiB/s, done.\n","Resolving deltas: 100% (76/76), done.\n"]}],"source":["# git clone\n","%cd /content/drive/MyDrive/mjjeon\n","!pwd\n","!git clone https://github.com/seujung/KoBART-summarization.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1672227429719,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"QO9LW3ZWYn6a","outputId":"180d47bd-66cd-4936-b89d-34841a113376"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 21600/21600 [00:01<00:00, 21595.31it/s]\n"]}],"source":["# save data to tsv file\n","import csv\n","from tqdm import tqdm\n","\n","with open('/content/drive/MyDrive/mjjeon/KoBART-summarization/data/train.tsv', 'w', encoding='utf-8', newline='') as f:\n","    tw = csv.DictWriter(f, fieldnames = [\"news\", \"summary\"], delimiter='\\t')\n","    tw.writeheader()\n","    for original, summary in zip(tqdm(df_train['original']), df_train['summary']):\n","        tw.writerow({'news': original.replace('\\n', ' '), 'summary': summary.replace('\\n', ' ')})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":618,"status":"ok","timestamp":1672227430334,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"VmWvuMksbE58","outputId":"4c1137e3-bdca-4d36-b285-4221a04256da"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2700/2700 [00:00<00:00, 21708.82it/s]\n"]}],"source":["with open('/content/drive/MyDrive/mjjeon/KoBART-summarization/data/test.tsv', 'w', encoding='utf-8', newline='') as f:\n","    tw = csv.DictWriter(f, fieldnames = [\"news\", \"summary\"], delimiter='\\t')\n","    tw.writeheader()\n","    for original, summary in zip(tqdm(df_test['original']), df_test['summary']):\n","        tw.writerow({'news': original.replace('\\n', ' '), 'summary': summary.replace('\\n', ' ')})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1672227432676,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"-a5yVhBpYq9F","outputId":"685b6685-751c-46b6-94cf-444170ee6269"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# train.py\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1672227435753,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"eRc0j2IoanZy","outputId":"fe477799-80ff-4d9a-d48b-6684a7030eb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/mjjeon/KoBART-summarization\n"]}],"source":["%cd /content/drive/MyDrive/mjjeon/KoBART-summarization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6775,"status":"ok","timestamp":1672227443904,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"fsMzjsm3dLAQ","outputId":"2c2dcb3f-bd03-4520-b7fb-a927c26308d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n","\u001b[K     |████████████████████████████████| 800 kB 9.7 MB/s \n","\u001b[?25hCollecting tensorboardX>=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 83.9 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 90.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.0+cu116)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n","Collecting lightning-utilities!=0.4.0,>=0.3.0\n","  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.23.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n","Installing collected packages: torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n","Successfully installed lightning-utilities-0.5.0 pytorch-lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"]}],"source":["!pip install pytorch-lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"LzIXsrBIaqZX","outputId":"3f966dc5-8c10-4a5a-ed37-a5e4f978301d"},"outputs":[{"name":"stdout","output_type":"stream","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","INFO:root:Namespace(accelerator=None, accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, batch_size=8, benchmark=None, check_val_every_n_epoch=1, checkpoint_path=None, default_root_dir='logs', detect_anomaly=False, deterministic=None, devices=None, enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, fast_dev_run=False, gpus=1, gradient_clip_algorithm=None, gradient_clip_val=1.0, inference_mode=True, ipus=None, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, logger=True, lr=3e-05, max_epochs=50, max_len=512, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, model_path=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, num_workers=4, overfit_batches=0.0, plugins=None, precision=32, profiler=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, resume_from_checkpoint=None, strategy=None, sync_batchnorm=False, test_file='data/test.tsv', tpu_cores=None, track_grad_norm=-1, train_file='data/train.tsv', val_check_interval=None, warmup_ratio=0.1)\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n","  rank_zero_deprecation(\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /content/drive/MyDrive/mjjeon/KoBART-summarization/logs exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","INFO:root:number of workers 4, data length 2700\n","INFO:root:num_train_steps : 4218\n","INFO:root:num_warmup_steps : 421\n","\n","  | Name  | Type                         | Params\n","-------------------------------------------------------\n","0 | model | BartForConditionalGeneration | 123 M \n","-------------------------------------------------------\n","123 M     Trainable params\n","0         Non-trainable params\n","123 M     Total params\n","495.440   Total estimated model params size (MB)\n","Epoch 0:  89% 2700/3038 [51:05<06:23,  1.14s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  89% 2701/3038 [51:05<06:22,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2702/3038 [51:05<06:21,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2703/3038 [51:06<06:20,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2704/3038 [51:06<06:18,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2705/3038 [51:07<06:17,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2706/3038 [51:07<06:16,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2707/3038 [51:07<06:15,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2708/3038 [51:08<06:13,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2709/3038 [51:08<06:12,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2710/3038 [51:09<06:11,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2711/3038 [51:09<06:10,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2712/3038 [51:09<06:09,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2713/3038 [51:10<06:07,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2714/3038 [51:10<06:06,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2715/3038 [51:11<06:05,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2716/3038 [51:11<06:04,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2717/3038 [51:11<06:02,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2718/3038 [51:12<06:01,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  89% 2719/3038 [51:12<06:00,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2720/3038 [51:13<05:59,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2721/3038 [51:13<05:58,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2722/3038 [51:13<05:56,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2723/3038 [51:14<05:55,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2724/3038 [51:14<05:54,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2725/3038 [51:14<05:53,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2726/3038 [51:15<05:51,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2727/3038 [51:15<05:50,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2728/3038 [51:16<05:49,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2729/3038 [51:16<05:48,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2730/3038 [51:16<05:47,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2731/3038 [51:17<05:45,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2732/3038 [51:17<05:44,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2733/3038 [51:18<05:43,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2734/3038 [51:18<05:42,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2735/3038 [51:18<05:41,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2736/3038 [51:19<05:39,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2737/3038 [51:19<05:38,  1.13s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2738/3038 [51:20<05:37,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2739/3038 [51:20<05:36,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2740/3038 [51:20<05:35,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2741/3038 [51:21<05:33,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2742/3038 [51:21<05:32,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2743/3038 [51:22<05:31,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2744/3038 [51:22<05:30,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2745/3038 [51:22<05:29,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2746/3038 [51:23<05:27,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2747/3038 [51:23<05:26,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2748/3038 [51:24<05:25,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  90% 2749/3038 [51:24<05:24,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2750/3038 [51:24<05:23,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2751/3038 [51:25<05:21,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2752/3038 [51:25<05:20,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2753/3038 [51:26<05:19,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2754/3038 [51:26<05:18,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2755/3038 [51:26<05:17,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2756/3038 [51:27<05:15,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2757/3038 [51:27<05:14,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2758/3038 [51:28<05:13,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2759/3038 [51:28<05:12,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2760/3038 [51:28<05:11,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2761/3038 [51:29<05:09,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2762/3038 [51:29<05:08,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2763/3038 [51:30<05:07,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2764/3038 [51:30<05:06,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2765/3038 [51:30<05:05,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2766/3038 [51:31<05:03,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2767/3038 [51:31<05:02,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2768/3038 [51:32<05:01,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2769/3038 [51:32<05:00,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2770/3038 [51:32<04:59,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2771/3038 [51:33<04:58,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2772/3038 [51:33<04:56,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2773/3038 [51:33<04:55,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2774/3038 [51:34<04:54,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2775/3038 [51:34<04:53,  1.12s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2776/3038 [51:35<04:52,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2777/3038 [51:35<04:50,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2778/3038 [51:35<04:49,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  91% 2779/3038 [51:36<04:48,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2780/3038 [51:36<04:47,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2781/3038 [51:37<04:46,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2782/3038 [51:37<04:45,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2783/3038 [51:37<04:43,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2784/3038 [51:38<04:42,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2785/3038 [51:38<04:41,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2786/3038 [51:39<04:40,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2787/3038 [51:39<04:39,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2788/3038 [51:39<04:37,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2789/3038 [51:40<04:36,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2790/3038 [51:40<04:35,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2791/3038 [51:41<04:34,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2792/3038 [51:41<04:33,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2793/3038 [51:41<04:32,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2794/3038 [51:42<04:30,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2795/3038 [51:42<04:29,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2796/3038 [51:43<04:28,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2797/3038 [51:43<04:27,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2798/3038 [51:43<04:26,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2799/3038 [51:44<04:25,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2800/3038 [51:44<04:23,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2801/3038 [51:45<04:22,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2802/3038 [51:45<04:21,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2803/3038 [51:45<04:20,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2804/3038 [51:46<04:19,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2805/3038 [51:46<04:18,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2806/3038 [51:47<04:16,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2807/3038 [51:47<04:15,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2808/3038 [51:47<04:14,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2809/3038 [51:48<04:13,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  92% 2810/3038 [51:48<04:12,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2811/3038 [51:49<04:11,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2812/3038 [51:49<04:09,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2813/3038 [51:49<04:08,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2814/3038 [51:50<04:07,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2815/3038 [51:50<04:06,  1.11s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2816/3038 [51:50<04:05,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2817/3038 [51:51<04:04,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2818/3038 [51:51<04:02,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2819/3038 [51:52<04:01,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2820/3038 [51:52<04:00,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2821/3038 [51:52<03:59,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2822/3038 [51:53<03:58,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2823/3038 [51:53<03:57,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2824/3038 [51:54<03:55,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2825/3038 [51:54<03:54,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2826/3038 [51:54<03:53,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2827/3038 [51:55<03:52,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2828/3038 [51:55<03:51,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2829/3038 [51:56<03:50,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2830/3038 [51:56<03:49,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2831/3038 [51:56<03:47,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2832/3038 [51:57<03:46,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2833/3038 [51:57<03:45,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2834/3038 [51:58<03:44,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2835/3038 [51:58<03:43,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2836/3038 [51:58<03:42,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2837/3038 [51:59<03:41,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2838/3038 [51:59<03:39,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2839/3038 [52:00<03:38,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  93% 2840/3038 [52:00<03:37,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2841/3038 [52:00<03:36,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2842/3038 [52:01<03:35,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2843/3038 [52:01<03:34,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2844/3038 [52:02<03:32,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2845/3038 [52:02<03:31,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2846/3038 [52:02<03:30,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2847/3038 [52:03<03:29,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2848/3038 [52:03<03:28,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2849/3038 [52:04<03:27,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2850/3038 [52:04<03:26,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2851/3038 [52:04<03:24,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2852/3038 [52:05<03:23,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2853/3038 [52:05<03:22,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2854/3038 [52:06<03:21,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2855/3038 [52:06<03:20,  1.10s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2856/3038 [52:06<03:19,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2857/3038 [52:07<03:18,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2858/3038 [52:07<03:16,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2859/3038 [52:08<03:15,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2860/3038 [52:08<03:14,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2861/3038 [52:08<03:13,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2862/3038 [52:09<03:12,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2863/3038 [52:09<03:11,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2864/3038 [52:10<03:10,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2865/3038 [52:10<03:09,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2866/3038 [52:10<03:07,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2867/3038 [52:11<03:06,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2868/3038 [52:11<03:05,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2869/3038 [52:12<03:04,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  94% 2870/3038 [52:12<03:03,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2871/3038 [52:12<03:02,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2872/3038 [52:13<03:01,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2873/3038 [52:13<02:59,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2874/3038 [52:14<02:58,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2875/3038 [52:14<02:57,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2876/3038 [52:14<02:56,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2877/3038 [52:15<02:55,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2878/3038 [52:15<02:54,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2879/3038 [52:15<02:53,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2880/3038 [52:16<02:52,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2881/3038 [52:16<02:50,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2882/3038 [52:17<02:49,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2883/3038 [52:17<02:48,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2884/3038 [52:17<02:47,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2885/3038 [52:18<02:46,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2886/3038 [52:18<02:45,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2887/3038 [52:19<02:44,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2888/3038 [52:19<02:43,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2889/3038 [52:19<02:41,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2890/3038 [52:20<02:40,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2891/3038 [52:20<02:39,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2892/3038 [52:21<02:38,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2893/3038 [52:21<02:37,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2894/3038 [52:21<02:36,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2895/3038 [52:22<02:35,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2896/3038 [52:22<02:34,  1.09s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2897/3038 [52:23<02:32,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2898/3038 [52:23<02:31,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2899/3038 [52:23<02:30,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2900/3038 [52:24<02:29,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  95% 2901/3038 [52:24<02:28,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2902/3038 [52:25<02:27,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2903/3038 [52:25<02:26,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2904/3038 [52:25<02:25,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2905/3038 [52:26<02:24,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2906/3038 [52:26<02:22,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2907/3038 [52:27<02:21,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2908/3038 [52:27<02:20,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2909/3038 [52:27<02:19,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2910/3038 [52:28<02:18,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2911/3038 [52:28<02:17,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2912/3038 [52:29<02:16,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2913/3038 [52:29<02:15,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2914/3038 [52:29<02:14,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2915/3038 [52:30<02:12,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2916/3038 [52:30<02:11,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2917/3038 [52:31<02:10,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2918/3038 [52:31<02:09,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2919/3038 [52:31<02:08,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2920/3038 [52:32<02:07,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2921/3038 [52:32<02:06,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2922/3038 [52:33<02:05,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2923/3038 [52:33<02:04,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2924/3038 [52:33<02:02,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2925/3038 [52:34<02:01,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2926/3038 [52:34<02:00,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2927/3038 [52:35<01:59,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2928/3038 [52:35<01:58,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2929/3038 [52:35<01:57,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2930/3038 [52:36<01:56,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  96% 2931/3038 [52:36<01:55,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2932/3038 [52:37<01:54,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2933/3038 [52:37<01:53,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2934/3038 [52:37<01:51,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2935/3038 [52:38<01:50,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2936/3038 [52:38<01:49,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2937/3038 [52:39<01:48,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2938/3038 [52:39<01:47,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2939/3038 [52:39<01:46,  1.08s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2940/3038 [52:40<01:45,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2941/3038 [52:40<01:44,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2942/3038 [52:41<01:43,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2943/3038 [52:41<01:42,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2944/3038 [52:41<01:40,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2945/3038 [52:42<01:39,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2946/3038 [52:42<01:38,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2947/3038 [52:43<01:37,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2948/3038 [52:43<01:36,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2949/3038 [52:43<01:35,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2950/3038 [52:44<01:34,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2951/3038 [52:44<01:33,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2952/3038 [52:45<01:32,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2953/3038 [52:45<01:31,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2954/3038 [52:45<01:30,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2955/3038 [52:46<01:28,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2956/3038 [52:46<01:27,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2957/3038 [52:47<01:26,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2958/3038 [52:47<01:25,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2959/3038 [52:47<01:24,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2960/3038 [52:48<01:23,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2961/3038 [52:48<01:22,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  97% 2962/3038 [52:49<01:21,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2963/3038 [52:49<01:20,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2964/3038 [52:49<01:19,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2965/3038 [52:50<01:18,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2966/3038 [52:50<01:16,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2967/3038 [52:50<01:15,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2968/3038 [52:51<01:14,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2969/3038 [52:51<01:13,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2970/3038 [52:52<01:12,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2971/3038 [52:52<01:11,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2972/3038 [52:52<01:10,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2973/3038 [52:53<01:09,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2974/3038 [52:53<01:08,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2975/3038 [52:54<01:07,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2976/3038 [52:54<01:06,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2977/3038 [52:54<01:05,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2978/3038 [52:55<01:03,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2979/3038 [52:55<01:02,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2980/3038 [52:56<01:01,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2981/3038 [52:56<01:00,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2982/3038 [52:56<00:59,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2983/3038 [52:57<00:58,  1.07s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2984/3038 [52:57<00:57,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2985/3038 [52:58<00:56,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2986/3038 [52:58<00:55,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2987/3038 [52:58<00:54,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2988/3038 [52:59<00:53,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2989/3038 [52:59<00:52,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2990/3038 [53:00<00:51,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2991/3038 [53:00<00:49,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  98% 2992/3038 [53:00<00:48,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2993/3038 [53:01<00:47,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2994/3038 [53:01<00:46,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2995/3038 [53:02<00:45,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2996/3038 [53:02<00:44,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2997/3038 [53:02<00:43,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2998/3038 [53:03<00:42,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 2999/3038 [53:03<00:41,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3000/3038 [53:04<00:40,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3001/3038 [53:04<00:39,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3002/3038 [53:04<00:38,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3003/3038 [53:05<00:37,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3004/3038 [53:05<00:36,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3005/3038 [53:06<00:34,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3006/3038 [53:06<00:33,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3007/3038 [53:06<00:32,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3008/3038 [53:07<00:31,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3009/3038 [53:07<00:30,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3010/3038 [53:07<00:29,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3011/3038 [53:08<00:28,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3012/3038 [53:08<00:27,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3013/3038 [53:09<00:26,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3014/3038 [53:09<00:25,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3015/3038 [53:09<00:24,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3016/3038 [53:10<00:23,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3017/3038 [53:10<00:22,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3018/3038 [53:11<00:21,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3019/3038 [53:11<00:20,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3020/3038 [53:11<00:19,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3021/3038 [53:12<00:17,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0:  99% 3022/3038 [53:12<00:16,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3023/3038 [53:13<00:15,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3024/3038 [53:13<00:14,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3025/3038 [53:13<00:13,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3026/3038 [53:14<00:12,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3027/3038 [53:14<00:11,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3028/3038 [53:15<00:10,  1.06s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3029/3038 [53:15<00:09,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3030/3038 [53:15<00:08,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3031/3038 [53:16<00:07,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3032/3038 [53:16<00:06,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3033/3038 [53:17<00:05,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3034/3038 [53:17<00:04,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3035/3038 [53:17<00:03,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3036/3038 [53:18<00:02,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3037/3038 [53:18<00:01,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630]\n","Epoch 0: 100% 3038/3038 [53:19<00:00,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630, val_loss=1.620]\n","Epoch 0: 100% 3038/3038 [53:19<00:00,  1.05s/it, loss=1.58, v_num=5, train_loss=1.630, val_loss=1.620]Epoch 0, global step 2700: 'val_loss' reached 1.61636 (best 1.61636), saving model to '/content/drive/MyDrive/mjjeon/KoBART-summarization/logs/model_chp/epoch=00-val_loss=1.616.ckpt' as top 3\n","tcmalloc: large alloc 1075757056 bytes == 0x93a62000 @  0x7f8e3d697615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f8dfb1e85fe 0x7f8dd47eec85 0x7f8dd47e91e7 0x7f8dd47f0309 0x7f8dfb1fb0bb 0x7f8dfadfb6af 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","tcmalloc: large alloc 1344700416 bytes == 0xd454e000 @  0x7f8e3d697615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f8dfb1e85fe 0x7f8dd47eec85 0x7f8dd47e91e7 0x7f8dd47f0309 0x7f8dfb1fb0bb 0x7f8dfadfb6af 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","tcmalloc: large alloc 1680875520 bytes == 0x1354be000 @  0x7f8e3d697615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f8dfb1e85fe 0x7f8dd47eec85 0x7f8dd47e91e7 0x7f8dd47f0309 0x7f8dfb1fb0bb 0x7f8dfadfb6af 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","tcmalloc: large alloc 1680875520 bytes == 0x1354be000 @  0x7f8e3d697615 0x5d6f4c 0x51edd1 0x51ef5b 0x5aac95 0x5d8506 0x7f8dfb1e85fe 0x7f8dd47eec85 0x7f8dd47e91e7 0x7f8dd47f0309 0x7f8dfb1fb0bb 0x7f8dfadfb6af 0x5d80be 0x5d8d8c 0x4fedd4 0x4997c7 0x55d078 0x5d8941 0x4990ca 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","Epoch 1:  89% 2700/3038 [51:28<06:26,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  89% 2701/3038 [51:28<06:25,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2702/3038 [51:29<06:24,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2703/3038 [51:29<06:22,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2704/3038 [51:29<06:21,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2705/3038 [51:30<06:20,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2706/3038 [51:30<06:19,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2707/3038 [51:31<06:17,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2708/3038 [51:31<06:16,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2709/3038 [51:31<06:15,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2710/3038 [51:32<06:14,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2711/3038 [51:32<06:13,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2712/3038 [51:33<06:11,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2713/3038 [51:33<06:10,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2714/3038 [51:33<06:09,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2715/3038 [51:34<06:08,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2716/3038 [51:34<06:06,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2717/3038 [51:35<06:05,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2718/3038 [51:35<06:04,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  89% 2719/3038 [51:35<06:03,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2720/3038 [51:36<06:02,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2721/3038 [51:36<06:00,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2722/3038 [51:37<05:59,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2723/3038 [51:37<05:58,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2724/3038 [51:38<05:57,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2725/3038 [51:38<05:55,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2726/3038 [51:38<05:54,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2727/3038 [51:39<05:53,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2728/3038 [51:39<05:52,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2729/3038 [51:40<05:51,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2730/3038 [51:40<05:49,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2731/3038 [51:40<05:48,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2732/3038 [51:41<05:47,  1.14s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2733/3038 [51:41<05:46,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2734/3038 [51:42<05:44,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2735/3038 [51:42<05:43,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2736/3038 [51:42<05:42,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2737/3038 [51:43<05:41,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2738/3038 [51:43<05:40,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2739/3038 [51:44<05:38,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2740/3038 [51:44<05:37,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2741/3038 [51:44<05:36,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2742/3038 [51:45<05:35,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2743/3038 [51:45<05:34,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2744/3038 [51:46<05:32,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2745/3038 [51:46<05:31,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2746/3038 [51:46<05:30,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2747/3038 [51:47<05:29,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2748/3038 [51:47<05:27,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  90% 2749/3038 [51:48<05:26,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2750/3038 [51:48<05:25,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2751/3038 [51:48<05:24,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2752/3038 [51:49<05:23,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2753/3038 [51:49<05:21,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2754/3038 [51:50<05:20,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2755/3038 [51:50<05:19,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2756/3038 [51:50<05:18,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2757/3038 [51:51<05:17,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2758/3038 [51:51<05:15,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2759/3038 [51:52<05:14,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2760/3038 [51:52<05:13,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2761/3038 [51:52<05:12,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2762/3038 [51:53<05:11,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2763/3038 [51:53<05:09,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2764/3038 [51:54<05:08,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2765/3038 [51:54<05:07,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2766/3038 [51:54<05:06,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2767/3038 [51:55<05:05,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2768/3038 [51:55<05:03,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2769/3038 [51:56<05:02,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2770/3038 [51:56<05:01,  1.13s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2771/3038 [51:56<05:00,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2772/3038 [51:57<04:59,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2773/3038 [51:57<04:57,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2774/3038 [51:58<04:56,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2775/3038 [51:58<04:55,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2776/3038 [51:58<04:54,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2777/3038 [51:59<04:53,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2778/3038 [51:59<04:51,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  91% 2779/3038 [52:00<04:50,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2780/3038 [52:00<04:49,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2781/3038 [52:01<04:48,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2782/3038 [52:01<04:47,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2783/3038 [52:01<04:46,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2784/3038 [52:02<04:44,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2785/3038 [52:02<04:43,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2786/3038 [52:03<04:42,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2787/3038 [52:03<04:41,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2788/3038 [52:03<04:40,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2789/3038 [52:04<04:38,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2790/3038 [52:04<04:37,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2791/3038 [52:05<04:36,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2792/3038 [52:05<04:35,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2793/3038 [52:05<04:34,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2794/3038 [52:06<04:33,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2795/3038 [52:06<04:31,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2796/3038 [52:07<04:30,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2797/3038 [52:07<04:29,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2798/3038 [52:07<04:28,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2799/3038 [52:08<04:27,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2800/3038 [52:08<04:25,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2801/3038 [52:09<04:24,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2802/3038 [52:09<04:23,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2803/3038 [52:09<04:22,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2804/3038 [52:10<04:21,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2805/3038 [52:10<04:20,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2806/3038 [52:11<04:18,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2807/3038 [52:11<04:17,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2808/3038 [52:11<04:16,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2809/3038 [52:12<04:15,  1.12s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  92% 2810/3038 [52:12<04:14,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2811/3038 [52:13<04:13,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2812/3038 [52:13<04:11,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2813/3038 [52:13<04:10,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2814/3038 [52:14<04:09,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2815/3038 [52:14<04:08,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2816/3038 [52:15<04:07,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2817/3038 [52:15<04:05,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2818/3038 [52:15<04:04,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2819/3038 [52:16<04:03,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2820/3038 [52:16<04:02,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2821/3038 [52:17<04:01,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2822/3038 [52:17<04:00,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2823/3038 [52:17<03:58,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2824/3038 [52:18<03:57,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2825/3038 [52:18<03:56,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2826/3038 [52:19<03:55,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2827/3038 [52:19<03:54,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2828/3038 [52:19<03:53,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2829/3038 [52:20<03:52,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2830/3038 [52:20<03:50,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2831/3038 [52:21<03:49,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2832/3038 [52:21<03:48,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2833/3038 [52:21<03:47,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2834/3038 [52:22<03:46,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2835/3038 [52:22<03:45,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2836/3038 [52:23<03:43,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2837/3038 [52:23<03:42,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2838/3038 [52:23<03:41,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2839/3038 [52:24<03:40,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  93% 2840/3038 [52:24<03:39,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2841/3038 [52:25<03:38,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2842/3038 [52:25<03:36,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2843/3038 [52:26<03:35,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2844/3038 [52:26<03:34,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2845/3038 [52:26<03:33,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2846/3038 [52:27<03:32,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2847/3038 [52:27<03:31,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2848/3038 [52:28<03:30,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2849/3038 [52:28<03:28,  1.11s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2850/3038 [52:28<03:27,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2851/3038 [52:29<03:26,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2852/3038 [52:29<03:25,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2853/3038 [52:30<03:24,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2854/3038 [52:30<03:23,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2855/3038 [52:30<03:21,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2856/3038 [52:31<03:20,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2857/3038 [52:31<03:19,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2858/3038 [52:32<03:18,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2859/3038 [52:32<03:17,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2860/3038 [52:32<03:16,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2861/3038 [52:33<03:15,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2862/3038 [52:33<03:13,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2863/3038 [52:34<03:12,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2864/3038 [52:34<03:11,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2865/3038 [52:34<03:10,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2866/3038 [52:35<03:09,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2867/3038 [52:35<03:08,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2868/3038 [52:36<03:07,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2869/3038 [52:36<03:05,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  94% 2870/3038 [52:36<03:04,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2871/3038 [52:37<03:03,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2872/3038 [52:37<03:02,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2873/3038 [52:38<03:01,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2874/3038 [52:38<03:00,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2875/3038 [52:38<02:59,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2876/3038 [52:39<02:57,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2877/3038 [52:39<02:56,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2878/3038 [52:40<02:55,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2879/3038 [52:40<02:54,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2880/3038 [52:40<02:53,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2881/3038 [52:41<02:52,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2882/3038 [52:41<02:51,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2883/3038 [52:42<02:50,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2884/3038 [52:42<02:48,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2885/3038 [52:42<02:47,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2886/3038 [52:43<02:46,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2887/3038 [52:43<02:45,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2888/3038 [52:44<02:44,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2889/3038 [52:44<02:43,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2890/3038 [52:44<02:42,  1.10s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2891/3038 [52:45<02:40,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2892/3038 [52:45<02:39,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2893/3038 [52:46<02:38,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2894/3038 [52:46<02:37,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2895/3038 [52:46<02:36,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2896/3038 [52:47<02:35,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2897/3038 [52:47<02:34,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2898/3038 [52:48<02:33,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2899/3038 [52:48<02:31,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2900/3038 [52:48<02:30,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  95% 2901/3038 [52:49<02:29,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2902/3038 [52:49<02:28,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2903/3038 [52:50<02:27,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2904/3038 [52:50<02:26,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2905/3038 [52:50<02:25,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2906/3038 [52:51<02:24,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2907/3038 [52:51<02:22,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2908/3038 [52:52<02:21,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2909/3038 [52:52<02:20,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2910/3038 [52:52<02:19,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2911/3038 [52:53<02:18,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2912/3038 [52:53<02:17,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2913/3038 [52:54<02:16,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2914/3038 [52:54<02:15,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2915/3038 [52:54<02:13,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2916/3038 [52:55<02:12,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2917/3038 [52:55<02:11,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2918/3038 [52:56<02:10,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2919/3038 [52:56<02:09,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2920/3038 [52:56<02:08,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2921/3038 [52:57<02:07,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2922/3038 [52:57<02:06,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2923/3038 [52:58<02:05,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2924/3038 [52:58<02:03,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2925/3038 [52:58<02:02,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2926/3038 [52:59<02:01,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2927/3038 [52:59<02:00,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2928/3038 [53:00<01:59,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2929/3038 [53:00<01:58,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2930/3038 [53:00<01:57,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  96% 2931/3038 [53:01<01:56,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2932/3038 [53:01<01:55,  1.09s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2933/3038 [53:02<01:53,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2934/3038 [53:02<01:52,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2935/3038 [53:02<01:51,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2936/3038 [53:03<01:50,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2937/3038 [53:03<01:49,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2938/3038 [53:04<01:48,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2939/3038 [53:04<01:47,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2940/3038 [53:04<01:46,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2941/3038 [53:05<01:45,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2942/3038 [53:05<01:43,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2943/3038 [53:06<01:42,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2944/3038 [53:06<01:41,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2945/3038 [53:07<01:40,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2946/3038 [53:07<01:39,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2947/3038 [53:07<01:38,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2948/3038 [53:08<01:37,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2949/3038 [53:08<01:36,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2950/3038 [53:09<01:35,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2951/3038 [53:09<01:34,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2952/3038 [53:09<01:32,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2953/3038 [53:10<01:31,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2954/3038 [53:10<01:30,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2955/3038 [53:11<01:29,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2956/3038 [53:11<01:28,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2957/3038 [53:11<01:27,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2958/3038 [53:12<01:26,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2959/3038 [53:12<01:25,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2960/3038 [53:13<01:24,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2961/3038 [53:13<01:23,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  97% 2962/3038 [53:13<01:21,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2963/3038 [53:14<01:20,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2964/3038 [53:14<01:19,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2965/3038 [53:15<01:18,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2966/3038 [53:15<01:17,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2967/3038 [53:15<01:16,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2968/3038 [53:16<01:15,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2969/3038 [53:16<01:14,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2970/3038 [53:17<01:13,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2971/3038 [53:17<01:12,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2972/3038 [53:17<01:11,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2973/3038 [53:18<01:09,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2974/3038 [53:18<01:08,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2975/3038 [53:19<01:07,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2976/3038 [53:19<01:06,  1.08s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2977/3038 [53:19<01:05,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2978/3038 [53:20<01:04,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2979/3038 [53:20<01:03,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2980/3038 [53:21<01:02,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2981/3038 [53:21<01:01,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2982/3038 [53:21<01:00,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2983/3038 [53:22<00:59,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2984/3038 [53:22<00:57,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2985/3038 [53:23<00:56,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2986/3038 [53:23<00:55,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2987/3038 [53:23<00:54,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2988/3038 [53:24<00:53,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2989/3038 [53:24<00:52,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2990/3038 [53:25<00:51,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2991/3038 [53:25<00:50,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  98% 2992/3038 [53:25<00:49,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2993/3038 [53:26<00:48,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2994/3038 [53:26<00:47,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2995/3038 [53:27<00:46,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2996/3038 [53:27<00:44,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2997/3038 [53:27<00:43,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2998/3038 [53:28<00:42,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 2999/3038 [53:28<00:41,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3000/3038 [53:29<00:40,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3001/3038 [53:29<00:39,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3002/3038 [53:29<00:38,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3003/3038 [53:30<00:37,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3004/3038 [53:30<00:36,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3005/3038 [53:31<00:35,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3006/3038 [53:31<00:34,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3007/3038 [53:31<00:33,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3008/3038 [53:32<00:32,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3009/3038 [53:32<00:30,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3010/3038 [53:33<00:29,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3011/3038 [53:33<00:28,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3012/3038 [53:33<00:27,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3013/3038 [53:34<00:26,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3014/3038 [53:34<00:25,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3015/3038 [53:35<00:24,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3016/3038 [53:35<00:23,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3017/3038 [53:35<00:22,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3018/3038 [53:36<00:21,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3019/3038 [53:36<00:20,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3020/3038 [53:37<00:19,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3021/3038 [53:37<00:18,  1.07s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1:  99% 3022/3038 [53:37<00:17,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3023/3038 [53:38<00:15,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3024/3038 [53:38<00:14,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3025/3038 [53:39<00:13,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3026/3038 [53:39<00:12,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3027/3038 [53:39<00:11,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3028/3038 [53:40<00:10,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3029/3038 [53:40<00:09,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3030/3038 [53:41<00:08,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3031/3038 [53:41<00:07,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3032/3038 [53:41<00:06,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3033/3038 [53:42<00:05,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3034/3038 [53:42<00:04,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3035/3038 [53:43<00:03,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3036/3038 [53:43<00:02,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3037/3038 [53:43<00:01,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3038/3038 [53:44<00:00,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]\n","Epoch 1: 100% 3038/3038 [53:44<00:00,  1.06s/it, loss=1.23, v_num=5, train_loss=1.160, val_loss=1.620]Epoch 1, global step 5400: 'val_loss' reached 1.61953 (best 1.61636), saving model to '/content/drive/MyDrive/mjjeon/KoBART-summarization/logs/model_chp/epoch=01-val_loss=1.620.ckpt' as top 3\n","Epoch 2:  89% 2700/3038 [51:19<06:25,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  89% 2701/3038 [51:19<06:24,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2702/3038 [51:20<06:23,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2703/3038 [51:20<06:21,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2704/3038 [51:21<06:20,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2705/3038 [51:21<06:19,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2706/3038 [51:21<06:18,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2707/3038 [51:22<06:16,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2708/3038 [51:22<06:15,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2709/3038 [51:23<06:14,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2710/3038 [51:23<06:13,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2711/3038 [51:23<06:11,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2712/3038 [51:24<06:10,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2713/3038 [51:24<06:09,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2714/3038 [51:25<06:08,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2715/3038 [51:25<06:07,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2716/3038 [51:25<06:05,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2717/3038 [51:26<06:04,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2718/3038 [51:26<06:03,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  89% 2719/3038 [51:27<06:02,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2720/3038 [51:27<06:00,  1.14s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2721/3038 [51:27<05:59,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2722/3038 [51:28<05:58,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2723/3038 [51:28<05:57,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2724/3038 [51:29<05:56,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2725/3038 [51:29<05:54,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2726/3038 [51:29<05:53,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2727/3038 [51:30<05:52,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2728/3038 [51:30<05:51,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2729/3038 [51:31<05:49,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2730/3038 [51:31<05:48,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2731/3038 [51:31<05:47,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2732/3038 [51:32<05:46,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2733/3038 [51:32<05:45,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2734/3038 [51:33<05:43,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2735/3038 [51:33<05:42,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2736/3038 [51:33<05:41,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2737/3038 [51:34<05:40,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2738/3038 [51:34<05:39,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2739/3038 [51:35<05:37,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2740/3038 [51:35<05:36,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2741/3038 [51:35<05:35,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2742/3038 [51:36<05:34,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2743/3038 [51:36<05:33,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2744/3038 [51:37<05:31,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2745/3038 [51:37<05:30,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2746/3038 [51:37<05:29,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2747/3038 [51:38<05:28,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2748/3038 [51:38<05:27,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  90% 2749/3038 [51:39<05:25,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2750/3038 [51:39<05:24,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2751/3038 [51:39<05:23,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2752/3038 [51:40<05:22,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2753/3038 [51:40<05:20,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2754/3038 [51:41<05:19,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2755/3038 [51:41<05:18,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2756/3038 [51:41<05:17,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2757/3038 [51:42<05:16,  1.13s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2758/3038 [51:42<05:14,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2759/3038 [51:43<05:13,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2760/3038 [51:43<05:12,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2761/3038 [51:43<05:11,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2762/3038 [51:44<05:10,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2763/3038 [51:44<05:09,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2764/3038 [51:45<05:07,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2765/3038 [51:45<05:06,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2766/3038 [51:45<05:05,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2767/3038 [51:46<05:04,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2768/3038 [51:46<05:03,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2769/3038 [51:47<05:01,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2770/3038 [51:47<05:00,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2771/3038 [51:47<04:59,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2772/3038 [51:48<04:58,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2773/3038 [51:48<04:57,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2774/3038 [51:49<04:55,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2775/3038 [51:49<04:54,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2776/3038 [51:49<04:53,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2777/3038 [51:50<04:52,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2778/3038 [51:50<04:51,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  91% 2779/3038 [51:51<04:49,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2780/3038 [51:51<04:48,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2781/3038 [51:51<04:47,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2782/3038 [51:52<04:46,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2783/3038 [51:52<04:45,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2784/3038 [51:53<04:44,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2785/3038 [51:53<04:42,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2786/3038 [51:53<04:41,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2787/3038 [51:54<04:40,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2788/3038 [51:54<04:39,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2789/3038 [51:54<04:38,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2790/3038 [51:55<04:36,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2791/3038 [51:55<04:35,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2792/3038 [51:56<04:34,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2793/3038 [51:56<04:33,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2794/3038 [51:56<04:32,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2795/3038 [51:57<04:31,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2796/3038 [51:57<04:29,  1.12s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2797/3038 [51:58<04:28,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2798/3038 [51:58<04:27,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2799/3038 [51:58<04:26,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2800/3038 [51:59<04:25,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2801/3038 [51:59<04:23,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2802/3038 [52:00<04:22,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2803/3038 [52:00<04:21,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2804/3038 [52:00<04:20,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2805/3038 [52:01<04:19,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2806/3038 [52:01<04:18,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2807/3038 [52:02<04:16,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2808/3038 [52:02<04:15,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2809/3038 [52:02<04:14,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  92% 2810/3038 [52:03<04:13,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2811/3038 [52:03<04:12,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2812/3038 [52:04<04:11,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2813/3038 [52:04<04:09,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2814/3038 [52:04<04:08,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2815/3038 [52:05<04:07,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2816/3038 [52:05<04:06,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2817/3038 [52:06<04:05,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2818/3038 [52:06<04:04,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2819/3038 [52:06<04:02,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2820/3038 [52:07<04:01,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2821/3038 [52:07<04:00,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2822/3038 [52:08<03:59,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2823/3038 [52:08<03:58,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2824/3038 [52:08<03:57,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2825/3038 [52:09<03:55,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2826/3038 [52:09<03:54,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2827/3038 [52:10<03:53,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2828/3038 [52:10<03:52,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2829/3038 [52:10<03:51,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2830/3038 [52:11<03:50,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2831/3038 [52:11<03:48,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2832/3038 [52:12<03:47,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2833/3038 [52:12<03:46,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2834/3038 [52:12<03:45,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2835/3038 [52:13<03:44,  1.11s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2836/3038 [52:13<03:43,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2837/3038 [52:14<03:42,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2838/3038 [52:14<03:40,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2839/3038 [52:14<03:39,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  93% 2840/3038 [52:15<03:38,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2841/3038 [52:15<03:37,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2842/3038 [52:16<03:36,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2843/3038 [52:16<03:35,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2844/3038 [52:16<03:33,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2845/3038 [52:17<03:32,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2846/3038 [52:17<03:31,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2847/3038 [52:18<03:30,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2848/3038 [52:18<03:29,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2849/3038 [52:18<03:28,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2850/3038 [52:19<03:27,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2851/3038 [52:19<03:25,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2852/3038 [52:20<03:24,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2853/3038 [52:20<03:23,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2854/3038 [52:20<03:22,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2855/3038 [52:21<03:21,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2856/3038 [52:21<03:20,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2857/3038 [52:22<03:19,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2858/3038 [52:22<03:17,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2859/3038 [52:22<03:16,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2860/3038 [52:23<03:15,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2861/3038 [52:23<03:14,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2862/3038 [52:23<03:13,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2863/3038 [52:24<03:12,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2864/3038 [52:24<03:11,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2865/3038 [52:25<03:09,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2866/3038 [52:25<03:08,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2867/3038 [52:25<03:07,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2868/3038 [52:26<03:06,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2869/3038 [52:26<03:05,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  94% 2870/3038 [52:27<03:04,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2871/3038 [52:27<03:03,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2872/3038 [52:27<03:01,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2873/3038 [52:28<03:00,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2874/3038 [52:28<02:59,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2875/3038 [52:29<02:58,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2876/3038 [52:29<02:57,  1.10s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2877/3038 [52:29<02:56,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2878/3038 [52:30<02:55,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2879/3038 [52:30<02:54,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2880/3038 [52:31<02:52,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2881/3038 [52:31<02:51,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2882/3038 [52:31<02:50,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2883/3038 [52:32<02:49,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2884/3038 [52:32<02:48,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2885/3038 [52:33<02:47,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2886/3038 [52:33<02:46,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2887/3038 [52:33<02:44,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2888/3038 [52:34<02:43,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2889/3038 [52:34<02:42,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2890/3038 [52:35<02:41,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2891/3038 [52:35<02:40,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2892/3038 [52:36<02:39,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2893/3038 [52:36<02:38,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2894/3038 [52:36<02:37,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2895/3038 [52:37<02:35,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2896/3038 [52:37<02:34,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2897/3038 [52:38<02:33,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2898/3038 [52:38<02:32,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2899/3038 [52:38<02:31,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2900/3038 [52:39<02:30,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  95% 2901/3038 [52:39<02:29,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2902/3038 [52:40<02:28,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2903/3038 [52:40<02:26,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2904/3038 [52:40<02:25,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2905/3038 [52:41<02:24,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2906/3038 [52:41<02:23,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2907/3038 [52:42<02:22,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2908/3038 [52:42<02:21,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2909/3038 [52:42<02:20,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2910/3038 [52:43<02:19,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2911/3038 [52:43<02:18,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2912/3038 [52:44<02:16,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2913/3038 [52:44<02:15,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2914/3038 [52:44<02:14,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2915/3038 [52:45<02:13,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2916/3038 [52:45<02:12,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2917/3038 [52:46<02:11,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2918/3038 [52:46<02:10,  1.09s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2919/3038 [52:47<02:09,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2920/3038 [52:47<02:07,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2921/3038 [52:47<02:06,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2922/3038 [52:48<02:05,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2923/3038 [52:48<02:04,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2924/3038 [52:49<02:03,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2925/3038 [52:49<02:02,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2926/3038 [52:49<02:01,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2927/3038 [52:50<02:00,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2928/3038 [52:50<01:59,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2929/3038 [52:51<01:58,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2930/3038 [52:51<01:56,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  96% 2931/3038 [52:51<01:55,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2932/3038 [52:52<01:54,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2933/3038 [52:52<01:53,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2934/3038 [52:53<01:52,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2935/3038 [52:53<01:51,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2936/3038 [52:54<01:50,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2937/3038 [52:54<01:49,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2938/3038 [52:54<01:48,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2939/3038 [52:55<01:46,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2940/3038 [52:55<01:45,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2941/3038 [52:56<01:44,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2942/3038 [52:56<01:43,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2943/3038 [52:56<01:42,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2944/3038 [52:57<01:41,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2945/3038 [52:57<01:40,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2946/3038 [52:58<01:39,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2947/3038 [52:58<01:38,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2948/3038 [52:58<01:37,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2949/3038 [52:59<01:35,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2950/3038 [52:59<01:34,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2951/3038 [53:00<01:33,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2952/3038 [53:00<01:32,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2953/3038 [53:01<01:31,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2954/3038 [53:01<01:30,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2955/3038 [53:01<01:29,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2956/3038 [53:02<01:28,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2957/3038 [53:02<01:27,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2958/3038 [53:03<01:26,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2959/3038 [53:03<01:24,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2960/3038 [53:03<01:23,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2961/3038 [53:04<01:22,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  97% 2962/3038 [53:04<01:21,  1.08s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2963/3038 [53:05<01:20,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2964/3038 [53:05<01:19,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2965/3038 [53:06<01:18,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2966/3038 [53:06<01:17,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2967/3038 [53:06<01:16,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2968/3038 [53:07<01:15,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2969/3038 [53:07<01:14,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2970/3038 [53:08<01:12,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2971/3038 [53:08<01:11,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2972/3038 [53:08<01:10,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2973/3038 [53:09<01:09,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2974/3038 [53:09<01:08,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2975/3038 [53:10<01:07,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2976/3038 [53:10<01:06,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2977/3038 [53:11<01:05,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2978/3038 [53:11<01:04,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2979/3038 [53:11<01:03,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2980/3038 [53:12<01:02,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2981/3038 [53:12<01:01,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2982/3038 [53:13<00:59,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2983/3038 [53:13<00:58,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2984/3038 [53:13<00:57,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2985/3038 [53:14<00:56,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2986/3038 [53:14<00:55,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2987/3038 [53:15<00:54,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2988/3038 [53:15<00:53,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2989/3038 [53:15<00:52,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2990/3038 [53:16<00:51,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2991/3038 [53:16<00:50,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  98% 2992/3038 [53:17<00:49,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2993/3038 [53:17<00:48,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2994/3038 [53:18<00:46,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2995/3038 [53:18<00:45,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2996/3038 [53:18<00:44,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2997/3038 [53:19<00:43,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2998/3038 [53:19<00:42,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 2999/3038 [53:20<00:41,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3000/3038 [53:20<00:40,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3001/3038 [53:20<00:39,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3002/3038 [53:21<00:38,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3003/3038 [53:21<00:37,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3004/3038 [53:22<00:36,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3005/3038 [53:22<00:35,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3006/3038 [53:22<00:34,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3007/3038 [53:23<00:33,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3008/3038 [53:23<00:31,  1.07s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3009/3038 [53:24<00:30,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3010/3038 [53:24<00:29,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3011/3038 [53:25<00:28,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3012/3038 [53:25<00:27,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3013/3038 [53:25<00:26,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3014/3038 [53:26<00:25,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3015/3038 [53:26<00:24,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3016/3038 [53:27<00:23,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3017/3038 [53:27<00:22,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3018/3038 [53:27<00:21,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3019/3038 [53:28<00:20,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3020/3038 [53:28<00:19,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3021/3038 [53:29<00:18,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2:  99% 3022/3038 [53:29<00:16,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3023/3038 [53:29<00:15,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3024/3038 [53:30<00:14,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3025/3038 [53:30<00:13,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3026/3038 [53:31<00:12,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3027/3038 [53:31<00:11,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3028/3038 [53:31<00:10,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3029/3038 [53:32<00:09,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3030/3038 [53:32<00:08,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3031/3038 [53:33<00:07,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3032/3038 [53:33<00:06,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3033/3038 [53:34<00:05,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3034/3038 [53:34<00:04,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3035/3038 [53:34<00:03,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3036/3038 [53:35<00:02,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3037/3038 [53:35<00:01,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.620]\n","Epoch 2: 100% 3038/3038 [53:36<00:00,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.670]\n","Epoch 2: 100% 3038/3038 [53:36<00:00,  1.06s/it, loss=1.26, v_num=5, train_loss=1.560, val_loss=1.670]Epoch 2, global step 8100: 'val_loss' reached 1.67106 (best 1.61636), saving model to '/content/drive/MyDrive/mjjeon/KoBART-summarization/logs/model_chp/epoch=02-val_loss=1.671.ckpt' as top 3\n","Epoch 3:  89% 2700/3038 [52:05<06:31,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670] \n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  89% 2701/3038 [52:05<06:30,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2702/3038 [52:06<06:28,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2703/3038 [52:06<06:27,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2704/3038 [52:07<06:26,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2705/3038 [52:07<06:25,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2706/3038 [52:07<06:23,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2707/3038 [52:08<06:22,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2708/3038 [52:08<06:21,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2709/3038 [52:09<06:20,  1.16s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2710/3038 [52:09<06:18,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2711/3038 [52:10<06:17,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2712/3038 [52:10<06:16,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2713/3038 [52:10<06:15,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2714/3038 [52:11<06:13,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2715/3038 [52:11<06:12,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2716/3038 [52:12<06:11,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2717/3038 [52:12<06:10,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2718/3038 [52:12<06:08,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  89% 2719/3038 [52:13<06:07,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2720/3038 [52:13<06:06,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2721/3038 [52:14<06:05,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2722/3038 [52:14<06:03,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2723/3038 [52:14<06:02,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2724/3038 [52:15<06:01,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2725/3038 [52:15<06:00,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2726/3038 [52:16<05:58,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2727/3038 [52:16<05:57,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2728/3038 [52:17<05:56,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2729/3038 [52:17<05:55,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2730/3038 [52:17<05:54,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2731/3038 [52:18<05:52,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2732/3038 [52:18<05:51,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2733/3038 [52:19<05:50,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2734/3038 [52:19<05:49,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2735/3038 [52:19<05:47,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2736/3038 [52:20<05:46,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2737/3038 [52:20<05:45,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2738/3038 [52:21<05:44,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2739/3038 [52:21<05:42,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2740/3038 [52:21<05:41,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2741/3038 [52:22<05:40,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2742/3038 [52:22<05:39,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2743/3038 [52:23<05:38,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2744/3038 [52:23<05:36,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2745/3038 [52:24<05:35,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2746/3038 [52:24<05:34,  1.15s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2747/3038 [52:24<05:33,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2748/3038 [52:25<05:31,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  90% 2749/3038 [52:25<05:30,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2750/3038 [52:26<05:29,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2751/3038 [52:26<05:28,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2752/3038 [52:26<05:27,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2753/3038 [52:27<05:25,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2754/3038 [52:27<05:24,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2755/3038 [52:28<05:23,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2756/3038 [52:28<05:22,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2757/3038 [52:28<05:20,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2758/3038 [52:29<05:19,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2759/3038 [52:29<05:18,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2760/3038 [52:30<05:17,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2761/3038 [52:30<05:16,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2762/3038 [52:30<05:14,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2763/3038 [52:31<05:13,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2764/3038 [52:31<05:12,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2765/3038 [52:32<05:11,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2766/3038 [52:32<05:10,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2767/3038 [52:33<05:08,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2768/3038 [52:33<05:07,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2769/3038 [52:33<05:06,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2770/3038 [52:34<05:05,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2771/3038 [52:34<05:03,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2772/3038 [52:35<05:02,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2773/3038 [52:35<05:01,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2774/3038 [52:35<05:00,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2775/3038 [52:36<04:59,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2776/3038 [52:36<04:57,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2777/3038 [52:37<04:56,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2778/3038 [52:37<04:55,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  91% 2779/3038 [52:37<04:54,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2780/3038 [52:38<04:53,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2781/3038 [52:38<04:51,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2782/3038 [52:39<04:50,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2783/3038 [52:39<04:49,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2784/3038 [52:40<04:48,  1.14s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2785/3038 [52:40<04:47,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2786/3038 [52:40<04:45,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2787/3038 [52:41<04:44,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2788/3038 [52:41<04:43,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2789/3038 [52:42<04:42,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2790/3038 [52:42<04:41,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2791/3038 [52:42<04:39,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2792/3038 [52:43<04:38,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2793/3038 [52:43<04:37,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2794/3038 [52:44<04:36,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2795/3038 [52:44<04:35,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2796/3038 [52:44<04:33,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2797/3038 [52:45<04:32,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2798/3038 [52:45<04:31,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2799/3038 [52:46<04:30,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2800/3038 [52:46<04:29,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2801/3038 [52:46<04:27,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2802/3038 [52:47<04:26,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2803/3038 [52:47<04:25,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2804/3038 [52:48<04:24,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2805/3038 [52:48<04:23,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2806/3038 [52:49<04:22,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2807/3038 [52:49<04:20,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2808/3038 [52:49<04:19,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2809/3038 [52:50<04:18,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  92% 2810/3038 [52:50<04:17,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2811/3038 [52:51<04:16,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2812/3038 [52:51<04:14,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2813/3038 [52:51<04:13,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2814/3038 [52:52<04:12,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2815/3038 [52:52<04:11,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2816/3038 [52:53<04:10,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2817/3038 [52:53<04:08,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2818/3038 [52:53<04:07,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2819/3038 [52:54<04:06,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2820/3038 [52:54<04:05,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2821/3038 [52:55<04:04,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2822/3038 [52:55<04:03,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2823/3038 [52:55<04:01,  1.13s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2824/3038 [52:56<04:00,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2825/3038 [52:56<03:59,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2826/3038 [52:57<03:58,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2827/3038 [52:57<03:57,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2828/3038 [52:58<03:55,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2829/3038 [52:58<03:54,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2830/3038 [52:58<03:53,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2831/3038 [52:59<03:52,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2832/3038 [52:59<03:51,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2833/3038 [53:00<03:50,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2834/3038 [53:00<03:48,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2835/3038 [53:00<03:47,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2836/3038 [53:01<03:46,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2837/3038 [53:01<03:45,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2838/3038 [53:02<03:44,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2839/3038 [53:02<03:43,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  93% 2840/3038 [53:02<03:41,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2841/3038 [53:03<03:40,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2842/3038 [53:03<03:39,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2843/3038 [53:04<03:38,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2844/3038 [53:04<03:37,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2845/3038 [53:05<03:36,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2846/3038 [53:05<03:34,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2847/3038 [53:05<03:33,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2848/3038 [53:06<03:32,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2849/3038 [53:06<03:31,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2850/3038 [53:07<03:30,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2851/3038 [53:07<03:29,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2852/3038 [53:07<03:27,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2853/3038 [53:08<03:26,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2854/3038 [53:08<03:25,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2855/3038 [53:09<03:24,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2856/3038 [53:09<03:23,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2857/3038 [53:09<03:22,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2858/3038 [53:10<03:20,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2859/3038 [53:10<03:19,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2860/3038 [53:11<03:18,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2861/3038 [53:11<03:17,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2862/3038 [53:11<03:16,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2863/3038 [53:12<03:15,  1.12s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2864/3038 [53:12<03:13,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2865/3038 [53:13<03:12,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2866/3038 [53:13<03:11,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2867/3038 [53:14<03:10,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2868/3038 [53:14<03:09,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2869/3038 [53:14<03:08,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  94% 2870/3038 [53:15<03:07,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2871/3038 [53:15<03:05,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2872/3038 [53:16<03:04,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2873/3038 [53:16<03:03,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2874/3038 [53:16<03:02,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2875/3038 [53:17<03:01,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2876/3038 [53:17<03:00,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2877/3038 [53:18<02:58,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2878/3038 [53:18<02:57,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2879/3038 [53:18<02:56,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2880/3038 [53:19<02:55,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2881/3038 [53:19<02:54,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2882/3038 [53:20<02:53,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2883/3038 [53:20<02:52,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2884/3038 [53:20<02:50,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2885/3038 [53:21<02:49,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2886/3038 [53:21<02:48,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2887/3038 [53:22<02:47,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2888/3038 [53:22<02:46,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2889/3038 [53:23<02:45,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2890/3038 [53:23<02:44,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2891/3038 [53:23<02:42,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2892/3038 [53:24<02:41,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2893/3038 [53:24<02:40,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2894/3038 [53:25<02:39,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2895/3038 [53:25<02:38,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2896/3038 [53:25<02:37,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2897/3038 [53:26<02:36,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2898/3038 [53:26<02:34,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2899/3038 [53:27<02:33,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2900/3038 [53:27<02:32,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  95% 2901/3038 [53:27<02:31,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2902/3038 [53:28<02:30,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2903/3038 [53:28<02:29,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2904/3038 [53:29<02:28,  1.11s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2905/3038 [53:29<02:26,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2906/3038 [53:29<02:25,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2907/3038 [53:30<02:24,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2908/3038 [53:30<02:23,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2909/3038 [53:31<02:22,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2910/3038 [53:31<02:21,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2911/3038 [53:32<02:20,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2912/3038 [53:32<02:19,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2913/3038 [53:32<02:17,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2914/3038 [53:33<02:16,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2915/3038 [53:33<02:15,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2916/3038 [53:34<02:14,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2917/3038 [53:34<02:13,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2918/3038 [53:34<02:12,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2919/3038 [53:35<02:11,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2920/3038 [53:35<02:09,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2921/3038 [53:36<02:08,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2922/3038 [53:36<02:07,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2923/3038 [53:36<02:06,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2924/3038 [53:37<02:05,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2925/3038 [53:37<02:04,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2926/3038 [53:38<02:03,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2927/3038 [53:38<02:02,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2928/3038 [53:39<02:00,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2929/3038 [53:39<01:59,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2930/3038 [53:39<01:58,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  96% 2931/3038 [53:40<01:57,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2932/3038 [53:40<01:56,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2933/3038 [53:41<01:55,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2934/3038 [53:41<01:54,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2935/3038 [53:41<01:53,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2936/3038 [53:42<01:51,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2937/3038 [53:42<01:50,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2938/3038 [53:43<01:49,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2939/3038 [53:43<01:48,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2940/3038 [53:43<01:47,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2941/3038 [53:44<01:46,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2942/3038 [53:44<01:45,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2943/3038 [53:45<01:44,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2944/3038 [53:45<01:42,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2945/3038 [53:45<01:41,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2946/3038 [53:46<01:40,  1.10s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2947/3038 [53:46<01:39,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2948/3038 [53:47<01:38,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2949/3038 [53:47<01:37,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2950/3038 [53:48<01:36,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2951/3038 [53:48<01:35,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2952/3038 [53:48<01:34,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2953/3038 [53:49<01:32,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2954/3038 [53:49<01:31,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2955/3038 [53:50<01:30,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2956/3038 [53:50<01:29,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2957/3038 [53:50<01:28,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2958/3038 [53:51<01:27,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2959/3038 [53:51<01:26,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2960/3038 [53:52<01:25,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2961/3038 [53:52<01:24,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  97% 2962/3038 [53:52<01:22,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2963/3038 [53:53<01:21,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2964/3038 [53:53<01:20,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2965/3038 [53:54<01:19,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2966/3038 [53:54<01:18,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2967/3038 [53:55<01:17,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2968/3038 [53:55<01:16,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2969/3038 [53:55<01:15,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2970/3038 [53:56<01:14,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2971/3038 [53:56<01:12,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2972/3038 [53:57<01:11,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2973/3038 [53:57<01:10,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2974/3038 [53:57<01:09,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2975/3038 [53:58<01:08,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2976/3038 [53:58<01:07,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2977/3038 [53:59<01:06,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2978/3038 [53:59<01:05,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2979/3038 [53:59<01:04,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2980/3038 [54:00<01:03,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2981/3038 [54:00<01:01,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2982/3038 [54:01<01:00,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2983/3038 [54:01<00:59,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2984/3038 [54:02<00:58,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2985/3038 [54:02<00:57,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2986/3038 [54:02<00:56,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2987/3038 [54:03<00:55,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2988/3038 [54:03<00:54,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2989/3038 [54:04<00:53,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2990/3038 [54:04<00:52,  1.09s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2991/3038 [54:04<00:50,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  98% 2992/3038 [54:05<00:49,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2993/3038 [54:05<00:48,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2994/3038 [54:06<00:47,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2995/3038 [54:06<00:46,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2996/3038 [54:06<00:45,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2997/3038 [54:07<00:44,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2998/3038 [54:07<00:43,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 2999/3038 [54:08<00:42,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3000/3038 [54:08<00:41,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3001/3038 [54:09<00:40,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3002/3038 [54:09<00:38,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3003/3038 [54:09<00:37,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3004/3038 [54:10<00:36,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3005/3038 [54:10<00:35,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3006/3038 [54:11<00:34,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3007/3038 [54:11<00:33,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3008/3038 [54:11<00:32,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3009/3038 [54:12<00:31,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3010/3038 [54:12<00:30,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3011/3038 [54:13<00:29,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3012/3038 [54:13<00:28,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3013/3038 [54:13<00:26,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3014/3038 [54:14<00:25,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3015/3038 [54:14<00:24,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3016/3038 [54:15<00:23,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3017/3038 [54:15<00:22,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3018/3038 [54:16<00:21,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3019/3038 [54:16<00:20,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3020/3038 [54:16<00:19,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3021/3038 [54:17<00:18,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3:  99% 3022/3038 [54:17<00:17,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3023/3038 [54:18<00:16,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3024/3038 [54:18<00:15,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3025/3038 [54:18<00:14,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3026/3038 [54:19<00:12,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3027/3038 [54:19<00:11,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3028/3038 [54:20<00:10,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3029/3038 [54:20<00:09,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3030/3038 [54:20<00:08,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3031/3038 [54:21<00:07,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3032/3038 [54:21<00:06,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3033/3038 [54:22<00:05,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3034/3038 [54:22<00:04,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3035/3038 [54:23<00:03,  1.08s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3036/3038 [54:23<00:02,  1.07s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3037/3038 [54:23<00:01,  1.07s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.670]\n","Epoch 3: 100% 3038/3038 [54:24<00:00,  1.07s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.660]\n","Epoch 3: 100% 3038/3038 [54:24<00:00,  1.07s/it, loss=1.1, v_num=5, train_loss=1.150, val_loss=1.660]Epoch 3, global step 10800: 'val_loss' reached 1.66078 (best 1.61636), saving model to '/content/drive/MyDrive/mjjeon/KoBART-summarization/logs/model_chp/epoch=03-val_loss=1.661.ckpt' as top 3\n","Epoch 4:  89% 2700/3038 [52:08<06:31,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  89% 2701/3038 [52:09<06:30,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2702/3038 [52:09<06:29,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2703/3038 [52:10<06:27,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2704/3038 [52:10<06:26,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2705/3038 [52:10<06:25,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2706/3038 [52:11<06:24,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2707/3038 [52:11<06:22,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2708/3038 [52:12<06:21,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2709/3038 [52:12<06:20,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2710/3038 [52:12<06:19,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2711/3038 [52:13<06:17,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2712/3038 [52:13<06:16,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2713/3038 [52:14<06:15,  1.16s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2714/3038 [52:14<06:14,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2715/3038 [52:15<06:12,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2716/3038 [52:15<06:11,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2717/3038 [52:15<06:10,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2718/3038 [52:16<06:09,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  89% 2719/3038 [52:16<06:08,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2720/3038 [52:17<06:06,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2721/3038 [52:17<06:05,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2722/3038 [52:17<06:04,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2723/3038 [52:18<06:03,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2724/3038 [52:18<06:01,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2725/3038 [52:19<06:00,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2726/3038 [52:19<05:59,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2727/3038 [52:19<05:58,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2728/3038 [52:20<05:56,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2729/3038 [52:20<05:55,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2730/3038 [52:21<05:54,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2731/3038 [52:21<05:53,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2732/3038 [52:22<05:51,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2733/3038 [52:22<05:50,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2734/3038 [52:22<05:49,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2735/3038 [52:23<05:48,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2736/3038 [52:23<05:47,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2737/3038 [52:24<05:45,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2738/3038 [52:24<05:44,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2739/3038 [52:24<05:43,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2740/3038 [52:25<05:42,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2741/3038 [52:25<05:40,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2742/3038 [52:26<05:39,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2743/3038 [52:26<05:38,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2744/3038 [52:27<05:37,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2745/3038 [52:27<05:35,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2746/3038 [52:27<05:34,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2747/3038 [52:28<05:33,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2748/3038 [52:28<05:32,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  90% 2749/3038 [52:29<05:31,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2750/3038 [52:29<05:29,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2751/3038 [52:29<05:28,  1.15s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2752/3038 [52:30<05:27,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2753/3038 [52:30<05:26,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2754/3038 [52:31<05:24,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2755/3038 [52:31<05:23,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2756/3038 [52:31<05:22,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2757/3038 [52:32<05:21,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2758/3038 [52:32<05:20,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2759/3038 [52:33<05:18,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2760/3038 [52:33<05:17,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2761/3038 [52:34<05:16,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2762/3038 [52:34<05:15,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2763/3038 [52:34<05:14,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2764/3038 [52:35<05:12,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2765/3038 [52:35<05:11,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2766/3038 [52:36<05:10,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2767/3038 [52:36<05:09,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2768/3038 [52:36<05:07,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2769/3038 [52:37<05:06,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2770/3038 [52:37<05:05,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2771/3038 [52:38<05:04,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2772/3038 [52:38<05:03,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2773/3038 [52:39<05:01,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2774/3038 [52:39<05:00,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2775/3038 [52:39<04:59,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2776/3038 [52:40<04:58,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2777/3038 [52:40<04:57,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2778/3038 [52:41<04:55,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  91% 2779/3038 [52:41<04:54,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2780/3038 [52:41<04:53,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2781/3038 [52:42<04:52,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2782/3038 [52:42<04:51,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2783/3038 [52:43<04:49,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2784/3038 [52:43<04:48,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2785/3038 [52:43<04:47,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2786/3038 [52:44<04:46,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2787/3038 [52:44<04:45,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2788/3038 [52:45<04:43,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2789/3038 [52:45<04:42,  1.14s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2790/3038 [52:46<04:41,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2791/3038 [52:46<04:40,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2792/3038 [52:46<04:39,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2793/3038 [52:47<04:37,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2794/3038 [52:47<04:36,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2795/3038 [52:48<04:35,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2796/3038 [52:48<04:34,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2797/3038 [52:48<04:33,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2798/3038 [52:49<04:31,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2799/3038 [52:49<04:30,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2800/3038 [52:50<04:29,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2801/3038 [52:50<04:28,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2802/3038 [52:51<04:27,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2803/3038 [52:51<04:25,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2804/3038 [52:51<04:24,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2805/3038 [52:52<04:23,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2806/3038 [52:52<04:22,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2807/3038 [52:53<04:21,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2808/3038 [52:53<04:19,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2809/3038 [52:53<04:18,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  92% 2810/3038 [52:54<04:17,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2811/3038 [52:54<04:16,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2812/3038 [52:55<04:15,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2813/3038 [52:55<04:14,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2814/3038 [52:56<04:12,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2815/3038 [52:56<04:11,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2816/3038 [52:56<04:10,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2817/3038 [52:57<04:09,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2818/3038 [52:57<04:08,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2819/3038 [52:58<04:06,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2820/3038 [52:58<04:05,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2821/3038 [52:58<04:04,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2822/3038 [52:59<04:03,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2823/3038 [52:59<04:02,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2824/3038 [53:00<04:00,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2825/3038 [53:00<03:59,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2826/3038 [53:01<03:58,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2827/3038 [53:01<03:57,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2828/3038 [53:01<03:56,  1.13s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2829/3038 [53:02<03:55,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2830/3038 [53:02<03:53,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2831/3038 [53:03<03:52,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2832/3038 [53:03<03:51,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2833/3038 [53:03<03:50,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2834/3038 [53:04<03:49,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2835/3038 [53:04<03:48,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2836/3038 [53:05<03:46,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2837/3038 [53:05<03:45,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2838/3038 [53:06<03:44,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2839/3038 [53:06<03:43,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  93% 2840/3038 [53:06<03:42,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2841/3038 [53:07<03:41,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2842/3038 [53:07<03:39,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2843/3038 [53:08<03:38,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2844/3038 [53:08<03:37,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2845/3038 [53:08<03:36,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2846/3038 [53:09<03:35,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2847/3038 [53:09<03:33,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2848/3038 [53:10<03:32,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2849/3038 [53:10<03:31,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2850/3038 [53:11<03:30,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2851/3038 [53:11<03:29,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2852/3038 [53:11<03:28,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2853/3038 [53:12<03:26,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2854/3038 [53:12<03:25,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2855/3038 [53:13<03:24,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2856/3038 [53:13<03:23,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2857/3038 [53:13<03:22,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2858/3038 [53:14<03:21,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2859/3038 [53:14<03:20,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2860/3038 [53:15<03:18,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2861/3038 [53:15<03:17,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2862/3038 [53:15<03:16,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2863/3038 [53:16<03:15,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2864/3038 [53:16<03:14,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2865/3038 [53:17<03:13,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2866/3038 [53:17<03:11,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2867/3038 [53:18<03:10,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2868/3038 [53:18<03:09,  1.12s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2869/3038 [53:18<03:08,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  94% 2870/3038 [53:19<03:07,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2871/3038 [53:19<03:06,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2872/3038 [53:20<03:04,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2873/3038 [53:20<03:03,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2874/3038 [53:20<03:02,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2875/3038 [53:21<03:01,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2876/3038 [53:21<03:00,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2877/3038 [53:22<02:59,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2878/3038 [53:22<02:58,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2879/3038 [53:23<02:56,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2880/3038 [53:23<02:55,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2881/3038 [53:23<02:54,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2882/3038 [53:24<02:53,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2883/3038 [53:24<02:52,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2884/3038 [53:25<02:51,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2885/3038 [53:25<02:49,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2886/3038 [53:25<02:48,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2887/3038 [53:26<02:47,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2888/3038 [53:26<02:46,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2889/3038 [53:27<02:45,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2890/3038 [53:27<02:44,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2891/3038 [53:28<02:43,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2892/3038 [53:28<02:41,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2893/3038 [53:28<02:40,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2894/3038 [53:29<02:39,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2895/3038 [53:29<02:38,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2896/3038 [53:30<02:37,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2897/3038 [53:30<02:36,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2898/3038 [53:30<02:35,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2899/3038 [53:31<02:33,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2900/3038 [53:31<02:32,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  95% 2901/3038 [53:32<02:31,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2902/3038 [53:32<02:30,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2903/3038 [53:32<02:29,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2904/3038 [53:33<02:28,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2905/3038 [53:33<02:27,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2906/3038 [53:34<02:26,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2907/3038 [53:34<02:24,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2908/3038 [53:35<02:23,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2909/3038 [53:35<02:22,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2910/3038 [53:35<02:21,  1.11s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2911/3038 [53:36<02:20,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2912/3038 [53:36<02:19,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2913/3038 [53:37<02:18,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2914/3038 [53:37<02:16,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2915/3038 [53:37<02:15,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2916/3038 [53:38<02:14,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2917/3038 [53:38<02:13,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2918/3038 [53:39<02:12,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2919/3038 [53:39<02:11,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2920/3038 [53:40<02:10,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2921/3038 [53:40<02:08,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2922/3038 [53:40<02:07,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2923/3038 [53:41<02:06,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2924/3038 [53:41<02:05,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2925/3038 [53:42<02:04,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2926/3038 [53:42<02:03,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2927/3038 [53:42<02:02,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2928/3038 [53:43<02:01,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2929/3038 [53:43<01:59,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2930/3038 [53:44<01:58,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  96% 2931/3038 [53:44<01:57,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2932/3038 [53:45<01:56,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2933/3038 [53:45<01:55,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2934/3038 [53:45<01:54,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2935/3038 [53:46<01:53,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2936/3038 [53:46<01:52,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2937/3038 [53:47<01:50,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2938/3038 [53:47<01:49,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2939/3038 [53:47<01:48,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2940/3038 [53:48<01:47,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2941/3038 [53:48<01:46,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2942/3038 [53:49<01:45,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2943/3038 [53:49<01:44,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2944/3038 [53:49<01:43,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2945/3038 [53:50<01:42,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2946/3038 [53:50<01:40,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2947/3038 [53:51<01:39,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2948/3038 [53:51<01:38,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2949/3038 [53:52<01:37,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2950/3038 [53:52<01:36,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2951/3038 [53:52<01:35,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2952/3038 [53:53<01:34,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2953/3038 [53:53<01:33,  1.10s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2954/3038 [53:54<01:31,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2955/3038 [53:54<01:30,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2956/3038 [53:54<01:29,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2957/3038 [53:55<01:28,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2958/3038 [53:55<01:27,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2959/3038 [53:56<01:26,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2960/3038 [53:56<01:25,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2961/3038 [53:57<01:24,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  97% 2962/3038 [53:57<01:23,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2963/3038 [53:57<01:21,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2964/3038 [53:58<01:20,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2965/3038 [53:58<01:19,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2966/3038 [53:59<01:18,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2967/3038 [53:59<01:17,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2968/3038 [53:59<01:16,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2969/3038 [54:00<01:15,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2970/3038 [54:00<01:14,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2971/3038 [54:01<01:13,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2972/3038 [54:01<01:11,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2973/3038 [54:01<01:10,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2974/3038 [54:02<01:09,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2975/3038 [54:02<01:08,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2976/3038 [54:03<01:07,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2977/3038 [54:03<01:06,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2978/3038 [54:04<01:05,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2979/3038 [54:04<01:04,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2980/3038 [54:04<01:03,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2981/3038 [54:05<01:02,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2982/3038 [54:05<01:00,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2983/3038 [54:06<00:59,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2984/3038 [54:06<00:58,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2985/3038 [54:06<00:57,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2986/3038 [54:07<00:56,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2987/3038 [54:07<00:55,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2988/3038 [54:08<00:54,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2989/3038 [54:08<00:53,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2990/3038 [54:09<00:52,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2991/3038 [54:09<00:51,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  98% 2992/3038 [54:09<00:49,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2993/3038 [54:10<00:48,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2994/3038 [54:10<00:47,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2995/3038 [54:11<00:46,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2996/3038 [54:11<00:45,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2997/3038 [54:11<00:44,  1.09s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2998/3038 [54:12<00:43,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 2999/3038 [54:12<00:42,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3000/3038 [54:13<00:41,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3001/3038 [54:13<00:40,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3002/3038 [54:13<00:39,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3003/3038 [54:14<00:37,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3004/3038 [54:14<00:36,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3005/3038 [54:15<00:35,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3006/3038 [54:15<00:34,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3007/3038 [54:16<00:33,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3008/3038 [54:16<00:32,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3009/3038 [54:16<00:31,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3010/3038 [54:17<00:30,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3011/3038 [54:17<00:29,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3012/3038 [54:18<00:28,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3013/3038 [54:18<00:27,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3014/3038 [54:18<00:25,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3015/3038 [54:19<00:24,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3016/3038 [54:19<00:23,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3017/3038 [54:20<00:22,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3018/3038 [54:20<00:21,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3019/3038 [54:20<00:20,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3020/3038 [54:21<00:19,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3021/3038 [54:21<00:18,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4:  99% 3022/3038 [54:22<00:17,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3023/3038 [54:22<00:16,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3024/3038 [54:23<00:15,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3025/3038 [54:23<00:14,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3026/3038 [54:23<00:12,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3027/3038 [54:24<00:11,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3028/3038 [54:24<00:10,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3029/3038 [54:25<00:09,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3030/3038 [54:25<00:08,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3031/3038 [54:25<00:07,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3032/3038 [54:26<00:06,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3033/3038 [54:26<00:05,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3034/3038 [54:27<00:04,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3035/3038 [54:27<00:03,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3036/3038 [54:28<00:02,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3037/3038 [54:28<00:01,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.660]\n","Epoch 4: 100% 3038/3038 [54:28<00:00,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.740]\n","Epoch 4: 100% 3038/3038 [54:28<00:00,  1.08s/it, loss=0.825, v_num=5, train_loss=0.664, val_loss=1.740]Epoch 4, global step 13500: 'val_loss' was not in top 3\n","Epoch 5:  89% 2700/3038 [52:31<06:34,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 5:  89% 2701/3038 [52:32<06:33,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2702/3038 [52:32<06:32,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2703/3038 [52:32<06:30,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2704/3038 [52:33<06:29,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2705/3038 [52:33<06:28,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2706/3038 [52:34<06:26,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2707/3038 [52:34<06:25,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2708/3038 [52:35<06:24,  1.17s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2709/3038 [52:35<06:23,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2710/3038 [52:35<06:21,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2711/3038 [52:36<06:20,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2712/3038 [52:36<06:19,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2713/3038 [52:37<06:18,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2714/3038 [52:37<06:16,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2715/3038 [52:37<06:15,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2716/3038 [52:38<06:14,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2717/3038 [52:38<06:13,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2718/3038 [52:39<06:11,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  89% 2719/3038 [52:39<06:10,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2720/3038 [52:40<06:09,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2721/3038 [52:40<06:08,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2722/3038 [52:40<06:06,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2723/3038 [52:41<06:05,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2724/3038 [52:41<06:04,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2725/3038 [52:42<06:03,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2726/3038 [52:42<06:01,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2727/3038 [52:42<06:00,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2728/3038 [52:43<05:59,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2729/3038 [52:43<05:58,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2730/3038 [52:44<05:56,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2731/3038 [52:44<05:55,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2732/3038 [52:45<05:54,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2733/3038 [52:45<05:53,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2734/3038 [52:45<05:52,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2735/3038 [52:46<05:50,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2736/3038 [52:46<05:49,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2737/3038 [52:47<05:48,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2738/3038 [52:47<05:47,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2739/3038 [52:47<05:45,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2740/3038 [52:48<05:44,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2741/3038 [52:48<05:43,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2742/3038 [52:49<05:42,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2743/3038 [52:49<05:40,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2744/3038 [52:50<05:39,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2745/3038 [52:50<05:38,  1.16s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2746/3038 [52:50<05:37,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2747/3038 [52:51<05:35,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2748/3038 [52:51<05:34,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  90% 2749/3038 [52:52<05:33,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2750/3038 [52:52<05:32,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2751/3038 [52:52<05:31,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2752/3038 [52:53<05:29,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2753/3038 [52:53<05:28,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2754/3038 [52:54<05:27,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2755/3038 [52:54<05:26,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2756/3038 [52:55<05:24,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2757/3038 [52:55<05:23,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2758/3038 [52:55<05:22,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2759/3038 [52:56<05:21,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2760/3038 [52:56<05:19,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2761/3038 [52:57<05:18,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2762/3038 [52:57<05:17,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2763/3038 [52:58<05:16,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2764/3038 [52:58<05:15,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2765/3038 [52:58<05:13,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2766/3038 [52:59<05:12,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2767/3038 [52:59<05:11,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2768/3038 [53:00<05:10,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2769/3038 [53:00<05:08,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2770/3038 [53:00<05:07,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2771/3038 [53:01<05:06,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2772/3038 [53:01<05:05,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2773/3038 [53:02<05:04,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2774/3038 [53:02<05:02,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2775/3038 [53:03<05:01,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2776/3038 [53:03<05:00,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2777/3038 [53:03<04:59,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2778/3038 [53:04<04:58,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  91% 2779/3038 [53:04<04:56,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2780/3038 [53:05<04:55,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2781/3038 [53:05<04:54,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2782/3038 [53:05<04:53,  1.15s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2783/3038 [53:06<04:51,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2784/3038 [53:06<04:50,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2785/3038 [53:07<04:49,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2786/3038 [53:07<04:48,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2787/3038 [53:08<04:47,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2788/3038 [53:08<04:45,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2789/3038 [53:08<04:44,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2790/3038 [53:09<04:43,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2791/3038 [53:09<04:42,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2792/3038 [53:10<04:41,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2793/3038 [53:10<04:39,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2794/3038 [53:10<04:38,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2795/3038 [53:11<04:37,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2796/3038 [53:11<04:36,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2797/3038 [53:12<04:35,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2798/3038 [53:12<04:33,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2799/3038 [53:13<04:32,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2800/3038 [53:13<04:31,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2801/3038 [53:13<04:30,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2802/3038 [53:14<04:29,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2803/3038 [53:14<04:27,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2804/3038 [53:15<04:26,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2805/3038 [53:15<04:25,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2806/3038 [53:16<04:24,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2807/3038 [53:16<04:23,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2808/3038 [53:16<04:21,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2809/3038 [53:17<04:20,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  92% 2810/3038 [53:17<04:19,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2811/3038 [53:18<04:18,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2812/3038 [53:18<04:17,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2813/3038 [53:18<04:15,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2814/3038 [53:19<04:14,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2815/3038 [53:19<04:13,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2816/3038 [53:20<04:12,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2817/3038 [53:20<04:11,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2818/3038 [53:21<04:09,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2819/3038 [53:21<04:08,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2820/3038 [53:21<04:07,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2821/3038 [53:22<04:06,  1.14s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2822/3038 [53:22<04:05,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2823/3038 [53:23<04:03,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2824/3038 [53:23<04:02,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2825/3038 [53:23<04:01,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2826/3038 [53:24<04:00,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2827/3038 [53:24<03:59,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2828/3038 [53:25<03:58,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2829/3038 [53:25<03:56,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2830/3038 [53:26<03:55,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2831/3038 [53:26<03:54,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2832/3038 [53:26<03:53,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2833/3038 [53:27<03:52,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2834/3038 [53:27<03:50,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2835/3038 [53:28<03:49,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2836/3038 [53:28<03:48,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2837/3038 [53:29<03:47,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2838/3038 [53:29<03:46,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2839/3038 [53:29<03:44,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  93% 2840/3038 [53:30<03:43,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2841/3038 [53:30<03:42,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2842/3038 [53:31<03:41,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2843/3038 [53:31<03:40,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2844/3038 [53:31<03:39,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2845/3038 [53:32<03:37,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2846/3038 [53:32<03:36,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2847/3038 [53:33<03:35,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2848/3038 [53:33<03:34,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2849/3038 [53:34<03:33,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2850/3038 [53:34<03:32,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2851/3038 [53:34<03:30,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2852/3038 [53:35<03:29,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2853/3038 [53:35<03:28,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2854/3038 [53:36<03:27,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2855/3038 [53:36<03:26,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2856/3038 [53:36<03:25,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2857/3038 [53:37<03:23,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2858/3038 [53:37<03:22,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2859/3038 [53:38<03:21,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2860/3038 [53:38<03:20,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2861/3038 [53:39<03:19,  1.13s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2862/3038 [53:39<03:17,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2863/3038 [53:39<03:16,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2864/3038 [53:40<03:15,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2865/3038 [53:40<03:14,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2866/3038 [53:41<03:13,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2867/3038 [53:41<03:12,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2868/3038 [53:42<03:10,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2869/3038 [53:42<03:09,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  94% 2870/3038 [53:42<03:08,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2871/3038 [53:43<03:07,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2872/3038 [53:43<03:06,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2873/3038 [53:44<03:05,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2874/3038 [53:44<03:04,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2875/3038 [53:44<03:02,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2876/3038 [53:45<03:01,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2877/3038 [53:45<03:00,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2878/3038 [53:46<02:59,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2879/3038 [53:46<02:58,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2880/3038 [53:47<02:57,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2881/3038 [53:47<02:55,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2882/3038 [53:47<02:54,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2883/3038 [53:48<02:53,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2884/3038 [53:48<02:52,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2885/3038 [53:49<02:51,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2886/3038 [53:49<02:50,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2887/3038 [53:50<02:48,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2888/3038 [53:50<02:47,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2889/3038 [53:50<02:46,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2890/3038 [53:51<02:45,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2891/3038 [53:51<02:44,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2892/3038 [53:52<02:43,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2893/3038 [53:52<02:42,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2894/3038 [53:52<02:40,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2895/3038 [53:53<02:39,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2896/3038 [53:53<02:38,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2897/3038 [53:54<02:37,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2898/3038 [53:54<02:36,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2899/3038 [53:55<02:35,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2900/3038 [53:55<02:33,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  95% 2901/3038 [53:55<02:32,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2902/3038 [53:56<02:31,  1.12s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2903/3038 [53:56<02:30,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2904/3038 [53:57<02:29,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2905/3038 [53:57<02:28,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2906/3038 [53:58<02:27,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2907/3038 [53:58<02:25,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2908/3038 [53:58<02:24,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2909/3038 [53:59<02:23,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2910/3038 [53:59<02:22,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2911/3038 [54:00<02:21,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2912/3038 [54:00<02:20,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2913/3038 [54:00<02:19,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2914/3038 [54:01<02:17,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2915/3038 [54:01<02:16,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2916/3038 [54:02<02:15,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2917/3038 [54:02<02:14,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2918/3038 [54:03<02:13,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2919/3038 [54:03<02:12,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2920/3038 [54:03<02:11,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2921/3038 [54:04<02:09,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2922/3038 [54:04<02:08,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2923/3038 [54:05<02:07,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2924/3038 [54:05<02:06,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2925/3038 [54:05<02:05,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2926/3038 [54:06<02:04,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2927/3038 [54:06<02:03,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2928/3038 [54:07<02:01,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2929/3038 [54:07<02:00,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2930/3038 [54:08<01:59,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  96% 2931/3038 [54:08<01:58,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2932/3038 [54:08<01:57,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2933/3038 [54:09<01:56,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2934/3038 [54:09<01:55,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2935/3038 [54:10<01:54,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2936/3038 [54:10<01:52,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2937/3038 [54:11<01:51,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2938/3038 [54:11<01:50,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2939/3038 [54:11<01:49,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2940/3038 [54:12<01:48,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2941/3038 [54:12<01:47,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2942/3038 [54:13<01:46,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2943/3038 [54:13<01:45,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2944/3038 [54:13<01:43,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2945/3038 [54:14<01:42,  1.11s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2946/3038 [54:14<01:41,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2947/3038 [54:15<01:40,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2948/3038 [54:15<01:39,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2949/3038 [54:16<01:38,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2950/3038 [54:16<01:37,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2951/3038 [54:16<01:36,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2952/3038 [54:17<01:34,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2953/3038 [54:17<01:33,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2954/3038 [54:18<01:32,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2955/3038 [54:18<01:31,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2956/3038 [54:18<01:30,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2957/3038 [54:19<01:29,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2958/3038 [54:19<01:28,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2959/3038 [54:20<01:27,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2960/3038 [54:20<01:25,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2961/3038 [54:21<01:24,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  97% 2962/3038 [54:21<01:23,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2963/3038 [54:21<01:22,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2964/3038 [54:22<01:21,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2965/3038 [54:22<01:20,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2966/3038 [54:23<01:19,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2967/3038 [54:23<01:18,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2968/3038 [54:24<01:16,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2969/3038 [54:24<01:15,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2970/3038 [54:24<01:14,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2971/3038 [54:25<01:13,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2972/3038 [54:25<01:12,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2973/3038 [54:26<01:11,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2974/3038 [54:26<01:10,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2975/3038 [54:26<01:09,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2976/3038 [54:27<01:08,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2977/3038 [54:27<01:06,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2978/3038 [54:28<01:05,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2979/3038 [54:28<01:04,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2980/3038 [54:29<01:03,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2981/3038 [54:29<01:02,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2982/3038 [54:29<01:01,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2983/3038 [54:30<01:00,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2984/3038 [54:30<00:59,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2985/3038 [54:31<00:58,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2986/3038 [54:31<00:56,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2987/3038 [54:31<00:55,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2988/3038 [54:32<00:54,  1.10s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2989/3038 [54:32<00:53,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2990/3038 [54:33<00:52,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2991/3038 [54:33<00:51,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  98% 2992/3038 [54:34<00:50,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2993/3038 [54:34<00:49,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2994/3038 [54:34<00:48,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2995/3038 [54:35<00:47,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2996/3038 [54:35<00:45,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2997/3038 [54:36<00:44,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2998/3038 [54:36<00:43,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 2999/3038 [54:37<00:42,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3000/3038 [54:37<00:41,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3001/3038 [54:37<00:40,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3002/3038 [54:38<00:39,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3003/3038 [54:38<00:38,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3004/3038 [54:39<00:37,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3005/3038 [54:39<00:36,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3006/3038 [54:39<00:34,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3007/3038 [54:40<00:33,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3008/3038 [54:40<00:32,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3009/3038 [54:41<00:31,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3010/3038 [54:41<00:30,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3011/3038 [54:42<00:29,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3012/3038 [54:42<00:28,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3013/3038 [54:42<00:27,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3014/3038 [54:43<00:26,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3015/3038 [54:43<00:25,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3016/3038 [54:44<00:23,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3017/3038 [54:44<00:22,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3018/3038 [54:45<00:21,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3019/3038 [54:45<00:20,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3020/3038 [54:45<00:19,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3021/3038 [54:46<00:18,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5:  99% 3022/3038 [54:46<00:17,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3023/3038 [54:47<00:16,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3024/3038 [54:47<00:15,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3025/3038 [54:47<00:14,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3026/3038 [54:48<00:13,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3027/3038 [54:48<00:11,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3028/3038 [54:49<00:10,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3029/3038 [54:49<00:09,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3030/3038 [54:50<00:08,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3031/3038 [54:50<00:07,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3032/3038 [54:50<00:06,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3033/3038 [54:51<00:05,  1.09s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3034/3038 [54:51<00:04,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3035/3038 [54:52<00:03,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3036/3038 [54:52<00:02,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3037/3038 [54:52<00:01,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.740]\n","Epoch 5: 100% 3038/3038 [54:53<00:00,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.790]\n","Epoch 5: 100% 3038/3038 [54:53<00:00,  1.08s/it, loss=0.898, v_num=5, train_loss=0.924, val_loss=1.790]Epoch 5, global step 16200: 'val_loss' was not in top 3\n","Epoch 6:  89% 2700/3038 [52:15<06:32,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 6:  89% 2701/3038 [52:15<06:31,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2702/3038 [52:16<06:30,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2703/3038 [52:16<06:28,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2704/3038 [52:17<06:27,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2705/3038 [52:17<06:26,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2706/3038 [52:17<06:24,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2707/3038 [52:18<06:23,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2708/3038 [52:18<06:22,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2709/3038 [52:19<06:21,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2710/3038 [52:19<06:19,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2711/3038 [52:20<06:18,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2712/3038 [52:20<06:17,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2713/3038 [52:20<06:16,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2714/3038 [52:21<06:15,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2715/3038 [52:21<06:13,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2716/3038 [52:22<06:12,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2717/3038 [52:22<06:11,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2718/3038 [52:22<06:10,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  89% 2719/3038 [52:23<06:08,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2720/3038 [52:23<06:07,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2721/3038 [52:24<06:06,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2722/3038 [52:24<06:05,  1.16s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2723/3038 [52:25<06:03,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2724/3038 [52:25<06:02,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2725/3038 [52:25<06:01,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2726/3038 [52:26<06:00,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2727/3038 [52:26<05:58,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2728/3038 [52:27<05:57,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2729/3038 [52:27<05:56,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2730/3038 [52:27<05:55,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2731/3038 [52:28<05:53,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2732/3038 [52:28<05:52,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2733/3038 [52:29<05:51,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2734/3038 [52:29<05:50,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2735/3038 [52:30<05:48,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2736/3038 [52:30<05:47,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2737/3038 [52:30<05:46,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2738/3038 [52:31<05:45,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2739/3038 [52:31<05:44,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2740/3038 [52:32<05:42,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2741/3038 [52:32<05:41,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2742/3038 [52:32<05:40,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2743/3038 [52:33<05:39,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2744/3038 [52:33<05:37,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2745/3038 [52:34<05:36,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2746/3038 [52:34<05:35,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2747/3038 [52:35<05:34,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2748/3038 [52:35<05:32,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  90% 2749/3038 [52:35<05:31,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2750/3038 [52:36<05:30,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2751/3038 [52:36<05:29,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2752/3038 [52:37<05:28,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2753/3038 [52:37<05:26,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2754/3038 [52:37<05:25,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2755/3038 [52:38<05:24,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2756/3038 [52:38<05:23,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2757/3038 [52:39<05:21,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2758/3038 [52:39<05:20,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2759/3038 [52:40<05:19,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2760/3038 [52:40<05:18,  1.15s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2761/3038 [52:40<05:17,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2762/3038 [52:41<05:15,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2763/3038 [52:41<05:14,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2764/3038 [52:42<05:13,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2765/3038 [52:42<05:12,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2766/3038 [52:42<05:11,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2767/3038 [52:43<05:09,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2768/3038 [52:43<05:08,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2769/3038 [52:44<05:07,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2770/3038 [52:44<05:06,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2771/3038 [52:45<05:04,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2772/3038 [52:45<05:03,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2773/3038 [52:45<05:02,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2774/3038 [52:46<05:01,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2775/3038 [52:46<05:00,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2776/3038 [52:47<04:58,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2777/3038 [52:47<04:57,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2778/3038 [52:47<04:56,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  91% 2779/3038 [52:48<04:55,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2780/3038 [52:48<04:54,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2781/3038 [52:49<04:52,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2782/3038 [52:49<04:51,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2783/3038 [52:50<04:50,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2784/3038 [52:50<04:49,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2785/3038 [52:50<04:48,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2786/3038 [52:51<04:46,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2787/3038 [52:51<04:45,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2788/3038 [52:52<04:44,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2789/3038 [52:52<04:43,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2790/3038 [52:52<04:42,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2791/3038 [52:53<04:40,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2792/3038 [52:53<04:39,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2793/3038 [52:54<04:38,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2794/3038 [52:54<04:37,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2795/3038 [52:55<04:36,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2796/3038 [52:55<04:34,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2797/3038 [52:55<04:33,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2798/3038 [52:56<04:32,  1.14s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2799/3038 [52:56<04:31,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2800/3038 [52:57<04:30,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2801/3038 [52:57<04:28,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2802/3038 [52:57<04:27,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2803/3038 [52:58<04:26,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2804/3038 [52:58<04:25,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2805/3038 [52:59<04:24,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2806/3038 [52:59<04:22,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2807/3038 [53:00<04:21,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2808/3038 [53:00<04:20,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2809/3038 [53:00<04:19,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  92% 2810/3038 [53:01<04:18,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2811/3038 [53:01<04:16,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2812/3038 [53:02<04:15,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2813/3038 [53:02<04:14,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2814/3038 [53:02<04:13,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2815/3038 [53:03<04:12,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2816/3038 [53:03<04:10,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2817/3038 [53:04<04:09,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2818/3038 [53:04<04:08,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2819/3038 [53:05<04:07,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2820/3038 [53:05<04:06,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2821/3038 [53:05<04:05,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2822/3038 [53:06<04:03,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2823/3038 [53:06<04:02,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2824/3038 [53:07<04:01,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2825/3038 [53:07<04:00,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2826/3038 [53:07<03:59,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2827/3038 [53:08<03:57,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2828/3038 [53:08<03:56,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2829/3038 [53:09<03:55,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2830/3038 [53:09<03:54,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2831/3038 [53:10<03:53,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2832/3038 [53:10<03:52,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2833/3038 [53:10<03:50,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2834/3038 [53:11<03:49,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2835/3038 [53:11<03:48,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2836/3038 [53:12<03:47,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2837/3038 [53:12<03:46,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2838/3038 [53:13<03:45,  1.13s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2839/3038 [53:13<03:43,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  93% 2840/3038 [53:13<03:42,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2841/3038 [53:14<03:41,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2842/3038 [53:14<03:40,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2843/3038 [53:15<03:39,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2844/3038 [53:15<03:37,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2845/3038 [53:15<03:36,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2846/3038 [53:16<03:35,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2847/3038 [53:16<03:34,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2848/3038 [53:17<03:33,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2849/3038 [53:17<03:32,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2850/3038 [53:18<03:30,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2851/3038 [53:18<03:29,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2852/3038 [53:18<03:28,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2853/3038 [53:19<03:27,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2854/3038 [53:19<03:26,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2855/3038 [53:20<03:25,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2856/3038 [53:20<03:23,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2857/3038 [53:20<03:22,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2858/3038 [53:21<03:21,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2859/3038 [53:21<03:20,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2860/3038 [53:22<03:19,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2861/3038 [53:22<03:18,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2862/3038 [53:23<03:16,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2863/3038 [53:23<03:15,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2864/3038 [53:23<03:14,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2865/3038 [53:24<03:13,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2866/3038 [53:24<03:12,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2867/3038 [53:25<03:11,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2868/3038 [53:25<03:10,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2869/3038 [53:25<03:08,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  94% 2870/3038 [53:26<03:07,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2871/3038 [53:26<03:06,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2872/3038 [53:27<03:05,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2873/3038 [53:27<03:04,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2874/3038 [53:28<03:03,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2875/3038 [53:28<03:01,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2876/3038 [53:28<03:00,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2877/3038 [53:29<02:59,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2878/3038 [53:29<02:58,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2879/3038 [53:30<02:57,  1.12s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2880/3038 [53:30<02:56,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2881/3038 [53:30<02:54,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2882/3038 [53:31<02:53,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2883/3038 [53:31<02:52,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2884/3038 [53:32<02:51,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2885/3038 [53:32<02:50,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2886/3038 [53:33<02:49,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2887/3038 [53:33<02:48,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2888/3038 [53:33<02:46,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2889/3038 [53:34<02:45,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2890/3038 [53:34<02:44,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2891/3038 [53:35<02:43,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2892/3038 [53:35<02:42,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2893/3038 [53:35<02:41,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2894/3038 [53:36<02:40,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2895/3038 [53:36<02:38,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2896/3038 [53:37<02:37,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2897/3038 [53:37<02:36,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2898/3038 [53:38<02:35,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2899/3038 [53:38<02:34,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2900/3038 [53:38<02:33,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  95% 2901/3038 [53:39<02:32,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2902/3038 [53:39<02:30,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2903/3038 [53:40<02:29,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2904/3038 [53:40<02:28,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2905/3038 [53:40<02:27,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2906/3038 [53:41<02:26,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2907/3038 [53:41<02:25,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2908/3038 [53:42<02:24,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2909/3038 [53:42<02:22,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2910/3038 [53:43<02:21,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2911/3038 [53:43<02:20,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2912/3038 [53:43<02:19,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2913/3038 [53:44<02:18,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2914/3038 [53:44<02:17,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2915/3038 [53:45<02:16,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2916/3038 [53:45<02:14,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2917/3038 [53:46<02:13,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2918/3038 [53:46<02:12,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2919/3038 [53:46<02:11,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2920/3038 [53:47<02:10,  1.11s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2921/3038 [53:47<02:09,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2922/3038 [53:48<02:08,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2923/3038 [53:48<02:07,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2924/3038 [53:48<02:05,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2925/3038 [53:49<02:04,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2926/3038 [53:49<02:03,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2927/3038 [53:50<02:02,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2928/3038 [53:50<02:01,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2929/3038 [53:51<02:00,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2930/3038 [53:51<01:59,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  96% 2931/3038 [53:51<01:57,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2932/3038 [53:52<01:56,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2933/3038 [53:52<01:55,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2934/3038 [53:53<01:54,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2935/3038 [53:53<01:53,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2936/3038 [53:53<01:52,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2937/3038 [53:54<01:51,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2938/3038 [53:54<01:50,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2939/3038 [53:55<01:48,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2940/3038 [53:55<01:47,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2941/3038 [53:56<01:46,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2942/3038 [53:56<01:45,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2943/3038 [53:56<01:44,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2944/3038 [53:57<01:43,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2945/3038 [53:57<01:42,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2946/3038 [53:58<01:41,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2947/3038 [53:58<01:40,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2948/3038 [53:58<01:38,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2949/3038 [53:59<01:37,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2950/3038 [53:59<01:36,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2951/3038 [54:00<01:35,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2952/3038 [54:00<01:34,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2953/3038 [54:01<01:33,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2954/3038 [54:01<01:32,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2955/3038 [54:01<01:31,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2956/3038 [54:02<01:29,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2957/3038 [54:02<01:28,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2958/3038 [54:03<01:27,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2959/3038 [54:03<01:26,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2960/3038 [54:03<01:25,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2961/3038 [54:04<01:24,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  97% 2962/3038 [54:04<01:23,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2963/3038 [54:05<01:22,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2964/3038 [54:05<01:21,  1.10s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2965/3038 [54:06<01:19,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2966/3038 [54:06<01:18,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2967/3038 [54:06<01:17,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2968/3038 [54:07<01:16,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2969/3038 [54:07<01:15,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2970/3038 [54:08<01:14,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2971/3038 [54:08<01:13,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2972/3038 [54:08<01:12,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2973/3038 [54:09<01:11,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2974/3038 [54:09<01:09,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2975/3038 [54:10<01:08,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2976/3038 [54:10<01:07,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2977/3038 [54:11<01:06,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2978/3038 [54:11<01:05,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2979/3038 [54:11<01:04,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2980/3038 [54:12<01:03,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2981/3038 [54:12<01:02,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2982/3038 [54:13<01:01,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2983/3038 [54:13<00:59,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2984/3038 [54:14<00:58,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2985/3038 [54:14<00:57,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2986/3038 [54:14<00:56,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2987/3038 [54:15<00:55,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2988/3038 [54:15<00:54,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2989/3038 [54:16<00:53,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2990/3038 [54:16<00:52,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2991/3038 [54:16<00:51,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  98% 2992/3038 [54:17<00:50,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2993/3038 [54:17<00:48,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2994/3038 [54:18<00:47,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2995/3038 [54:18<00:46,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2996/3038 [54:19<00:45,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2997/3038 [54:19<00:44,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2998/3038 [54:19<00:43,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 2999/3038 [54:20<00:42,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3000/3038 [54:20<00:41,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3001/3038 [54:21<00:40,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3002/3038 [54:21<00:39,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3003/3038 [54:21<00:38,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3004/3038 [54:22<00:36,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3005/3038 [54:22<00:35,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3006/3038 [54:23<00:34,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3007/3038 [54:23<00:33,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3008/3038 [54:24<00:32,  1.09s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3009/3038 [54:24<00:31,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3010/3038 [54:24<00:30,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3011/3038 [54:25<00:29,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3012/3038 [54:25<00:28,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3013/3038 [54:26<00:27,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3014/3038 [54:26<00:26,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3015/3038 [54:26<00:24,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3016/3038 [54:27<00:23,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3017/3038 [54:27<00:22,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3018/3038 [54:28<00:21,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3019/3038 [54:28<00:20,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3020/3038 [54:28<00:19,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3021/3038 [54:29<00:18,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6:  99% 3022/3038 [54:29<00:17,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3023/3038 [54:30<00:16,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3024/3038 [54:30<00:15,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3025/3038 [54:31<00:14,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3026/3038 [54:31<00:12,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3027/3038 [54:31<00:11,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3028/3038 [54:32<00:10,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3029/3038 [54:32<00:09,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3030/3038 [54:33<00:08,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3031/3038 [54:33<00:07,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3032/3038 [54:33<00:06,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3033/3038 [54:34<00:05,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3034/3038 [54:34<00:04,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3035/3038 [54:35<00:03,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3036/3038 [54:35<00:02,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3037/3038 [54:36<00:01,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.790]\n","Epoch 6: 100% 3038/3038 [54:36<00:00,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.860]\n","Epoch 6: 100% 3038/3038 [54:36<00:00,  1.08s/it, loss=0.651, v_num=5, train_loss=0.944, val_loss=1.860]Epoch 6, global step 18900: 'val_loss' was not in top 3\n","Epoch 7:  89% 2700/3038 [52:32<06:34,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 7:  89% 2701/3038 [52:33<06:33,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2702/3038 [52:33<06:32,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2703/3038 [52:34<06:30,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2704/3038 [52:34<06:29,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2705/3038 [52:34<06:28,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2706/3038 [52:35<06:27,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2707/3038 [52:35<06:25,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2708/3038 [52:36<06:24,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2709/3038 [52:36<06:23,  1.17s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2710/3038 [52:37<06:22,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2711/3038 [52:37<06:20,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2712/3038 [52:37<06:19,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2713/3038 [52:38<06:18,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2714/3038 [52:38<06:17,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2715/3038 [52:39<06:15,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2716/3038 [52:39<06:14,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2717/3038 [52:39<06:13,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2718/3038 [52:40<06:12,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  89% 2719/3038 [52:40<06:10,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2720/3038 [52:41<06:09,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2721/3038 [52:41<06:08,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2722/3038 [52:42<06:07,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2723/3038 [52:42<06:05,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2724/3038 [52:42<06:04,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2725/3038 [52:43<06:03,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2726/3038 [52:43<06:02,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2727/3038 [52:44<06:00,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2728/3038 [52:44<05:59,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2729/3038 [52:44<05:58,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2730/3038 [52:45<05:57,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2731/3038 [52:45<05:55,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2732/3038 [52:46<05:54,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2733/3038 [52:46<05:53,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2734/3038 [52:47<05:52,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2735/3038 [52:47<05:50,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2736/3038 [52:47<05:49,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2737/3038 [52:48<05:48,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2738/3038 [52:48<05:47,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2739/3038 [52:49<05:45,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2740/3038 [52:49<05:44,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2741/3038 [52:50<05:43,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2742/3038 [52:50<05:42,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2743/3038 [52:50<05:41,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2744/3038 [52:51<05:39,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2745/3038 [52:51<05:38,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2746/3038 [52:52<05:37,  1.16s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2747/3038 [52:52<05:36,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2748/3038 [52:53<05:34,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  90% 2749/3038 [52:53<05:33,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2750/3038 [52:53<05:32,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2751/3038 [52:54<05:31,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2752/3038 [52:54<05:29,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2753/3038 [52:55<05:28,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2754/3038 [52:55<05:27,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2755/3038 [52:55<05:26,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2756/3038 [52:56<05:25,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2757/3038 [52:56<05:23,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2758/3038 [52:57<05:22,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2759/3038 [52:57<05:21,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2760/3038 [52:58<05:20,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2761/3038 [52:58<05:18,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2762/3038 [52:58<05:17,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2763/3038 [52:59<05:16,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2764/3038 [52:59<05:15,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2765/3038 [53:00<05:13,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2766/3038 [53:00<05:12,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2767/3038 [53:01<05:11,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2768/3038 [53:01<05:10,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2769/3038 [53:01<05:09,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2770/3038 [53:02<05:07,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2771/3038 [53:02<05:06,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2772/3038 [53:03<05:05,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2773/3038 [53:03<05:04,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2774/3038 [53:04<05:03,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2775/3038 [53:04<05:01,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2776/3038 [53:04<05:00,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2777/3038 [53:05<04:59,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2778/3038 [53:05<04:58,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  91% 2779/3038 [53:06<04:56,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2780/3038 [53:06<04:55,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2781/3038 [53:06<04:54,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2782/3038 [53:07<04:53,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2783/3038 [53:07<04:52,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2784/3038 [53:08<04:50,  1.15s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2785/3038 [53:08<04:49,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2786/3038 [53:09<04:48,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2787/3038 [53:09<04:47,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2788/3038 [53:09<04:46,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2789/3038 [53:10<04:44,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2790/3038 [53:10<04:43,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2791/3038 [53:11<04:42,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2792/3038 [53:11<04:41,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2793/3038 [53:12<04:40,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2794/3038 [53:12<04:38,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2795/3038 [53:12<04:37,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2796/3038 [53:13<04:36,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2797/3038 [53:13<04:35,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2798/3038 [53:14<04:33,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2799/3038 [53:14<04:32,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2800/3038 [53:14<04:31,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2801/3038 [53:15<04:30,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2802/3038 [53:15<04:29,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2803/3038 [53:16<04:27,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2804/3038 [53:16<04:26,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2805/3038 [53:17<04:25,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2806/3038 [53:17<04:24,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2807/3038 [53:17<04:23,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2808/3038 [53:18<04:21,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2809/3038 [53:18<04:20,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  92% 2810/3038 [53:19<04:19,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2811/3038 [53:19<04:18,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2812/3038 [53:19<04:17,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2813/3038 [53:20<04:15,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2814/3038 [53:20<04:14,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2815/3038 [53:21<04:13,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2816/3038 [53:21<04:12,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2817/3038 [53:22<04:11,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2818/3038 [53:22<04:10,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2819/3038 [53:22<04:08,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2820/3038 [53:23<04:07,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2821/3038 [53:23<04:06,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2822/3038 [53:24<04:05,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2823/3038 [53:24<04:04,  1.14s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2824/3038 [53:25<04:02,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2825/3038 [53:25<04:01,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2826/3038 [53:25<04:00,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2827/3038 [53:26<03:59,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2828/3038 [53:26<03:58,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2829/3038 [53:27<03:56,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2830/3038 [53:27<03:55,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2831/3038 [53:27<03:54,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2832/3038 [53:28<03:53,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2833/3038 [53:28<03:52,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2834/3038 [53:29<03:51,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2835/3038 [53:29<03:49,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2836/3038 [53:30<03:48,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2837/3038 [53:30<03:47,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2838/3038 [53:30<03:46,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2839/3038 [53:31<03:45,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  93% 2840/3038 [53:31<03:43,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2841/3038 [53:32<03:42,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2842/3038 [53:32<03:41,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2843/3038 [53:32<03:40,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2844/3038 [53:33<03:39,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2845/3038 [53:33<03:38,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2846/3038 [53:34<03:36,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2847/3038 [53:34<03:35,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2848/3038 [53:35<03:34,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2849/3038 [53:35<03:33,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2850/3038 [53:35<03:32,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2851/3038 [53:36<03:30,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2852/3038 [53:36<03:29,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2853/3038 [53:37<03:28,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2854/3038 [53:37<03:27,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2855/3038 [53:38<03:26,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2856/3038 [53:38<03:25,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2857/3038 [53:38<03:23,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2858/3038 [53:39<03:22,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2859/3038 [53:39<03:21,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2860/3038 [53:40<03:20,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2861/3038 [53:40<03:19,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2862/3038 [53:40<03:18,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2863/3038 [53:41<03:16,  1.13s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2864/3038 [53:41<03:15,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2865/3038 [53:42<03:14,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2866/3038 [53:42<03:13,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2867/3038 [53:43<03:12,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2868/3038 [53:43<03:11,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2869/3038 [53:43<03:09,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  94% 2870/3038 [53:44<03:08,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2871/3038 [53:44<03:07,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2872/3038 [53:45<03:06,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2873/3038 [53:45<03:05,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2874/3038 [53:45<03:04,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2875/3038 [53:46<03:02,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2876/3038 [53:46<03:01,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2877/3038 [53:47<03:00,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2878/3038 [53:47<02:59,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2879/3038 [53:48<02:58,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2880/3038 [53:48<02:57,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2881/3038 [53:48<02:55,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2882/3038 [53:49<02:54,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2883/3038 [53:49<02:53,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2884/3038 [53:50<02:52,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2885/3038 [53:50<02:51,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2886/3038 [53:51<02:50,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2887/3038 [53:51<02:49,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2888/3038 [53:51<02:47,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2889/3038 [53:52<02:46,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2890/3038 [53:52<02:45,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2891/3038 [53:53<02:44,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2892/3038 [53:53<02:43,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2893/3038 [53:53<02:42,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2894/3038 [53:54<02:40,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2895/3038 [53:54<02:39,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2896/3038 [53:55<02:38,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2897/3038 [53:55<02:37,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2898/3038 [53:56<02:36,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2899/3038 [53:56<02:35,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2900/3038 [53:56<02:34,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  95% 2901/3038 [53:57<02:32,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2902/3038 [53:57<02:31,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2903/3038 [53:58<02:30,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2904/3038 [53:58<02:29,  1.12s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2905/3038 [53:58<02:28,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2906/3038 [53:59<02:27,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2907/3038 [53:59<02:25,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2908/3038 [54:00<02:24,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2909/3038 [54:00<02:23,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2910/3038 [54:01<02:22,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2911/3038 [54:01<02:21,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2912/3038 [54:01<02:20,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2913/3038 [54:02<02:19,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2914/3038 [54:02<02:17,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2915/3038 [54:03<02:16,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2916/3038 [54:03<02:15,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2917/3038 [54:03<02:14,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2918/3038 [54:04<02:13,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2919/3038 [54:04<02:12,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2920/3038 [54:05<02:11,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2921/3038 [54:05<02:10,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2922/3038 [54:06<02:08,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2923/3038 [54:06<02:07,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2924/3038 [54:06<02:06,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2925/3038 [54:07<02:05,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2926/3038 [54:07<02:04,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2927/3038 [54:08<02:03,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2928/3038 [54:08<02:02,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2929/3038 [54:09<02:00,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2930/3038 [54:09<01:59,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  96% 2931/3038 [54:09<01:58,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2932/3038 [54:10<01:57,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2933/3038 [54:10<01:56,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2934/3038 [54:11<01:55,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2935/3038 [54:11<01:54,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2936/3038 [54:11<01:52,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2937/3038 [54:12<01:51,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2938/3038 [54:12<01:50,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2939/3038 [54:13<01:49,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2940/3038 [54:13<01:48,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2941/3038 [54:14<01:47,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2942/3038 [54:14<01:46,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2943/3038 [54:14<01:45,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2944/3038 [54:15<01:43,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2945/3038 [54:15<01:42,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2946/3038 [54:16<01:41,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2947/3038 [54:16<01:40,  1.11s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2948/3038 [54:16<01:39,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2949/3038 [54:17<01:38,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2950/3038 [54:17<01:37,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2951/3038 [54:18<01:36,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2952/3038 [54:18<01:34,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2953/3038 [54:19<01:33,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2954/3038 [54:19<01:32,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2955/3038 [54:19<01:31,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2956/3038 [54:20<01:30,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2957/3038 [54:20<01:29,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2958/3038 [54:21<01:28,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2959/3038 [54:21<01:27,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2960/3038 [54:21<01:25,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2961/3038 [54:22<01:24,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  97% 2962/3038 [54:22<01:23,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2963/3038 [54:23<01:22,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2964/3038 [54:23<01:21,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2965/3038 [54:24<01:20,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2966/3038 [54:24<01:19,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2967/3038 [54:24<01:18,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2968/3038 [54:25<01:17,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2969/3038 [54:25<01:15,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2970/3038 [54:26<01:14,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2971/3038 [54:26<01:13,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2972/3038 [54:26<01:12,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2973/3038 [54:27<01:11,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2974/3038 [54:27<01:10,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2975/3038 [54:28<01:09,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2976/3038 [54:28<01:08,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2977/3038 [54:29<01:06,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2978/3038 [54:29<01:05,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2979/3038 [54:29<01:04,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2980/3038 [54:30<01:03,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2981/3038 [54:30<01:02,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2982/3038 [54:31<01:01,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2983/3038 [54:31<01:00,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2984/3038 [54:31<00:59,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2985/3038 [54:32<00:58,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2986/3038 [54:32<00:56,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2987/3038 [54:33<00:55,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2988/3038 [54:33<00:54,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2989/3038 [54:34<00:53,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2990/3038 [54:34<00:52,  1.10s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2991/3038 [54:34<00:51,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  98% 2992/3038 [54:35<00:50,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2993/3038 [54:35<00:49,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2994/3038 [54:36<00:48,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2995/3038 [54:36<00:47,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2996/3038 [54:37<00:45,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2997/3038 [54:37<00:44,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2998/3038 [54:37<00:43,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 2999/3038 [54:38<00:42,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3000/3038 [54:38<00:41,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3001/3038 [54:39<00:40,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3002/3038 [54:39<00:39,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3003/3038 [54:39<00:38,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3004/3038 [54:40<00:37,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3005/3038 [54:40<00:36,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3006/3038 [54:41<00:34,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3007/3038 [54:41<00:33,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3008/3038 [54:42<00:32,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3009/3038 [54:42<00:31,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3010/3038 [54:42<00:30,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3011/3038 [54:43<00:29,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3012/3038 [54:43<00:28,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3013/3038 [54:44<00:27,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3014/3038 [54:44<00:26,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3015/3038 [54:44<00:25,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3016/3038 [54:45<00:23,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3017/3038 [54:45<00:22,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3018/3038 [54:46<00:21,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3019/3038 [54:46<00:20,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3020/3038 [54:47<00:19,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3021/3038 [54:47<00:18,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7:  99% 3022/3038 [54:47<00:17,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3023/3038 [54:48<00:16,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3024/3038 [54:48<00:15,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3025/3038 [54:49<00:14,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3026/3038 [54:49<00:13,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3027/3038 [54:50<00:11,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3028/3038 [54:50<00:10,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3029/3038 [54:50<00:09,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3030/3038 [54:51<00:08,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3031/3038 [54:51<00:07,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3032/3038 [54:52<00:06,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3033/3038 [54:52<00:05,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3034/3038 [54:52<00:04,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3035/3038 [54:53<00:03,  1.09s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3036/3038 [54:53<00:02,  1.08s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3037/3038 [54:54<00:01,  1.08s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.860]\n","Epoch 7: 100% 3038/3038 [54:54<00:00,  1.08s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.930]\n","Epoch 7: 100% 3038/3038 [54:54<00:00,  1.08s/it, loss=0.54, v_num=5, train_loss=0.525, val_loss=1.930]Epoch 7, global step 21600: 'val_loss' was not in top 3\n","Epoch 8:  89% 2700/3038 [52:21<06:33,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 8:  89% 2701/3038 [52:21<06:32,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2702/3038 [52:22<06:30,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2703/3038 [52:22<06:29,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2704/3038 [52:23<06:28,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2705/3038 [52:23<06:26,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2706/3038 [52:23<06:25,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2707/3038 [52:24<06:24,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2708/3038 [52:24<06:23,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2709/3038 [52:25<06:21,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2710/3038 [52:25<06:20,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2711/3038 [52:26<06:19,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2712/3038 [52:26<06:18,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2713/3038 [52:26<06:16,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2714/3038 [52:27<06:15,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2715/3038 [52:27<06:14,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2716/3038 [52:28<06:13,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2717/3038 [52:28<06:11,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2718/3038 [52:29<06:10,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  89% 2719/3038 [52:29<06:09,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2720/3038 [52:29<06:08,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2721/3038 [52:30<06:07,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2722/3038 [52:30<06:05,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2723/3038 [52:31<06:04,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2724/3038 [52:31<06:03,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2725/3038 [52:31<06:02,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2726/3038 [52:32<06:00,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2727/3038 [52:32<05:59,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2728/3038 [52:33<05:58,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2729/3038 [52:33<05:57,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2730/3038 [52:34<05:55,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2731/3038 [52:34<05:54,  1.16s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2732/3038 [52:34<05:53,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2733/3038 [52:35<05:52,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2734/3038 [52:35<05:50,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2735/3038 [52:36<05:49,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2736/3038 [52:36<05:48,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2737/3038 [52:36<05:47,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2738/3038 [52:37<05:45,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2739/3038 [52:37<05:44,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2740/3038 [52:38<05:43,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2741/3038 [52:38<05:42,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2742/3038 [52:39<05:41,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2743/3038 [52:39<05:39,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2744/3038 [52:39<05:38,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2745/3038 [52:40<05:37,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2746/3038 [52:40<05:36,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2747/3038 [52:41<05:34,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2748/3038 [52:41<05:33,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  90% 2749/3038 [52:41<05:32,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2750/3038 [52:42<05:31,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2751/3038 [52:42<05:29,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2752/3038 [52:43<05:28,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2753/3038 [52:43<05:27,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2754/3038 [52:44<05:26,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2755/3038 [52:44<05:25,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2756/3038 [52:44<05:23,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2757/3038 [52:45<05:22,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2758/3038 [52:45<05:21,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2759/3038 [52:46<05:20,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2760/3038 [52:46<05:18,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2761/3038 [52:46<05:17,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2762/3038 [52:47<05:16,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2763/3038 [52:47<05:15,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2764/3038 [52:48<05:14,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2765/3038 [52:48<05:12,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2766/3038 [52:49<05:11,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2767/3038 [52:49<05:10,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2768/3038 [52:49<05:09,  1.15s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2769/3038 [52:50<05:07,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2770/3038 [52:50<05:06,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2771/3038 [52:51<05:05,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2772/3038 [52:51<05:04,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2773/3038 [52:52<05:03,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2774/3038 [52:52<05:01,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2775/3038 [52:52<05:00,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2776/3038 [52:53<04:59,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2777/3038 [52:53<04:58,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2778/3038 [52:54<04:57,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  91% 2779/3038 [52:54<04:55,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2780/3038 [52:54<04:54,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2781/3038 [52:55<04:53,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2782/3038 [52:55<04:52,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2783/3038 [52:56<04:51,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2784/3038 [52:56<04:49,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2785/3038 [52:57<04:48,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2786/3038 [52:57<04:47,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2787/3038 [52:57<04:46,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2788/3038 [52:58<04:44,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2789/3038 [52:58<04:43,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2790/3038 [52:59<04:42,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2791/3038 [52:59<04:41,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2792/3038 [52:59<04:40,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2793/3038 [53:00<04:38,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2794/3038 [53:00<04:37,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2795/3038 [53:01<04:36,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2796/3038 [53:01<04:35,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2797/3038 [53:02<04:34,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2798/3038 [53:02<04:32,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2799/3038 [53:02<04:31,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2800/3038 [53:03<04:30,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2801/3038 [53:03<04:29,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2802/3038 [53:04<04:28,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2803/3038 [53:04<04:26,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2804/3038 [53:04<04:25,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2805/3038 [53:05<04:24,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2806/3038 [53:05<04:23,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2807/3038 [53:06<04:22,  1.14s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2808/3038 [53:06<04:21,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2809/3038 [53:07<04:19,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  92% 2810/3038 [53:07<04:18,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2811/3038 [53:07<04:17,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2812/3038 [53:08<04:16,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2813/3038 [53:08<04:15,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2814/3038 [53:09<04:13,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2815/3038 [53:09<04:12,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2816/3038 [53:10<04:11,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2817/3038 [53:10<04:10,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2818/3038 [53:10<04:09,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2819/3038 [53:11<04:07,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2820/3038 [53:11<04:06,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2821/3038 [53:12<04:05,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2822/3038 [53:12<04:04,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2823/3038 [53:12<04:03,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2824/3038 [53:13<04:01,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2825/3038 [53:13<04:00,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2826/3038 [53:14<03:59,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2827/3038 [53:14<03:58,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2828/3038 [53:15<03:57,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2829/3038 [53:15<03:56,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2830/3038 [53:15<03:54,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2831/3038 [53:16<03:53,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2832/3038 [53:16<03:52,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2833/3038 [53:17<03:51,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2834/3038 [53:17<03:50,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2835/3038 [53:17<03:48,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2836/3038 [53:18<03:47,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2837/3038 [53:18<03:46,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2838/3038 [53:19<03:45,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2839/3038 [53:19<03:44,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  93% 2840/3038 [53:20<03:43,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2841/3038 [53:20<03:41,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2842/3038 [53:20<03:40,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2843/3038 [53:21<03:39,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2844/3038 [53:21<03:38,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2845/3038 [53:22<03:37,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2846/3038 [53:22<03:36,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2847/3038 [53:22<03:34,  1.13s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2848/3038 [53:23<03:33,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2849/3038 [53:23<03:32,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2850/3038 [53:24<03:31,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2851/3038 [53:24<03:30,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2852/3038 [53:25<03:29,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2853/3038 [53:25<03:27,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2854/3038 [53:25<03:26,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2855/3038 [53:26<03:25,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2856/3038 [53:26<03:24,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2857/3038 [53:27<03:23,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2858/3038 [53:27<03:22,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2859/3038 [53:27<03:20,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2860/3038 [53:28<03:19,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2861/3038 [53:28<03:18,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2862/3038 [53:29<03:17,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2863/3038 [53:29<03:16,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2864/3038 [53:30<03:15,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2865/3038 [53:30<03:13,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2866/3038 [53:30<03:12,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2867/3038 [53:31<03:11,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2868/3038 [53:31<03:10,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2869/3038 [53:32<03:09,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  94% 2870/3038 [53:32<03:08,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2871/3038 [53:32<03:06,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2872/3038 [53:33<03:05,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2873/3038 [53:33<03:04,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2874/3038 [53:34<03:03,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2875/3038 [53:34<03:02,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2876/3038 [53:35<03:01,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2877/3038 [53:35<02:59,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2878/3038 [53:35<02:58,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2879/3038 [53:36<02:57,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2880/3038 [53:36<02:56,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2881/3038 [53:37<02:55,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2882/3038 [53:37<02:54,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2883/3038 [53:37<02:53,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2884/3038 [53:38<02:51,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2885/3038 [53:38<02:50,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2886/3038 [53:39<02:49,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2887/3038 [53:39<02:48,  1.12s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2888/3038 [53:40<02:47,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2889/3038 [53:40<02:46,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2890/3038 [53:40<02:44,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2891/3038 [53:41<02:43,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2892/3038 [53:41<02:42,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2893/3038 [53:42<02:41,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2894/3038 [53:42<02:40,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2895/3038 [53:42<02:39,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2896/3038 [53:43<02:38,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2897/3038 [53:43<02:36,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2898/3038 [53:44<02:35,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2899/3038 [53:44<02:34,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2900/3038 [53:45<02:33,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  95% 2901/3038 [53:45<02:32,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2902/3038 [53:45<02:31,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2903/3038 [53:46<02:30,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2904/3038 [53:46<02:28,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2905/3038 [53:47<02:27,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2906/3038 [53:47<02:26,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2907/3038 [53:47<02:25,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2908/3038 [53:48<02:24,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2909/3038 [53:48<02:23,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2910/3038 [53:49<02:22,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2911/3038 [53:49<02:20,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2912/3038 [53:50<02:19,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2913/3038 [53:50<02:18,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2914/3038 [53:50<02:17,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2915/3038 [53:51<02:16,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2916/3038 [53:51<02:15,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2917/3038 [53:52<02:14,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2918/3038 [53:52<02:12,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2919/3038 [53:52<02:11,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2920/3038 [53:53<02:10,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2921/3038 [53:53<02:09,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2922/3038 [53:54<02:08,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2923/3038 [53:54<02:07,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2924/3038 [53:55<02:06,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2925/3038 [53:55<02:04,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2926/3038 [53:55<02:03,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2927/3038 [53:56<02:02,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2928/3038 [53:56<02:01,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2929/3038 [53:57<02:00,  1.11s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2930/3038 [53:57<01:59,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  96% 2931/3038 [53:57<01:58,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2932/3038 [53:58<01:57,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2933/3038 [53:58<01:55,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2934/3038 [53:59<01:54,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2935/3038 [53:59<01:53,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2936/3038 [54:00<01:52,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2937/3038 [54:00<01:51,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2938/3038 [54:00<01:50,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2939/3038 [54:01<01:49,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2940/3038 [54:01<01:48,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2941/3038 [54:02<01:46,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2942/3038 [54:02<01:45,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2943/3038 [54:02<01:44,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2944/3038 [54:03<01:43,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2945/3038 [54:03<01:42,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2946/3038 [54:04<01:41,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2947/3038 [54:04<01:40,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2948/3038 [54:05<01:39,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2949/3038 [54:05<01:37,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2950/3038 [54:05<01:36,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2951/3038 [54:06<01:35,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2952/3038 [54:06<01:34,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2953/3038 [54:07<01:33,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2954/3038 [54:07<01:32,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2955/3038 [54:07<01:31,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2956/3038 [54:08<01:30,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2957/3038 [54:08<01:28,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2958/3038 [54:09<01:27,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2959/3038 [54:09<01:26,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2960/3038 [54:10<01:25,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2961/3038 [54:10<01:24,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  97% 2962/3038 [54:10<01:23,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2963/3038 [54:11<01:22,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2964/3038 [54:11<01:21,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2965/3038 [54:12<01:20,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2966/3038 [54:12<01:18,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2967/3038 [54:12<01:17,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2968/3038 [54:13<01:16,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2969/3038 [54:13<01:15,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2970/3038 [54:14<01:14,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2971/3038 [54:14<01:13,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2972/3038 [54:15<01:12,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2973/3038 [54:15<01:11,  1.10s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2974/3038 [54:15<01:10,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2975/3038 [54:16<01:08,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2976/3038 [54:16<01:07,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2977/3038 [54:17<01:06,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2978/3038 [54:17<01:05,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2979/3038 [54:17<01:04,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2980/3038 [54:18<01:03,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2981/3038 [54:18<01:02,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2982/3038 [54:19<01:01,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2983/3038 [54:19<01:00,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2984/3038 [54:20<00:58,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2985/3038 [54:20<00:57,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2986/3038 [54:20<00:56,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2987/3038 [54:21<00:55,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2988/3038 [54:21<00:54,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2989/3038 [54:22<00:53,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2990/3038 [54:22<00:52,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2991/3038 [54:22<00:51,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  98% 2992/3038 [54:23<00:50,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2993/3038 [54:23<00:49,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2994/3038 [54:24<00:47,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2995/3038 [54:24<00:46,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2996/3038 [54:25<00:45,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2997/3038 [54:25<00:44,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2998/3038 [54:25<00:43,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 2999/3038 [54:26<00:42,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3000/3038 [54:26<00:41,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3001/3038 [54:27<00:40,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3002/3038 [54:27<00:39,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3003/3038 [54:27<00:38,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3004/3038 [54:28<00:36,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3005/3038 [54:28<00:35,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3006/3038 [54:29<00:34,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3007/3038 [54:29<00:33,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3008/3038 [54:30<00:32,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3009/3038 [54:30<00:31,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3010/3038 [54:30<00:30,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3011/3038 [54:31<00:29,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3012/3038 [54:31<00:28,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3013/3038 [54:32<00:27,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3014/3038 [54:32<00:26,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3015/3038 [54:32<00:24,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3016/3038 [54:33<00:23,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3017/3038 [54:33<00:22,  1.09s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3018/3038 [54:34<00:21,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3019/3038 [54:34<00:20,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3020/3038 [54:34<00:19,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3021/3038 [54:35<00:18,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8:  99% 3022/3038 [54:35<00:17,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3023/3038 [54:36<00:16,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3024/3038 [54:36<00:15,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3025/3038 [54:37<00:14,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3026/3038 [54:37<00:12,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3027/3038 [54:37<00:11,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3028/3038 [54:38<00:10,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3029/3038 [54:38<00:09,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3030/3038 [54:39<00:08,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3031/3038 [54:39<00:07,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3032/3038 [54:39<00:06,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3033/3038 [54:40<00:05,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3034/3038 [54:40<00:04,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3035/3038 [54:41<00:03,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3036/3038 [54:41<00:02,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3037/3038 [54:42<00:01,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.930]\n","Epoch 8: 100% 3038/3038 [54:42<00:00,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.980]\n","Epoch 8: 100% 3038/3038 [54:42<00:00,  1.08s/it, loss=0.563, v_num=5, train_loss=0.474, val_loss=1.980]Epoch 8, global step 24300: 'val_loss' was not in top 3\n","Epoch 9:  89% 2700/3038 [52:36<06:35,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 9:  89% 2701/3038 [52:37<06:33,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2702/3038 [52:37<06:32,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2703/3038 [52:37<06:31,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2704/3038 [52:38<06:30,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2705/3038 [52:38<06:28,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2706/3038 [52:39<06:27,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2707/3038 [52:39<06:26,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2708/3038 [52:39<06:25,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2709/3038 [52:40<06:23,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2710/3038 [52:40<06:22,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2711/3038 [52:41<06:21,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2712/3038 [52:41<06:20,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2713/3038 [52:42<06:18,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2714/3038 [52:42<06:17,  1.17s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2715/3038 [52:42<06:16,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2716/3038 [52:43<06:15,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2717/3038 [52:43<06:13,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2718/3038 [52:44<06:12,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  89% 2719/3038 [52:44<06:11,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2720/3038 [52:45<06:10,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2721/3038 [52:45<06:08,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2722/3038 [52:45<06:07,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2723/3038 [52:46<06:06,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2724/3038 [52:46<06:05,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2725/3038 [52:47<06:03,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2726/3038 [52:47<06:02,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2727/3038 [52:47<06:01,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2728/3038 [52:48<06:00,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2729/3038 [52:48<05:58,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2730/3038 [52:49<05:57,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2731/3038 [52:49<05:56,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2732/3038 [52:50<05:55,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2733/3038 [52:50<05:53,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2734/3038 [52:50<05:52,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2735/3038 [52:51<05:51,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2736/3038 [52:51<05:50,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2737/3038 [52:52<05:48,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2738/3038 [52:52<05:47,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2739/3038 [52:53<05:46,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2740/3038 [52:53<05:45,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2741/3038 [52:53<05:43,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2742/3038 [52:54<05:42,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2743/3038 [52:54<05:41,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2744/3038 [52:55<05:40,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2745/3038 [52:55<05:38,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2746/3038 [52:56<05:37,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2747/3038 [52:56<05:36,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2748/3038 [52:56<05:35,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  90% 2749/3038 [52:57<05:34,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2750/3038 [52:57<05:32,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2751/3038 [52:58<05:31,  1.16s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2752/3038 [52:58<05:30,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2753/3038 [52:58<05:29,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2754/3038 [52:59<05:27,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2755/3038 [52:59<05:26,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2756/3038 [53:00<05:25,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2757/3038 [53:00<05:24,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2758/3038 [53:01<05:22,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2759/3038 [53:01<05:21,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2760/3038 [53:01<05:20,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2761/3038 [53:02<05:19,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2762/3038 [53:02<05:18,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2763/3038 [53:03<05:16,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2764/3038 [53:03<05:15,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2765/3038 [53:04<05:14,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2766/3038 [53:04<05:13,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2767/3038 [53:04<05:11,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2768/3038 [53:05<05:10,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2769/3038 [53:05<05:09,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2770/3038 [53:06<05:08,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2771/3038 [53:06<05:07,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2772/3038 [53:07<05:05,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2773/3038 [53:07<05:04,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2774/3038 [53:07<05:03,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2775/3038 [53:08<05:02,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2776/3038 [53:08<05:00,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2777/3038 [53:09<04:59,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2778/3038 [53:09<04:58,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  91% 2779/3038 [53:09<04:57,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2780/3038 [53:10<04:56,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2781/3038 [53:10<04:54,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2782/3038 [53:11<04:53,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2783/3038 [53:11<04:52,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2784/3038 [53:12<04:51,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2785/3038 [53:12<04:50,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2786/3038 [53:12<04:48,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2787/3038 [53:13<04:47,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2788/3038 [53:13<04:46,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2789/3038 [53:14<04:45,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2790/3038 [53:14<04:43,  1.15s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2791/3038 [53:15<04:42,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2792/3038 [53:15<04:41,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2793/3038 [53:15<04:40,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2794/3038 [53:16<04:39,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2795/3038 [53:16<04:37,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2796/3038 [53:17<04:36,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2797/3038 [53:17<04:35,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2798/3038 [53:17<04:34,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2799/3038 [53:18<04:33,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2800/3038 [53:18<04:31,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2801/3038 [53:19<04:30,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2802/3038 [53:19<04:29,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2803/3038 [53:20<04:28,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2804/3038 [53:20<04:27,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2805/3038 [53:20<04:25,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2806/3038 [53:21<04:24,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2807/3038 [53:21<04:23,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2808/3038 [53:22<04:22,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2809/3038 [53:22<04:21,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  92% 2810/3038 [53:23<04:19,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2811/3038 [53:23<04:18,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2812/3038 [53:23<04:17,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2813/3038 [53:24<04:16,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2814/3038 [53:24<04:15,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2815/3038 [53:25<04:13,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2816/3038 [53:25<04:12,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2817/3038 [53:26<04:11,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2818/3038 [53:26<04:10,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2819/3038 [53:26<04:09,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2820/3038 [53:27<04:07,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2821/3038 [53:27<04:06,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2822/3038 [53:28<04:05,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2823/3038 [53:28<04:04,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2824/3038 [53:28<04:03,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2825/3038 [53:29<04:01,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2826/3038 [53:29<04:00,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2827/3038 [53:30<03:59,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2828/3038 [53:30<03:58,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2829/3038 [53:31<03:57,  1.14s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2830/3038 [53:31<03:56,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2831/3038 [53:31<03:54,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2832/3038 [53:32<03:53,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2833/3038 [53:32<03:52,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2834/3038 [53:33<03:51,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2835/3038 [53:33<03:50,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2836/3038 [53:34<03:48,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2837/3038 [53:34<03:47,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2838/3038 [53:34<03:46,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2839/3038 [53:35<03:45,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  93% 2840/3038 [53:35<03:44,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2841/3038 [53:36<03:43,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2842/3038 [53:36<03:41,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2843/3038 [53:37<03:40,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2844/3038 [53:37<03:39,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2845/3038 [53:37<03:38,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2846/3038 [53:38<03:37,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2847/3038 [53:38<03:35,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2848/3038 [53:39<03:34,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2849/3038 [53:39<03:33,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2850/3038 [53:39<03:32,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2851/3038 [53:40<03:31,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2852/3038 [53:40<03:30,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2853/3038 [53:41<03:28,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2854/3038 [53:41<03:27,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2855/3038 [53:42<03:26,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2856/3038 [53:42<03:25,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2857/3038 [53:42<03:24,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2858/3038 [53:43<03:23,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2859/3038 [53:43<03:21,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2860/3038 [53:44<03:20,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2861/3038 [53:44<03:19,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2862/3038 [53:45<03:18,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2863/3038 [53:45<03:17,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2864/3038 [53:45<03:15,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2865/3038 [53:46<03:14,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2866/3038 [53:46<03:13,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2867/3038 [53:47<03:12,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2868/3038 [53:47<03:11,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2869/3038 [53:47<03:10,  1.13s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  94% 2870/3038 [53:48<03:08,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2871/3038 [53:48<03:07,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2872/3038 [53:49<03:06,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2873/3038 [53:49<03:05,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2874/3038 [53:50<03:04,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2875/3038 [53:50<03:03,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2876/3038 [53:50<03:01,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2877/3038 [53:51<03:00,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2878/3038 [53:51<02:59,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2879/3038 [53:52<02:58,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2880/3038 [53:52<02:57,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2881/3038 [53:53<02:56,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2882/3038 [53:53<02:55,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2883/3038 [53:53<02:53,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2884/3038 [53:54<02:52,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2885/3038 [53:54<02:51,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2886/3038 [53:55<02:50,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2887/3038 [53:55<02:49,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2888/3038 [53:56<02:48,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2889/3038 [53:56<02:46,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2890/3038 [53:56<02:45,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2891/3038 [53:57<02:44,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2892/3038 [53:57<02:43,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2893/3038 [53:58<02:42,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2894/3038 [53:58<02:41,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2895/3038 [53:58<02:39,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2896/3038 [53:59<02:38,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2897/3038 [53:59<02:37,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2898/3038 [54:00<02:36,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2899/3038 [54:00<02:35,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2900/3038 [54:01<02:34,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  95% 2901/3038 [54:01<02:33,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2902/3038 [54:01<02:31,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2903/3038 [54:02<02:30,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2904/3038 [54:02<02:29,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2905/3038 [54:03<02:28,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2906/3038 [54:03<02:27,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2907/3038 [54:04<02:26,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2908/3038 [54:04<02:25,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2909/3038 [54:04<02:23,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2910/3038 [54:05<02:22,  1.12s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2911/3038 [54:05<02:21,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2912/3038 [54:06<02:20,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2913/3038 [54:06<02:19,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2914/3038 [54:07<02:18,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2915/3038 [54:07<02:17,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2916/3038 [54:07<02:15,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2917/3038 [54:08<02:14,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2918/3038 [54:08<02:13,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2919/3038 [54:09<02:12,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2920/3038 [54:09<02:11,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2921/3038 [54:09<02:10,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2922/3038 [54:10<02:09,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2923/3038 [54:10<02:07,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2924/3038 [54:11<02:06,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2925/3038 [54:11<02:05,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2926/3038 [54:12<02:04,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2927/3038 [54:12<02:03,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2928/3038 [54:12<02:02,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2929/3038 [54:13<02:01,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2930/3038 [54:13<01:59,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  96% 2931/3038 [54:14<01:58,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2932/3038 [54:14<01:57,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2933/3038 [54:15<01:56,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2934/3038 [54:15<01:55,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2935/3038 [54:15<01:54,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2936/3038 [54:16<01:53,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2937/3038 [54:16<01:51,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2938/3038 [54:17<01:50,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2939/3038 [54:17<01:49,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2940/3038 [54:18<01:48,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2941/3038 [54:18<01:47,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2942/3038 [54:18<01:46,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2943/3038 [54:19<01:45,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2944/3038 [54:19<01:44,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2945/3038 [54:20<01:42,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2946/3038 [54:20<01:41,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2947/3038 [54:20<01:40,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2948/3038 [54:21<01:39,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2949/3038 [54:21<01:38,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2950/3038 [54:22<01:37,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2951/3038 [54:22<01:36,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2952/3038 [54:23<01:35,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2953/3038 [54:23<01:33,  1.11s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2954/3038 [54:23<01:32,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2955/3038 [54:24<01:31,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2956/3038 [54:24<01:30,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2957/3038 [54:25<01:29,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2958/3038 [54:25<01:28,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2959/3038 [54:26<01:27,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2960/3038 [54:26<01:26,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2961/3038 [54:26<01:24,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  97% 2962/3038 [54:27<01:23,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2963/3038 [54:27<01:22,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2964/3038 [54:28<01:21,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2965/3038 [54:28<01:20,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2966/3038 [54:28<01:19,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2967/3038 [54:29<01:18,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2968/3038 [54:29<01:17,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2969/3038 [54:30<01:16,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2970/3038 [54:30<01:14,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2971/3038 [54:31<01:13,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2972/3038 [54:31<01:12,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2973/3038 [54:31<01:11,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2974/3038 [54:32<01:10,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2975/3038 [54:32<01:09,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2976/3038 [54:33<01:08,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2977/3038 [54:33<01:07,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2978/3038 [54:34<01:05,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2979/3038 [54:34<01:04,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2980/3038 [54:34<01:03,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2981/3038 [54:35<01:02,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2982/3038 [54:35<01:01,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2983/3038 [54:36<01:00,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2984/3038 [54:36<00:59,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2985/3038 [54:36<00:58,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2986/3038 [54:37<00:57,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2987/3038 [54:37<00:55,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2988/3038 [54:38<00:54,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2989/3038 [54:38<00:53,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2990/3038 [54:39<00:52,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2991/3038 [54:39<00:51,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  98% 2992/3038 [54:39<00:50,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2993/3038 [54:40<00:49,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2994/3038 [54:40<00:48,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2995/3038 [54:41<00:47,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2996/3038 [54:41<00:46,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2997/3038 [54:42<00:44,  1.10s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2998/3038 [54:42<00:43,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 2999/3038 [54:42<00:42,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3000/3038 [54:43<00:41,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3001/3038 [54:43<00:40,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3002/3038 [54:44<00:39,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3003/3038 [54:44<00:38,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3004/3038 [54:44<00:37,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3005/3038 [54:45<00:36,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3006/3038 [54:45<00:34,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3007/3038 [54:46<00:33,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3008/3038 [54:46<00:32,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3009/3038 [54:47<00:31,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3010/3038 [54:47<00:30,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3011/3038 [54:47<00:29,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3012/3038 [54:48<00:28,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3013/3038 [54:48<00:27,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3014/3038 [54:49<00:26,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3015/3038 [54:49<00:25,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3016/3038 [54:50<00:23,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3017/3038 [54:50<00:22,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3018/3038 [54:50<00:21,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3019/3038 [54:51<00:20,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3020/3038 [54:51<00:19,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3021/3038 [54:52<00:18,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9:  99% 3022/3038 [54:52<00:17,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3023/3038 [54:52<00:16,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3024/3038 [54:53<00:15,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3025/3038 [54:53<00:14,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3026/3038 [54:54<00:13,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3027/3038 [54:54<00:11,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3028/3038 [54:55<00:10,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3029/3038 [54:55<00:09,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3030/3038 [54:55<00:08,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3031/3038 [54:56<00:07,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3032/3038 [54:56<00:06,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3033/3038 [54:57<00:05,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3034/3038 [54:57<00:04,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3035/3038 [54:58<00:03,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3036/3038 [54:58<00:02,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3037/3038 [54:58<00:01,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=1.980]\n","Epoch 9: 100% 3038/3038 [54:59<00:00,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 9: 100% 3038/3038 [54:59<00:00,  1.09s/it, loss=0.375, v_num=5, train_loss=0.388, val_loss=2.030]Epoch 9, global step 27000: 'val_loss' was not in top 3\n","Epoch 10:  89% 2700/3038 [52:23<06:33,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 10:  89% 2701/3038 [52:24<06:32,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2702/3038 [52:24<06:31,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2703/3038 [52:25<06:29,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2704/3038 [52:25<06:28,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2705/3038 [52:26<06:27,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2706/3038 [52:26<06:26,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2707/3038 [52:27<06:24,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2708/3038 [52:27<06:23,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2709/3038 [52:27<06:22,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2710/3038 [52:28<06:21,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2711/3038 [52:28<06:19,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2712/3038 [52:29<06:18,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2713/3038 [52:29<06:17,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2714/3038 [52:29<06:16,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2715/3038 [52:30<06:14,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2716/3038 [52:30<06:13,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2717/3038 [52:31<06:12,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2718/3038 [52:31<06:11,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  89% 2719/3038 [52:32<06:09,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2720/3038 [52:32<06:08,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2721/3038 [52:32<06:07,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2722/3038 [52:33<06:06,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2723/3038 [52:33<06:04,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2724/3038 [52:34<06:03,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2725/3038 [52:34<06:02,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2726/3038 [52:34<06:01,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2727/3038 [52:35<05:59,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2728/3038 [52:35<05:58,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2729/3038 [52:36<05:57,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2730/3038 [52:36<05:56,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2731/3038 [52:37<05:54,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2732/3038 [52:37<05:53,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2733/3038 [52:37<05:52,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2734/3038 [52:38<05:51,  1.16s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2735/3038 [52:38<05:49,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2736/3038 [52:39<05:48,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2737/3038 [52:39<05:47,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2738/3038 [52:39<05:46,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2739/3038 [52:40<05:45,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2740/3038 [52:40<05:43,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2741/3038 [52:41<05:42,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2742/3038 [52:41<05:41,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2743/3038 [52:42<05:40,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2744/3038 [52:42<05:38,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2745/3038 [52:42<05:37,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2746/3038 [52:43<05:36,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2747/3038 [52:43<05:35,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2748/3038 [52:44<05:33,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  90% 2749/3038 [52:44<05:32,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2750/3038 [52:45<05:31,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2751/3038 [52:45<05:30,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2752/3038 [52:45<05:29,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2753/3038 [52:46<05:27,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2754/3038 [52:46<05:26,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2755/3038 [52:47<05:25,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2756/3038 [52:47<05:24,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2757/3038 [52:47<05:22,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2758/3038 [52:48<05:21,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2759/3038 [52:48<05:20,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2760/3038 [52:49<05:19,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2761/3038 [52:49<05:17,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2762/3038 [52:50<05:16,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2763/3038 [52:50<05:15,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2764/3038 [52:50<05:14,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2765/3038 [52:51<05:13,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2766/3038 [52:51<05:11,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2767/3038 [52:52<05:10,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2768/3038 [52:52<05:09,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2769/3038 [52:52<05:08,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2770/3038 [52:53<05:07,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2771/3038 [52:53<05:05,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2772/3038 [52:54<05:04,  1.15s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2773/3038 [52:54<05:03,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2774/3038 [52:55<05:02,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2775/3038 [52:55<05:00,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2776/3038 [52:55<04:59,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2777/3038 [52:56<04:58,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2778/3038 [52:56<04:57,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  91% 2779/3038 [52:57<04:56,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2780/3038 [52:57<04:54,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2781/3038 [52:57<04:53,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2782/3038 [52:58<04:52,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2783/3038 [52:58<04:51,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2784/3038 [52:59<04:50,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2785/3038 [52:59<04:48,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2786/3038 [53:00<04:47,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2787/3038 [53:00<04:46,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2788/3038 [53:00<04:45,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2789/3038 [53:01<04:44,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2790/3038 [53:01<04:42,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2791/3038 [53:02<04:41,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2792/3038 [53:02<04:40,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2793/3038 [53:03<04:39,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2794/3038 [53:03<04:38,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2795/3038 [53:03<04:36,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2796/3038 [53:04<04:35,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2797/3038 [53:04<04:34,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2798/3038 [53:05<04:33,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2799/3038 [53:05<04:32,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2800/3038 [53:05<04:30,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2801/3038 [53:06<04:29,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2802/3038 [53:06<04:28,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2803/3038 [53:07<04:27,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2804/3038 [53:07<04:26,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2805/3038 [53:08<04:24,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2806/3038 [53:08<04:23,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2807/3038 [53:08<04:22,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2808/3038 [53:09<04:21,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2809/3038 [53:09<04:20,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  92% 2810/3038 [53:10<04:18,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2811/3038 [53:10<04:17,  1.14s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2812/3038 [53:10<04:16,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2813/3038 [53:11<04:15,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2814/3038 [53:11<04:14,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2815/3038 [53:12<04:12,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2816/3038 [53:12<04:11,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2817/3038 [53:13<04:10,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2818/3038 [53:13<04:09,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2819/3038 [53:13<04:08,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2820/3038 [53:14<04:06,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2821/3038 [53:14<04:05,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2822/3038 [53:15<04:04,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2823/3038 [53:15<04:03,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2824/3038 [53:16<04:02,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2825/3038 [53:16<04:01,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2826/3038 [53:16<03:59,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2827/3038 [53:17<03:58,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2828/3038 [53:17<03:57,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2829/3038 [53:18<03:56,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2830/3038 [53:18<03:55,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2831/3038 [53:18<03:53,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2832/3038 [53:19<03:52,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2833/3038 [53:19<03:51,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2834/3038 [53:20<03:50,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2835/3038 [53:20<03:49,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2836/3038 [53:21<03:48,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2837/3038 [53:21<03:46,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2838/3038 [53:21<03:45,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2839/3038 [53:22<03:44,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  93% 2840/3038 [53:22<03:43,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2841/3038 [53:23<03:42,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2842/3038 [53:23<03:40,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2843/3038 [53:24<03:39,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2844/3038 [53:24<03:38,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2845/3038 [53:24<03:37,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2846/3038 [53:25<03:36,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2847/3038 [53:25<03:35,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2848/3038 [53:26<03:33,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2849/3038 [53:26<03:32,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2850/3038 [53:26<03:31,  1.13s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2851/3038 [53:27<03:30,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2852/3038 [53:27<03:29,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2853/3038 [53:28<03:28,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2854/3038 [53:28<03:26,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2855/3038 [53:29<03:25,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2856/3038 [53:29<03:24,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2857/3038 [53:29<03:23,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2858/3038 [53:30<03:22,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2859/3038 [53:30<03:21,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2860/3038 [53:31<03:19,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2861/3038 [53:31<03:18,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2862/3038 [53:31<03:17,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2863/3038 [53:32<03:16,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2864/3038 [53:32<03:15,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2865/3038 [53:33<03:14,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2866/3038 [53:33<03:12,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2867/3038 [53:34<03:11,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2868/3038 [53:34<03:10,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2869/3038 [53:34<03:09,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  94% 2870/3038 [53:35<03:08,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2871/3038 [53:35<03:07,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2872/3038 [53:36<03:05,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2873/3038 [53:36<03:04,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2874/3038 [53:36<03:03,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2875/3038 [53:37<03:02,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2876/3038 [53:37<03:01,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2877/3038 [53:38<03:00,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2878/3038 [53:38<02:58,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2879/3038 [53:39<02:57,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2880/3038 [53:39<02:56,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2881/3038 [53:39<02:55,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2882/3038 [53:40<02:54,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2883/3038 [53:40<02:53,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2884/3038 [53:41<02:52,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2885/3038 [53:41<02:50,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2886/3038 [53:42<02:49,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2887/3038 [53:42<02:48,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2888/3038 [53:42<02:47,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2889/3038 [53:43<02:46,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2890/3038 [53:43<02:45,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2891/3038 [53:44<02:43,  1.12s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2892/3038 [53:44<02:42,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2893/3038 [53:44<02:41,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2894/3038 [53:45<02:40,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2895/3038 [53:45<02:39,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2896/3038 [53:46<02:38,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2897/3038 [53:46<02:37,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2898/3038 [53:47<02:35,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2899/3038 [53:47<02:34,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2900/3038 [53:47<02:33,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  95% 2901/3038 [53:48<02:32,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2902/3038 [53:48<02:31,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2903/3038 [53:49<02:30,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2904/3038 [53:49<02:29,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2905/3038 [53:49<02:27,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2906/3038 [53:50<02:26,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2907/3038 [53:50<02:25,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2908/3038 [53:51<02:24,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2909/3038 [53:51<02:23,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2910/3038 [53:52<02:22,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2911/3038 [53:52<02:21,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2912/3038 [53:52<02:19,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2913/3038 [53:53<02:18,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2914/3038 [53:53<02:17,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2915/3038 [53:54<02:16,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2916/3038 [53:54<02:15,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2917/3038 [53:55<02:14,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2918/3038 [53:55<02:13,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2919/3038 [53:55<02:11,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2920/3038 [53:56<02:10,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2921/3038 [53:56<02:09,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2922/3038 [53:57<02:08,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2923/3038 [53:57<02:07,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2924/3038 [53:57<02:06,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2925/3038 [53:58<02:05,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2926/3038 [53:58<02:03,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2927/3038 [53:59<02:02,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2928/3038 [53:59<02:01,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2929/3038 [54:00<02:00,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2930/3038 [54:00<01:59,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  96% 2931/3038 [54:00<01:58,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2932/3038 [54:01<01:57,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2933/3038 [54:01<01:56,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2934/3038 [54:02<01:54,  1.11s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2935/3038 [54:02<01:53,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2936/3038 [54:02<01:52,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2937/3038 [54:03<01:51,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2938/3038 [54:03<01:50,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2939/3038 [54:04<01:49,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2940/3038 [54:04<01:48,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2941/3038 [54:05<01:47,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2942/3038 [54:05<01:45,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2943/3038 [54:05<01:44,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2944/3038 [54:06<01:43,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2945/3038 [54:06<01:42,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2946/3038 [54:07<01:41,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2947/3038 [54:07<01:40,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2948/3038 [54:07<01:39,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2949/3038 [54:08<01:38,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2950/3038 [54:08<01:36,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2951/3038 [54:09<01:35,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2952/3038 [54:09<01:34,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2953/3038 [54:10<01:33,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2954/3038 [54:10<01:32,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2955/3038 [54:10<01:31,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2956/3038 [54:11<01:30,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2957/3038 [54:11<01:29,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2958/3038 [54:12<01:27,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2959/3038 [54:12<01:26,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2960/3038 [54:13<01:25,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2961/3038 [54:13<01:24,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  97% 2962/3038 [54:13<01:23,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2963/3038 [54:14<01:22,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2964/3038 [54:14<01:21,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2965/3038 [54:15<01:20,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2966/3038 [54:15<01:19,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2967/3038 [54:15<01:17,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2968/3038 [54:16<01:16,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2969/3038 [54:16<01:15,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2970/3038 [54:17<01:14,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2971/3038 [54:17<01:13,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2972/3038 [54:18<01:12,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2973/3038 [54:18<01:11,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2974/3038 [54:18<01:10,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2975/3038 [54:19<01:09,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2976/3038 [54:19<01:07,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2977/3038 [54:20<01:06,  1.10s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2978/3038 [54:20<01:05,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2979/3038 [54:20<01:04,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2980/3038 [54:21<01:03,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2981/3038 [54:21<01:02,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2982/3038 [54:22<01:01,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2983/3038 [54:22<01:00,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2984/3038 [54:23<00:59,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2985/3038 [54:23<00:57,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2986/3038 [54:23<00:56,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2987/3038 [54:24<00:55,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2988/3038 [54:24<00:54,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2989/3038 [54:25<00:53,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2990/3038 [54:25<00:52,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2991/3038 [54:26<00:51,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  98% 2992/3038 [54:26<00:50,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2993/3038 [54:26<00:49,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2994/3038 [54:27<00:48,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2995/3038 [54:27<00:46,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2996/3038 [54:28<00:45,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2997/3038 [54:28<00:44,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2998/3038 [54:28<00:43,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 2999/3038 [54:29<00:42,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3000/3038 [54:29<00:41,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3001/3038 [54:30<00:40,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3002/3038 [54:30<00:39,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3003/3038 [54:31<00:38,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3004/3038 [54:31<00:37,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3005/3038 [54:31<00:35,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3006/3038 [54:32<00:34,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3007/3038 [54:32<00:33,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3008/3038 [54:33<00:32,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3009/3038 [54:33<00:31,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3010/3038 [54:33<00:30,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3011/3038 [54:34<00:29,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3012/3038 [54:34<00:28,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3013/3038 [54:35<00:27,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3014/3038 [54:35<00:26,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3015/3038 [54:36<00:24,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3016/3038 [54:36<00:23,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3017/3038 [54:36<00:22,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3018/3038 [54:37<00:21,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3019/3038 [54:37<00:20,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3020/3038 [54:38<00:19,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3021/3038 [54:38<00:18,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10:  99% 3022/3038 [54:38<00:17,  1.09s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3023/3038 [54:39<00:16,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3024/3038 [54:39<00:15,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3025/3038 [54:40<00:14,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3026/3038 [54:40<00:13,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3027/3038 [54:41<00:11,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3028/3038 [54:41<00:10,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3029/3038 [54:41<00:09,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3030/3038 [54:42<00:08,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3031/3038 [54:42<00:07,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3032/3038 [54:43<00:06,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3033/3038 [54:43<00:05,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3034/3038 [54:44<00:04,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3035/3038 [54:44<00:03,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3036/3038 [54:44<00:02,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3037/3038 [54:45<00:01,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.030]\n","Epoch 10: 100% 3038/3038 [54:45<00:00,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.090]\n","Epoch 10: 100% 3038/3038 [54:45<00:00,  1.08s/it, loss=0.393, v_num=5, train_loss=0.388, val_loss=2.090]Epoch 10, global step 29700: 'val_loss' was not in top 3\n","Epoch 11:  89% 2700/3038 [52:41<06:35,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/338 [00:00<?, ?it/s]\u001b[A\n","Epoch 11:  89% 2701/3038 [52:42<06:34,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2702/3038 [52:42<06:33,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2703/3038 [52:43<06:32,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2704/3038 [52:43<06:30,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2705/3038 [52:44<06:29,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2706/3038 [52:44<06:28,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2707/3038 [52:45<06:27,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2708/3038 [52:45<06:25,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2709/3038 [52:45<06:24,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2710/3038 [52:46<06:23,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2711/3038 [52:46<06:21,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2712/3038 [52:47<06:20,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2713/3038 [52:47<06:19,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2714/3038 [52:48<06:18,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2715/3038 [52:48<06:16,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2716/3038 [52:48<06:15,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2717/3038 [52:49<06:14,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2718/3038 [52:49<06:13,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  89% 2719/3038 [52:50<06:11,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2720/3038 [52:50<06:10,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2721/3038 [52:50<06:09,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2722/3038 [52:51<06:08,  1.17s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2723/3038 [52:51<06:06,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2724/3038 [52:52<06:05,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2725/3038 [52:52<06:04,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2726/3038 [52:53<06:03,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2727/3038 [52:53<06:01,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2728/3038 [52:53<06:00,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2729/3038 [52:54<05:59,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2730/3038 [52:54<05:58,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2731/3038 [52:55<05:56,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2732/3038 [52:55<05:55,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2733/3038 [52:56<05:54,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2734/3038 [52:56<05:53,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2735/3038 [52:56<05:51,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2736/3038 [52:57<05:50,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2737/3038 [52:57<05:49,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2738/3038 [52:58<05:48,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2739/3038 [52:58<05:46,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2740/3038 [52:58<05:45,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2741/3038 [52:59<05:44,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2742/3038 [52:59<05:43,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2743/3038 [53:00<05:42,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2744/3038 [53:00<05:40,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2745/3038 [53:01<05:39,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2746/3038 [53:01<05:38,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2747/3038 [53:01<05:37,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2748/3038 [53:02<05:35,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  90% 2749/3038 [53:02<05:34,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2750/3038 [53:03<05:33,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2751/3038 [53:03<05:32,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2752/3038 [53:04<05:30,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2753/3038 [53:04<05:29,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2754/3038 [53:04<05:28,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2755/3038 [53:05<05:27,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2756/3038 [53:05<05:25,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2757/3038 [53:06<05:24,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2758/3038 [53:06<05:23,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2759/3038 [53:07<05:22,  1.16s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2760/3038 [53:07<05:21,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2761/3038 [53:07<05:19,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2762/3038 [53:08<05:18,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2763/3038 [53:08<05:17,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2764/3038 [53:09<05:16,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2765/3038 [53:09<05:14,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2766/3038 [53:09<05:13,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2767/3038 [53:10<05:12,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2768/3038 [53:10<05:11,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2769/3038 [53:11<05:10,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2770/3038 [53:11<05:08,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2771/3038 [53:12<05:07,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2772/3038 [53:12<05:06,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2773/3038 [53:12<05:05,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2774/3038 [53:13<05:03,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2775/3038 [53:13<05:02,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2776/3038 [53:14<05:01,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2777/3038 [53:14<05:00,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2778/3038 [53:15<04:59,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  91% 2779/3038 [53:15<04:57,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2780/3038 [53:15<04:56,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2781/3038 [53:16<04:55,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2782/3038 [53:16<04:54,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2783/3038 [53:17<04:52,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2784/3038 [53:17<04:51,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2785/3038 [53:18<04:50,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2786/3038 [53:18<04:49,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2787/3038 [53:18<04:48,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2788/3038 [53:19<04:46,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2789/3038 [53:19<04:45,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2790/3038 [53:20<04:44,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2791/3038 [53:20<04:43,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2792/3038 [53:20<04:42,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2793/3038 [53:21<04:40,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2794/3038 [53:21<04:39,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2795/3038 [53:22<04:38,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2796/3038 [53:22<04:37,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2797/3038 [53:23<04:35,  1.15s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2798/3038 [53:23<04:34,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2799/3038 [53:23<04:33,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2800/3038 [53:24<04:32,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2801/3038 [53:24<04:31,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2802/3038 [53:25<04:29,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2803/3038 [53:25<04:28,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2804/3038 [53:26<04:27,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2805/3038 [53:26<04:26,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2806/3038 [53:26<04:25,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2807/3038 [53:27<04:23,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2808/3038 [53:27<04:22,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2809/3038 [53:28<04:21,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  92% 2810/3038 [53:28<04:20,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2811/3038 [53:28<04:19,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2812/3038 [53:29<04:17,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2813/3038 [53:29<04:16,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2814/3038 [53:30<04:15,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2815/3038 [53:30<04:14,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2816/3038 [53:31<04:13,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2817/3038 [53:31<04:11,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2818/3038 [53:31<04:10,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2819/3038 [53:32<04:09,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2820/3038 [53:32<04:08,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2821/3038 [53:33<04:07,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2822/3038 [53:33<04:05,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2823/3038 [53:34<04:04,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2824/3038 [53:34<04:03,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2825/3038 [53:34<04:02,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2826/3038 [53:35<04:01,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2827/3038 [53:35<04:00,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2828/3038 [53:36<03:58,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2829/3038 [53:36<03:57,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2830/3038 [53:37<03:56,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2831/3038 [53:37<03:55,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2832/3038 [53:37<03:54,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2833/3038 [53:38<03:52,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2834/3038 [53:38<03:51,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2835/3038 [53:39<03:50,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2836/3038 [53:39<03:49,  1.14s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2837/3038 [53:39<03:48,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2838/3038 [53:40<03:46,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2839/3038 [53:40<03:45,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  93% 2840/3038 [53:41<03:44,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2841/3038 [53:41<03:43,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2842/3038 [53:42<03:42,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2843/3038 [53:42<03:41,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2844/3038 [53:42<03:39,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2845/3038 [53:43<03:38,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2846/3038 [53:43<03:37,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2847/3038 [53:44<03:36,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2848/3038 [53:44<03:35,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2849/3038 [53:45<03:33,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2850/3038 [53:45<03:32,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2851/3038 [53:45<03:31,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2852/3038 [53:46<03:30,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2853/3038 [53:46<03:29,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2854/3038 [53:47<03:28,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2855/3038 [53:47<03:26,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2856/3038 [53:48<03:25,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2857/3038 [53:48<03:24,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2858/3038 [53:48<03:23,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2859/3038 [53:49<03:22,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2860/3038 [53:49<03:21,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2861/3038 [53:50<03:19,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2862/3038 [53:50<03:18,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2863/3038 [53:50<03:17,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2864/3038 [53:51<03:16,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2865/3038 [53:51<03:15,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2866/3038 [53:52<03:13,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2867/3038 [53:52<03:12,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2868/3038 [53:53<03:11,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2869/3038 [53:53<03:10,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  94% 2870/3038 [53:53<03:09,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2871/3038 [53:54<03:08,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2872/3038 [53:54<03:06,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2873/3038 [53:55<03:05,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2874/3038 [53:55<03:04,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2875/3038 [53:56<03:03,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2876/3038 [53:56<03:02,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2877/3038 [53:56<03:01,  1.13s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2878/3038 [53:57<02:59,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2879/3038 [53:57<02:58,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2880/3038 [53:58<02:57,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2881/3038 [53:58<02:56,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2882/3038 [53:58<02:55,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2883/3038 [53:59<02:54,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2884/3038 [53:59<02:53,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2885/3038 [54:00<02:51,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2886/3038 [54:00<02:50,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2887/3038 [54:01<02:49,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2888/3038 [54:01<02:48,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2889/3038 [54:01<02:47,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2890/3038 [54:02<02:46,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2891/3038 [54:02<02:44,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2892/3038 [54:03<02:43,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2893/3038 [54:03<02:42,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2894/3038 [54:04<02:41,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2895/3038 [54:04<02:40,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2896/3038 [54:04<02:39,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2897/3038 [54:05<02:37,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2898/3038 [54:05<02:36,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2899/3038 [54:06<02:35,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2900/3038 [54:06<02:34,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  95% 2901/3038 [54:07<02:33,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2902/3038 [54:07<02:32,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2903/3038 [54:07<02:31,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2904/3038 [54:08<02:29,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2905/3038 [54:08<02:28,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2906/3038 [54:09<02:27,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2907/3038 [54:09<02:26,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2908/3038 [54:09<02:25,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2909/3038 [54:10<02:24,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2910/3038 [54:10<02:22,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2911/3038 [54:11<02:21,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2912/3038 [54:11<02:20,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2913/3038 [54:12<02:19,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2914/3038 [54:12<02:18,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2915/3038 [54:12<02:17,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2916/3038 [54:13<02:16,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2917/3038 [54:13<02:14,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2918/3038 [54:14<02:13,  1.12s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2919/3038 [54:14<02:12,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2920/3038 [54:14<02:11,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2921/3038 [54:15<02:10,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2922/3038 [54:15<02:09,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2923/3038 [54:16<02:08,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2924/3038 [54:16<02:06,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2925/3038 [54:17<02:05,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2926/3038 [54:17<02:04,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2927/3038 [54:17<02:03,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2928/3038 [54:18<02:02,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2929/3038 [54:18<02:01,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2930/3038 [54:19<02:00,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  96% 2931/3038 [54:19<01:58,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2932/3038 [54:20<01:57,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2933/3038 [54:20<01:56,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2934/3038 [54:20<01:55,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2935/3038 [54:21<01:54,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2936/3038 [54:21<01:53,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2937/3038 [54:22<01:52,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2938/3038 [54:22<01:51,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2939/3038 [54:23<01:49,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2940/3038 [54:23<01:48,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2941/3038 [54:23<01:47,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2942/3038 [54:24<01:46,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2943/3038 [54:24<01:45,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2944/3038 [54:25<01:44,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2945/3038 [54:25<01:43,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2946/3038 [54:25<01:41,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2947/3038 [54:26<01:40,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2948/3038 [54:26<01:39,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2949/3038 [54:27<01:38,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2950/3038 [54:27<01:37,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2951/3038 [54:28<01:36,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2952/3038 [54:28<01:35,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2953/3038 [54:28<01:34,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2954/3038 [54:29<01:32,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2955/3038 [54:29<01:31,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2956/3038 [54:30<01:30,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2957/3038 [54:30<01:29,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2958/3038 [54:31<01:28,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2959/3038 [54:31<01:27,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2960/3038 [54:31<01:26,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2961/3038 [54:32<01:25,  1.11s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  97% 2962/3038 [54:32<01:23,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2963/3038 [54:33<01:22,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2964/3038 [54:33<01:21,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2965/3038 [54:34<01:20,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2966/3038 [54:34<01:19,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2967/3038 [54:34<01:18,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2968/3038 [54:35<01:17,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2969/3038 [54:35<01:16,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2970/3038 [54:36<01:15,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2971/3038 [54:36<01:13,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2972/3038 [54:37<01:12,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2973/3038 [54:37<01:11,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2974/3038 [54:37<01:10,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2975/3038 [54:38<01:09,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2976/3038 [54:38<01:08,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2977/3038 [54:39<01:07,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2978/3038 [54:39<01:06,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2979/3038 [54:39<01:04,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2980/3038 [54:40<01:03,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2981/3038 [54:40<01:02,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2982/3038 [54:41<01:01,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2983/3038 [54:41<01:00,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2984/3038 [54:42<00:59,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2985/3038 [54:42<00:58,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2986/3038 [54:42<00:57,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2987/3038 [54:43<00:56,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2988/3038 [54:43<00:54,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2989/3038 [54:44<00:53,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2990/3038 [54:44<00:52,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2991/3038 [54:45<00:51,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  98% 2992/3038 [54:45<00:50,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2993/3038 [54:45<00:49,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2994/3038 [54:46<00:48,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2995/3038 [54:46<00:47,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2996/3038 [54:47<00:46,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2997/3038 [54:47<00:44,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2998/3038 [54:47<00:43,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 2999/3038 [54:48<00:42,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3000/3038 [54:48<00:41,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3001/3038 [54:49<00:40,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3002/3038 [54:49<00:39,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3003/3038 [54:50<00:38,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3004/3038 [54:50<00:37,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3005/3038 [54:50<00:36,  1.10s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3006/3038 [54:51<00:35,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3007/3038 [54:51<00:33,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3008/3038 [54:52<00:32,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3009/3038 [54:52<00:31,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3010/3038 [54:53<00:30,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3011/3038 [54:53<00:29,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3012/3038 [54:53<00:28,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3013/3038 [54:54<00:27,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3014/3038 [54:54<00:26,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3015/3038 [54:55<00:25,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3016/3038 [54:55<00:24,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3017/3038 [54:56<00:22,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3018/3038 [54:56<00:21,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3019/3038 [54:56<00:20,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3020/3038 [54:57<00:19,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3021/3038 [54:57<00:18,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11:  99% 3022/3038 [54:58<00:17,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3023/3038 [54:58<00:16,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3024/3038 [54:58<00:15,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3025/3038 [54:59<00:14,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3026/3038 [54:59<00:13,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3027/3038 [55:00<00:11,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3028/3038 [55:00<00:10,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3029/3038 [55:01<00:09,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3030/3038 [55:01<00:08,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3031/3038 [55:01<00:07,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3032/3038 [55:02<00:06,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3033/3038 [55:02<00:05,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3034/3038 [55:03<00:04,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3035/3038 [55:03<00:03,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3036/3038 [55:04<00:02,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3037/3038 [55:04<00:01,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.090]\n","Epoch 11: 100% 3038/3038 [55:04<00:00,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.130]\n","Epoch 11: 100% 3038/3038 [55:04<00:00,  1.09s/it, loss=0.374, v_num=5, train_loss=0.405, val_loss=2.130]Epoch 11, global step 32400: 'val_loss' was not in top 3\n","Epoch 12:  58% 1757/3038 [34:08<24:53,  1.17s/it, loss=0.225, v_num=5, train_loss=0.291, val_loss=2.130]"]}],"source":["!python train.py --gradient_clip_val 1.0  \\\n","                 --max_epochs 50 \\\n","                 --default_root_dir logs \\\n","                 --gpus 1 \\\n","                 --batch_size 8 \\\n","                 --num_workers 4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12435,"status":"ok","timestamp":1672227853690,"user":{"displayName":"detection object","userId":"15437484413253545811"},"user_tz":-540},"id":"HlyYOIbZc6Kt","outputId":"38885ee2-5af6-4116-c505-f81a4d291947"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=64aefa8a3f6c687cb32192e71e292e9af6f3c0332e3ed7951ab6b00abde84003\n","  Stored in directory: /root/.cache/pip/wheels/ba/03/bb/7a97840eb54479b328672e15a536e49dc60da200fb21564d53\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (5.4.8)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: humanize in /usr/local/lib/python3.8/dist-packages (0.5.1)\n","Gen RAM Free: 52.9 GB  |     Proc size: 223.6 MB\n","GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total     15109MB\n"]}],"source":["# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"]},{"cell_type":"markdown","source":["# BERT SCORE\n"],"metadata":{"id":"uXQMze30i956"}},{"cell_type":"code","source":["!pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3bewdQOMO_MZ","executionInfo":{"status":"ok","timestamp":1672379883336,"user_tz":-540,"elapsed":11825,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"24e89f38-d63e-4843-989b-7d9056762515"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.12-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.8/dist-packages (from bert-score) (4.64.1)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from bert-score) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bert-score) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bert-score) (3.2.2)\n","Collecting transformers>=3.0.0\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 34.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bert-score) (1.13.0+cu116)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from bert-score) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bert-score) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->bert-score) (3.0.9)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert-score) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (3.8.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 77.1 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 57.7 MB/s \n","\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers, bert-score\n","Successfully installed bert-score-0.3.12 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}]},{"cell_type":"code","source":["!pip uninstall keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3lKNBFNP8hq","executionInfo":{"status":"ok","timestamp":1672373864700,"user_tz":-540,"elapsed":6103,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"5bd9d891-4c46-4aef-f78e-7ae463439548"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: keras 2.9.0\n","Uninstalling keras-2.9.0:\n","  Would remove:\n","    /usr/local/lib/python3.8/dist-packages/keras-2.9.0.dist-info/*\n","    /usr/local/lib/python3.8/dist-packages/keras/*\n","Proceed (y/n)? Y\n","  Successfully uninstalled keras-2.9.0\n"]}]},{"cell_type":"code","source":["!pip install keras==2.6.*"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpWrq0ZrQBBk","executionInfo":{"status":"ok","timestamp":1672373886100,"user_tz":-540,"elapsed":11885,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"d181dab0-3f02-40d0-aa51-52bb2be5f002"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.6.*\n","  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 21.2 MB/s \n","\u001b[?25hInstalling collected packages: keras\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.6.0 which is incompatible.\u001b[0m\n","Successfully installed keras-2.6.0\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/Tiiiger/bert_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"44jpBE_GQQ70","executionInfo":{"status":"ok","timestamp":1672379784375,"user_tz":-540,"elapsed":1413,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"c8bf7358-e819-4f0b-ea4c-5cb117677485"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'bert_score'...\n","remote: Enumerating objects: 982, done.\u001b[K\n","remote: Counting objects: 100% (344/344), done.\u001b[K\n","remote: Compressing objects: 100% (163/163), done.\u001b[K\n","remote: Total 982 (delta 207), reused 308 (delta 180), pack-reused 638\u001b[K\n","Receiving objects: 100% (982/982), 1.35 MiB | 8.38 MiB/s, done.\n","Resolving deltas: 100% (522/522), done.\n"]}]},{"cell_type":"code","source":["%cd /content/bert_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kyPyqB9BQWsb","executionInfo":{"status":"ok","timestamp":1672379856049,"user_tz":-540,"elapsed":525,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"15008c31-2c86-4887-9994-2509373d8e9b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/bert_score\n"]}]},{"cell_type":"code","source":["y_true = \"노형욱 국토교통부 장관은 7월 14일 수도권 코로나19 방역의 관문이라고 할 수 있는 서울역을 방문하여, 철도역사 및 열차 방역실태 등을 점검하고, 관계자들을 격려하였다. 또한 방역으로 인해 자칫 운행 안전에 대한 경각심이 느슨해질 수 있다면서, 촘촘하고 치밀한 시설물 점검 및 차량의 정비를 통해 안전사고 예방에도 만전을 기해줄 것을 당부하였다.\"\n","y_pred = '노 장관은 서울역을 방문하여 철도역사 및 열차 방역실태 등을 점검하고 관계자들을 격려하였다.'"],"metadata":{"id":"wynHcDKFSUfI","executionInfo":{"status":"ok","timestamp":1672379792768,"user_tz":-540,"elapsed":455,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!bert-score -r example/refs2.txt -c example/hyps.txt --lang others"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSe2cP6qQWMM","executionInfo":{"status":"ok","timestamp":1672379863736,"user_tz":-540,"elapsed":558,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"e1e2e39e-427a-4483-b66b-fc8276d4b7c9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: bert-score: command not found\n"]}]},{"cell_type":"code","source":["!bert-score -r example/refs2.txt -c example/hyps.txt --lang others"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcNdIoUiSYDY","executionInfo":{"status":"ok","timestamp":1672375589143,"user_tz":-540,"elapsed":13162,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"0ef49960-1fbb-41dd-9bbb-48ad7f000d69"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.25.1)_fast-tokenizer P: 0.777701 R: 0.762030 F1: 0.769786\n"]}]},{"cell_type":"code","source":["from bert_score import score\n","\n","refs = [\"노형욱 국토교통부 장관은 7월 14일 수도권 코로나19 방역의 관문이라고 할 수 있는 서울역을 방문하여, 철도역사 및 열차 방역실태 등을 점검하고, 관계자들을 격려하였다. 또한 방역으로 인해 자칫 운행 안전에 대한 경각심이 느슨해질 수 있다면서, 촘촘하고 치밀한 시설물 점검 및 차량의 정비를 통해 안전사고 예방에도 만전을 기해줄 것을 당부하였다.\"]\n","cands = ['노 장관은 서울역을 방문하여 철도역사 및 열차 방역실태 등을 점검하고 관계자들을 격려하였다.']\n","\n","(P, R, F), hashname = score(cands, refs, lang=\"others\", return_hash=True)\n","print(\n","    f\"{hashname}: P={P.mean().item():.6f} R={R.mean().item():.6f} F={F.mean().item():.6f}\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236,"referenced_widgets":["3e6c70c9abdb4b00a64296c77d2f487a","cff9a744c904442b90e3b91fda2bcda9","efcf95b70ea943e69e800f84033ea579","d454efbed64041f1ba699127cc9f26a0","e943b75da438436281eac970bdec6479","e59535becc2b4184a5d32847b56e4342","019ef6222edf4c2b988b0110531b13f8","d7d44542813f4e2a86f01abea5783bda","ff1404129ea14b0d9da90d9052b71384","ec8ea7b98fdf4e16aa6e2b5d7c87d64f","8d64cb6b3a2e493b8755cb219adc89e6","669f9dea6a134624aef4051be83f0ad2","069b96ff8bc0489eba25d1804540df14","fd789578200642229559db0f72551a93","1544e3ec8bdc46a38b2c2a5030d07317","bbece60ad9624cba834c518e02cc9e76","1baf7124671f4850ac458a5d64710fe4","84d5b4f299764ea294cf228adf6c514a","042389f00b5048f2a530243c1856475b","058ff63233ac44cea7bb5e5724177e0e","1812468e1ef3431fb948df15fc1e5b5c","a1a352d3faf141efb053f2db87fa48f2","d4f71a2bead54f8d8d9de753192e4847","9ceac191841d4d29849d0780c1fc21c8","914170f1568642efa610abaa311448fe","5a5b997e0948461f9fd7acf548825446","5a7f4515571a432f970311000ea6b0a7","6e7be857c9f9485f9f91bdd50a333429","5b508dc3c5c84cadb0cad34b1ec729cf","38086bb11bc747e793bf80b43a9abcb6","d8b5175062e04d3caf3af5d9984850cc","103dc2183a9b462296597f60bfcd97cf","ba79e1cd093443f4ac233051eb26da87","708bfa7bf5e74b99864763a5f5c1da9b","1f7f7879631e497d92c67f45e3b023cb","70e6e07b42984876a510a02dcf64c123","627ac888079243b099acd5aecc5a8961","c272d93441ed4132bf733bc7f5924e09","395455bc982c4adaacef3528b3e92b81","7c950ce88ea946c4a3988ff5d7073bcc","835b60036cf94e4c80f999d2f1f47ddb","24d53a2bbc4c49c2b6409e5a1073510b","675aa28ea0ad460c9551e8483528b8a9","f1761a49132d408c98f1195c34628247"]},"id":"Bl2aQxGLO_WE","executionInfo":{"status":"ok","timestamp":1672379948427,"user_tz":-540,"elapsed":44757,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"f3b5be9a-3eaa-4e9d-e931-e1e3549877c1"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6c70c9abdb4b00a64296c77d2f487a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"669f9dea6a134624aef4051be83f0ad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4f71a2bead54f8d8d9de753192e4847"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"708bfa7bf5e74b99864763a5f5c1da9b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.25.1): P=0.915823 R=0.737988 F=0.817345\n"]}]},{"cell_type":"code","source":["import bert_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"lScifDpkPgyi","executionInfo":{"status":"error","timestamp":1672374302385,"user_tz":-540,"elapsed":6,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"baec283b-1288-4acd-b5a9-b69db9fe8ab3"},"execution_count":14,"outputs":[{"output_type":"error","ename":"AlreadyExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-0affdc93bb71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbert_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/bert_score/bert_score/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.3.12\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mscorer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bert_score/bert_score/score.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes_grid1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m from .utils import (bert_cos_score_idf, cache_scibert, get_bert_embedding,\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_monitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m _tf2_gauge = _monitoring.BoolGauge(\n\u001b[0m\u001b[1;32m    121\u001b[0m     '/tensorflow/api/tf2_enable', 'Environment variable TF2_BEHAVIOR is set\".')\n\u001b[1;32m    122\u001b[0m \u001b[0m_tf2_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, description, *labels)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0;34m*\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \"\"\"\n\u001b[0;32m--> 356\u001b[0;31m     super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,\n\u001b[0m\u001b[1;32m    357\u001b[0m                                     len(labels), name, description, *labels)\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/monitoring.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[1;32m    129\u001b[0m           self._metric_name, len(self._metric_methods)))\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."]}]},{"cell_type":"code","source":["import torch\n","\n","!pip install keras-nlp --upgrade\n","\n","!pip install rouge-score --upgrade\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7NtohVMRl9j","executionInfo":{"status":"ok","timestamp":1672380260123,"user_tz":-540,"elapsed":133276,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"cb84da6f-6b92-45cd-da91-dc80deeb2872"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-nlp\n","  Downloading keras_nlp-0.4.0-py3-none-any.whl (337 kB)\n","\u001b[K     |████████████████████████████████| 337 kB 12.5 MB/s \n","\u001b[?25hCollecting tensorflow-text\n","  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 60.1 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (2.9.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (21.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras-nlp) (1.3.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras-nlp) (3.0.9)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.6.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (0.28.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (2.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (57.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.51.1)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (2.9.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.14.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (2.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (14.0.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (2.1.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (3.1.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (3.19.6)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (0.4.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (1.12)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-nlp) (4.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras-nlp) (0.38.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (2.23.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (2.15.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (0.6.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (5.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->keras-nlp) (3.2.2)\n","Collecting tensorflow\n","  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[K     |████████████████████████████████| 588.3 MB 22 kB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras-nlp) (0.12.0)\n","INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow-text\n","  Downloading tensorflow_text-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 51.0 MB/s \n","\u001b[?25hCollecting tensorflow\n","  Downloading tensorflow-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[K     |████████████████████████████████| 578.1 MB 8.7 kB/s \n","\u001b[?25h  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[K     |████████████████████████████████| 578.1 MB 7.1 kB/s \n","\u001b[?25hCollecting tensorflow-text\n","  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[K     |████████████████████████████████| 4.6 MB 57.3 MB/s \n","\u001b[?25hInstalling collected packages: tensorflow-text, keras-nlp\n","Successfully installed keras-nlp-0.4.0 tensorflow-text-2.9.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.3.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge-score) (3.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.21.6)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge-score) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (4.64.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->rouge-score) (2022.6.2)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=fa5680f280bf77145ad227fc8c2188c40a47df2f101c531f145a16595a33c1eb\n","  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}]},{"cell_type":"code","source":["\n","from tensorflow import keras\n","import rouge_score\n","import keras_nlp\n","from keras_nlp.metrics.rouge_base import RougeBase\n","rouge_l = keras_nlp.metrics.RougeL()\n","y_true = \"노형욱 국토교통부 장관은 7월 14일 수도권 코로나19 방역의 관문이라고 할 수 있는 서울역을 방문하여, 철도역사 및 열차 방역실태 등을 점검하고, 관계자들을 격려하였다. 또한 방역으로 인해 자칫 운행 안전에 대한 경각심이 느슨해질 수 있다면서, 촘촘하고 치밀한 시설물 점검 및 차량의 정비를 통해 안전사고 예방에도 만전을 기해줄 것을 당부하였다.\"\n","y_pred = '노 장관은 서울역을 방문하여 철도역사 및 열차 방역실태 등을 점검하고 관계자들을 격려하였다.'\n","rouge_l(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iju_9GKRn5LY","executionInfo":{"status":"ok","timestamp":1672380262465,"user_tz":-540,"elapsed":2346,"user":{"displayName":"JMJ mseagle","userId":"05181043881737298106"}},"outputId":"66e29110-6178-4be2-8bb7-f180bb64adc9"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'precision': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n"," 'recall': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n"," 'f1_score': <tf.Tensor: shape=(), dtype=float32, numpy=0.0>}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"QAnE9OpHoAtC"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["KqYwUg-GI5T_","BeEsUq3yHevJ","Wb9SoZt9gTpu"],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3e6c70c9abdb4b00a64296c77d2f487a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cff9a744c904442b90e3b91fda2bcda9","IPY_MODEL_efcf95b70ea943e69e800f84033ea579","IPY_MODEL_d454efbed64041f1ba699127cc9f26a0"],"layout":"IPY_MODEL_e943b75da438436281eac970bdec6479"}},"cff9a744c904442b90e3b91fda2bcda9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e59535becc2b4184a5d32847b56e4342","placeholder":"​","style":"IPY_MODEL_019ef6222edf4c2b988b0110531b13f8","value":"Downloading: 100%"}},"efcf95b70ea943e69e800f84033ea579":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7d44542813f4e2a86f01abea5783bda","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff1404129ea14b0d9da90d9052b71384","value":29}},"d454efbed64041f1ba699127cc9f26a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8ea7b98fdf4e16aa6e2b5d7c87d64f","placeholder":"​","style":"IPY_MODEL_8d64cb6b3a2e493b8755cb219adc89e6","value":" 29.0/29.0 [00:00&lt;00:00, 450B/s]"}},"e943b75da438436281eac970bdec6479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e59535becc2b4184a5d32847b56e4342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"019ef6222edf4c2b988b0110531b13f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d44542813f4e2a86f01abea5783bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1404129ea14b0d9da90d9052b71384":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec8ea7b98fdf4e16aa6e2b5d7c87d64f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d64cb6b3a2e493b8755cb219adc89e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"669f9dea6a134624aef4051be83f0ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_069b96ff8bc0489eba25d1804540df14","IPY_MODEL_fd789578200642229559db0f72551a93","IPY_MODEL_1544e3ec8bdc46a38b2c2a5030d07317"],"layout":"IPY_MODEL_bbece60ad9624cba834c518e02cc9e76"}},"069b96ff8bc0489eba25d1804540df14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1baf7124671f4850ac458a5d64710fe4","placeholder":"​","style":"IPY_MODEL_84d5b4f299764ea294cf228adf6c514a","value":"Downloading: 100%"}},"fd789578200642229559db0f72551a93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_042389f00b5048f2a530243c1856475b","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_058ff63233ac44cea7bb5e5724177e0e","value":625}},"1544e3ec8bdc46a38b2c2a5030d07317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1812468e1ef3431fb948df15fc1e5b5c","placeholder":"​","style":"IPY_MODEL_a1a352d3faf141efb053f2db87fa48f2","value":" 625/625 [00:00&lt;00:00, 17.7kB/s]"}},"bbece60ad9624cba834c518e02cc9e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1baf7124671f4850ac458a5d64710fe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84d5b4f299764ea294cf228adf6c514a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"042389f00b5048f2a530243c1856475b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058ff63233ac44cea7bb5e5724177e0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1812468e1ef3431fb948df15fc1e5b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a352d3faf141efb053f2db87fa48f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4f71a2bead54f8d8d9de753192e4847":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ceac191841d4d29849d0780c1fc21c8","IPY_MODEL_914170f1568642efa610abaa311448fe","IPY_MODEL_5a5b997e0948461f9fd7acf548825446"],"layout":"IPY_MODEL_5a7f4515571a432f970311000ea6b0a7"}},"9ceac191841d4d29849d0780c1fc21c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e7be857c9f9485f9f91bdd50a333429","placeholder":"​","style":"IPY_MODEL_5b508dc3c5c84cadb0cad34b1ec729cf","value":"Downloading: 100%"}},"914170f1568642efa610abaa311448fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38086bb11bc747e793bf80b43a9abcb6","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8b5175062e04d3caf3af5d9984850cc","value":995526}},"5a5b997e0948461f9fd7acf548825446":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_103dc2183a9b462296597f60bfcd97cf","placeholder":"​","style":"IPY_MODEL_ba79e1cd093443f4ac233051eb26da87","value":" 996k/996k [00:00&lt;00:00, 1.82MB/s]"}},"5a7f4515571a432f970311000ea6b0a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e7be857c9f9485f9f91bdd50a333429":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b508dc3c5c84cadb0cad34b1ec729cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38086bb11bc747e793bf80b43a9abcb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8b5175062e04d3caf3af5d9984850cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"103dc2183a9b462296597f60bfcd97cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba79e1cd093443f4ac233051eb26da87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"708bfa7bf5e74b99864763a5f5c1da9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f7f7879631e497d92c67f45e3b023cb","IPY_MODEL_70e6e07b42984876a510a02dcf64c123","IPY_MODEL_627ac888079243b099acd5aecc5a8961"],"layout":"IPY_MODEL_c272d93441ed4132bf733bc7f5924e09"}},"1f7f7879631e497d92c67f45e3b023cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_395455bc982c4adaacef3528b3e92b81","placeholder":"​","style":"IPY_MODEL_7c950ce88ea946c4a3988ff5d7073bcc","value":"Downloading: 100%"}},"70e6e07b42984876a510a02dcf64c123":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_835b60036cf94e4c80f999d2f1f47ddb","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24d53a2bbc4c49c2b6409e5a1073510b","value":714314041}},"627ac888079243b099acd5aecc5a8961":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675aa28ea0ad460c9551e8483528b8a9","placeholder":"​","style":"IPY_MODEL_f1761a49132d408c98f1195c34628247","value":" 714M/714M [00:14&lt;00:00, 57.8MB/s]"}},"c272d93441ed4132bf733bc7f5924e09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"395455bc982c4adaacef3528b3e92b81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c950ce88ea946c4a3988ff5d7073bcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"835b60036cf94e4c80f999d2f1f47ddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24d53a2bbc4c49c2b6409e5a1073510b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"675aa28ea0ad460c9551e8483528b8a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1761a49132d408c98f1195c34628247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}